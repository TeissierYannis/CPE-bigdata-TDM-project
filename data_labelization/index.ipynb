{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto labelization with yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All folders are created\n",
      "All files are downloaded\n"
     ]
    }
   ],
   "source": [
    "# Load the images from the folder \"../images\"\n",
    "import os\n",
    "\n",
    "# Load the images from the folder \"../images\"\n",
    "images = []\n",
    "for filename in os.listdir(\"../output/images\"):\n",
    "    images.append(filename)\n",
    "\n",
    "\n",
    "# Download and place it into the folder \"../config\"\n",
    "# https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "# https://pjreddie.com/media/files/yolov3.weights\n",
    "# https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
    "\n",
    "def download(url, filename):\n",
    "    import functools\n",
    "    import pathlib\n",
    "    import shutil\n",
    "    import requests\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    if r.status_code != 200:\n",
    "        r.raise_for_status()  # Will only raise for 4xx codes, so...\n",
    "        raise RuntimeError(f\"Request to {url} returned status code {r.status_code}\")\n",
    "    file_size = int(r.headers.get('Content-Length', 0))\n",
    "\n",
    "    path = pathlib.Path(filename).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "    r.raw.read = functools.partial(r.raw.read, decode_content=True)  # Decompress if needed\n",
    "    with tqdm.wrapattr(r.raw, \"read\", total=file_size, desc=desc) as r_raw:\n",
    "        with path.open(\"wb\") as f:\n",
    "            shutil.copyfileobj(r_raw, f)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "# Check if exist the folder \"../images_labelized\"\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"../output/images_labelized\"):\n",
    "    os.makedirs(\"../output/images_labelized\")\n",
    "\n",
    "# Check if the folder \"../labels\" exist\n",
    "if not os.path.exists(\"../output/labels\"):\n",
    "    os.makedirs(\"../output/labels\")\n",
    "\n",
    "# check if exist the folder \"../config\"\n",
    "if not os.path.exists(\"../output/config\"):\n",
    "    os.makedirs(\"../output/config\")\n",
    "\n",
    "print(\"All folders are created\")\n",
    "\n",
    "# Check if the file yolov3.cfg exist\n",
    "if not os.path.isfile(\"../output/config/yolov3.cfg\"):\n",
    "    download(\"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\", \"../output/config/yolov3.cfg\")\n",
    "\n",
    "# Check if the file yolov3.weights exist\n",
    "if not os.path.isfile(\"../output/config/yolov3.weights\"):\n",
    "    download(\"https://pjreddie.com/media/files/yolov3.weights\", \"../output/config/yolov3.weights\")\n",
    "\n",
    "# Check if the file coco.names exist\n",
    "if not os.path.isfile(\"../output/config/coco.names\"):\n",
    "    download(\"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\", \"../output/config/coco.names\")\n",
    "\n",
    "print(\"All files are downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from multiprocessing import Pool\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def detect(\n",
    "        path_name,\n",
    "        output_folder = \"../output/images_labelized/\",\n",
    "        label_path = \"../output/config/coco.names\",\n",
    "        weights_path = \"../output/config/yolov3.weights\",\n",
    "        config_path = \"../output/config/yolov3.cfg\",\n",
    "        CONFIDENCE = 0.5,\n",
    "        SCORE_THRESHOLD = 0.5,\n",
    "        IOU_THRESHOLD = 0.5\n",
    "):\n",
    "    labels = open(label_path).read().strip().split(\"\\n\")\n",
    "    colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "    net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "    image = cv2.imread(path_name)\n",
    "    file_name = os.path.basename(path_name)\n",
    "    filename, ext = file_name.split(\".\")\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    # create 4D blob\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # sets the blob as the input of the network\n",
    "    net.setInput(blob)\n",
    "    # get all the layer names\n",
    "    ln = net.getLayerNames()\n",
    "    try:\n",
    "        ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except IndexError:\n",
    "        # in case getUnconnectedOutLayers() returns 1D array when CUDA isn't available\n",
    "        ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # feed forward (inference) and get the network output\n",
    "    # measure how much it took in seconds\n",
    "    layer_outputs = net.forward(ln)\n",
    "\n",
    "    font_scale = 1\n",
    "    thickness = 1\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    text_labels = []\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layer_outputs:\n",
    "        # loop over each of the object detections\n",
    "        for detection in output:\n",
    "            # extract the class id (label) and confidence (as a probability) of\n",
    "            # the current object detection\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # discard out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            if confidence > CONFIDENCE:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update our list of bounding box coordinates, confidences,\n",
    "                # and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in range(len(boxes)):\n",
    "            text_labels.append(labels[class_ids[i]])\n",
    "            # extract the bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            # draw a bounding box rectangle and label on the image\n",
    "            color = [int(c) for c in colors[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "            text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            # calculate text width & height to draw the transparent boxes as background of the text\n",
    "            (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "            text_offset_x = x\n",
    "            text_offset_y = y - 5\n",
    "            box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "            # add opacity (transparency to the box)\n",
    "            image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "            # now put the text (label: confidence %)\n",
    "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "    return text_labels\n",
    "\n",
    "    #cv2.imwrite(os.path.join(output_folder, filename + \".\" + ext), image)\n",
    "\n",
    "\n",
    "\n",
    "def update_tags(images):\n",
    "    # Run the YOLOv3 algorithm on each image\n",
    "    # display progress bar in the first thread only\n",
    "    for image in tqdm(images, desc=\"Updating tags\"):\n",
    "        # read pickle file from ../output/metadata/file_name.pkl\n",
    "        file_name = os.path.basename(image)\n",
    "        file_name, ext = file_name.split(\".\")\n",
    "        with open(os.path.join(\"../output/metadata\", file_name + \".pickle\"), \"rb\") as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        if \"tags\" in metadata:\n",
    "            continue\n",
    "\n",
    "        labels = detect(image)\n",
    "\n",
    "        # Remove duplicates from labels\n",
    "        labels = list(set(labels))\n",
    "        # add labels to metadata\n",
    "        metadata[\"tags\"] = labels\n",
    "        # save metadata to pickle file\n",
    "        with open(os.path.join(\"../output/metadata\", file_name + \".pickle\"), \"wb\") as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "\n",
    "# Get the list of images\n",
    "images = os.listdir(\"../output/images\")\n",
    "images = [os.path.join(\"../output/images\", image) for image in images]\n",
    "\n",
    "update_tags(images)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, find dominant colors in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# Convert RGB to HEX (RGB is an array of 3 values)\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % (int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
    "\n",
    "\n",
    "# Find 4 dominant colors in the image\n",
    "def find_dominant_colors(image, k=4, image_processing_size=None):\n",
    "    # Need to return a list of 4 colors\n",
    "    assert k <= 4, \"k needs to be less than or equal to 4\"\n",
    "    # Resize image if new dims provided, just to speed up processing\n",
    "    if image_processing_size is not None:\n",
    "        image = cv2.resize(image, image_processing_size, interpolation=cv2.INTER_AREA)\n",
    "    # Convert to RGB from BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Reshape the image to be a list of pixels\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    # Cluster and assign labels to the pixels\n",
    "    clt = KMeans(n_clusters=k, n_init=10)\n",
    "    labels = clt.fit_predict(image)\n",
    "    # Count labels to find most popular\n",
    "    label_counts = Counter(labels)\n",
    "    # Subset out most popular centroid\n",
    "    dominant_colors = [clt.cluster_centers_[i] for i in label_counts.keys()]\n",
    "    # For each color, convert to hex and append to list\n",
    "    dominant_colors = [rgb_to_hex(color) for color in dominant_colors]\n",
    "\n",
    "    # find percent of each color in the image\n",
    "    percent = [int((label_counts[i] / len(labels)) * 100) for i in label_counts.keys()]\n",
    "\n",
    "    # return the 4 dominant colors and their percent\n",
    "    dominant_colors = list(zip(dominant_colors, percent))\n",
    "    return dominant_colors\n",
    "\n",
    "\n",
    "# For each image in the folder \"../images_labelized\"\n",
    "for image in tqdm(images, desc=\"Finding dominant colors\"):\n",
    "    img = cv2.imread(\"../output/images/\" + image)\n",
    "    dominant_color = find_dominant_colors(img)\n",
    "    # save the image in the folder \"../images_labelized\"\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"a\") as f:\n",
    "        f.write(f\"dominant_color:{dominant_color}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of the dominant colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Creating color pie charts\"):\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"dominant_color\" in line:\n",
    "                # Get the dominant color\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                # Create the pie chart\n",
    "                labels = [i[0] for i in dominant_color]\n",
    "                sizes = [i[1] for i in dominant_color]\n",
    "                fig1, ax1 = plt.subplots()\n",
    "                # change the colors of the pie chart\n",
    "                colors = [i[0] for i in dominant_color]\n",
    "                ax1.pie(sizes, colors=colors, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "                ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "                # Save the pie chart in the folder \"../histogram\"\n",
    "                plt.savefig(\"../output/histogram/\" + image.split(\".\")[0] + \".png\")\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the images by multiple data\n",
    "# there is multiple ways to group the images (in the folder labels, we can find the label, the dominant color), in metadata folder, we have the metadata of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Create a dataframe with the metadata of each image, one pikle file per image\n",
    "df = pd.DataFrame(columns=[\"image\", \"label\", \"dominant_color\", \"metadata\"])\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Creating dataframe\"):\n",
    "    # Example of lines :\n",
    "    # label:person,posX:113,posY:120,width:134,height:360,confidence:0.9987273216247559%\n",
    "    # label:horse,posX:325,posY:187,width:282,height:270,confidence:0.9985314607620239%\n",
    "    # label:handbag,posX:143,posY:385,width:82,height:91,confidence:0.5130287408828735%\n",
    "    # dominant_color:[('#3e4542', 37), ('#6d6f6d', 22), ('#a6a4a7', 9), ('#191b1d', 30)]\n",
    "\n",
    "    # Get the label\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        # it's possible to have more than one label per image\n",
    "        label = \"\"\n",
    "        dominant_color = \"\"\n",
    "\n",
    "        for line in f:\n",
    "            if \"label\" in line:\n",
    "                raw_label = line.split(\":\")[1]\n",
    "                # cut as the first , is the end of the label\n",
    "                label += raw_label.split(\",\")[0]\n",
    "                label += \",\"\n",
    "            if \"dominant_color\" in line:\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                dominant_color = [i[0] for i in dominant_color]\n",
    "                dominant_color = \",\".join(dominant_color)\n",
    "        # Get the metadata\n",
    "        with open(\"../output/metadata/\" + image.split(\".\")[0] + \".pickle\", \"rb\") as f:\n",
    "            metadata = pickle.load(f)\n",
    "            # Convert metadata to string : key:value,key:value\n",
    "            metadata = \",\".join([f\"{key}:{value}\" for key, value in metadata.items()])\n",
    "\n",
    "        # Add the image to the dataframe by using panda.concat\n",
    "        df = pd.concat([df, pd.DataFrame([[image, label, dominant_color, metadata]],\n",
    "                                         columns=[\"image\", \"label\", \"dominant_color\", \"metadata\"])])\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(\"../output/dataframe.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the images by label\n",
    "import os\n",
    "\n",
    "# Create a folder for each label\n",
    "for label in df[\"label\"].unique():\n",
    "    if not os.path.exists(\"../output/grouped_by_label/\" + label):\n",
    "        os.makedirs(\"../output/grouped_by_label/\" + label)\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by label\"):\n",
    "    # Get the label\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"label\" in line:\n",
    "                label = line.split(\":\")[1]\n",
    "                label = label.split(\",\")[0]\n",
    "    # Copy the image in the folder \"../grouped_by_label\"\n",
    "    os.system(f\"cp ../output/images/{image} ../output/grouped_by_label/{label}/{image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group image by dominant color, take the color one by one and create a folder for each color\n",
    "for colors in df[\"dominant_color\"].unique():\n",
    "    # split colors by , to get individual colors\n",
    "    colors = colors.split(\",\")\n",
    "    for color in colors:\n",
    "        if not os.path.exists(\"../output/grouped_by_dominant_color/\" + color):\n",
    "            os.makedirs(\"../output/grouped_by_dominant_color/\" + color)\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by dominant color\"):\n",
    "    # Get the dominant color\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"dominant_color\" in line:\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                dominant_color = [i[0] for i in dominant_color]\n",
    "                dominant_color = \",\".join(dominant_color)\n",
    "                # split colors by , to get individual colors\n",
    "                dominant_color = dominant_color.split(\",\")\n",
    "                for color in dominant_color:\n",
    "                    # Copy the image in the folder \"../grouped_by_dominant_color\"\n",
    "                    os.system(f\"cp ../output/images/{image} ../output/grouped_by_dominant_color/{color}/{image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all metadata and group by similar metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metadata in df[\"metadata\"].unique():\n",
    "    # Metadata are in string formated as key:value,key:value\n",
    "    # Split the metadata by , to get individual metadata\n",
    "    metadata = metadata.split(\",\")\n",
    "    for meta in metadata:\n",
    "        try:\n",
    "            # Split the metadata by : to get the key and the value\n",
    "            key, value = meta.split(\":\")\n",
    "            if not os.path.exists(f\"../output/grouped_by_metadata/{key}/{value}\"):\n",
    "                os.makedirs(f\"../output/grouped_by_metadata/{key}/{value}\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by metadata\"):\n",
    "    # Get the metadata\n",
    "    with open(\"../output/metadata/\" + image.split(\".\")[0] + \".pickle\", \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "        # Convert metadata to string : key:value,key:value\n",
    "        metadata = \",\".join([f\"{key}:{value}\" for key, value in metadata.items()])\n",
    "        # Split the metadata by , to get individual metadata\n",
    "        metadata = metadata.split(\",\")\n",
    "        for meta in metadata:\n",
    "            try:\n",
    "                # Split the metadata by : to get the key and the value\n",
    "                key, value = meta.split(\":\")\n",
    "            except:\n",
    "                continue\n",
    "            # Copy the image in the folder \"../grouped_by_metadata\"\n",
    "            os.system(f\"cp ../output/images/{image} ../output/grouped_by_metadata/{key}/{value}/{image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
