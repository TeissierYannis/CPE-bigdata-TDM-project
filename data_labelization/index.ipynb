{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "This code imports several libraries in order to perform some data processing tasks. The libraries used are:\n",
    "import pickle: imports the pickle module that provides a way to serialize and deserialize Python objects.\n",
    "\n",
    "import os: imports the os module that provides a way to interact with the operating system.\n",
    "\n",
    "import sqlite3: imports the sqlite3 module that provides a way to work with SQLite databases.\n",
    "\n",
    "import json: imports the json module that provides a way to encode and decode JSON data.\n",
    "\n",
    "import cv2: imports the cv2 module which is an OpenCV library for image processing and computer vision tasks.\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans: imports the MiniBatchKMeans class from the sklearn.cluster module which provides a way to perform KMeans clustering on a large dataset.\n",
    "\n",
    "from tqdm import tqdm: imports the tqdm module which provides a progress bar for long-running operations.\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection: imports the DetrImageProcessor and DetrForObjectDetection classes from the transformers module which provides a way to perform object detection using the DETR (DEtection TRansformer) model.\n",
    "\n",
    "import torch: imports the torch module which is a PyTorch library for machine learning and deep learning tasks.\n",
    "\n",
    "from PIL import Image: imports the Image class from the PIL module which provides a way to manipulate and analyze image data.\n",
    "\n",
    "With these libraries, you should be able to perform a wide range of data processing and analysis tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install sqlite3 json cv2 scikit-learn tqdm transformers torch Pillow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import cv2\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from tqdm import tqdm\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Settings base variables and paths\n",
    "This code sets up the file structure and URL's for a project that uses data from an image dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "config_path = os.path.join(output_path, \"config\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, config_path]\n",
    "\n",
    "# Set the base URL for the dataset\n",
    "metadata_extension = \"sqlite\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create folder structure\n",
    "The code creates the folder structure for the project. The folder structure is as follows:\n",
    "- output\n",
    "    - images\n",
    "    - metadata\n",
    "    - config\n",
    "\n",
    "This method creates a folder with the given path if it doesn't already exist, It also outputs a message to inform the user if the folder was created or if it already exists.\n",
    "This is useful for organizing and managing files in a project. By creating a folder to store data and resources, it keeps the working directory tidy and makes it easier to locate files. Additionally, by checking if the folder exists before creating it, it prevents the program from overwriting existing data or throwing an error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"\n",
    "    This function creates a folder at the specified path.\n",
    "    If the folder already exists, it will print a message saying so.\n",
    "    If there is an error creating the folder, it will print the error message.\n",
    "\n",
    "    Parameters:\n",
    "        :param path (str): The path of the folder to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use os.mkdir to create the folder at the specified path\n",
    "        os.mkdir(path)\n",
    "        print(f\"Folder {path} created\")\n",
    "    except FileExistsError:\n",
    "        # If the folder already exists, print a message saying so\n",
    "        print(f\"Folder {path} already exists\")\n",
    "    except Exception as e:\n",
    "        # If there is an error creating the folder, print the error message\n",
    "        print(f\"Error creating folder {path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the folder structure\n",
    "This method initializes a list of folders by calling the create_folder method for each folder in the list.\n",
    "The purpose of this method is to make sure that all necessary folders exist before the program continues its execution.\n",
    "If a folder does not exist, the create_folder method will create it. If a folder already exists, the method will simply print a message indicating that the folder already exists. In case of any other error, the method will print the error message."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def init_folder(folder_names: list):\n",
    "    for folder_name in folder_names:\n",
    "        create_folder(folder_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../output already exists\n",
      "Folder ../output/images already exists\n",
      "Folder ../output/metadata already exists\n",
      "Folder ../output/config created\n"
     ]
    }
   ],
   "source": [
    "init_folder(list_of_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define methods to get all the image paths\n",
    "The get_all_images method is used to retrieve all images present in the specified image path. It uses the os.walk function to traverse through all subdirectories within the image path and collects the file names that end with either '.png' or '.jpg' extensions. The full path of each image is then generated by joining the root directory and the file name. The method returns a list of all images' full paths. In case of any error, an error message is printed and an empty list is returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    \"\"\"Get all images from the given path.\n",
    "\n",
    "    Args:\n",
    "    param: image_path (str): path to the directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of full path to all the images with png or jpg extensions.\n",
    "    - empty list: an empty list if an error occurred while fetching images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # use os.walk to traverse all the subdirectories and get all images\n",
    "        return [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(path)\n",
    "                for name in files\n",
    "                if name.endswith((\".png\", \".jpg\"))]\n",
    "    except Exception as e:\n",
    "        # return an empty list and log the error message if an error occurred\n",
    "        print(f\"An error occurred while fetching images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Facebook DETR model (detr-resnet-101)\n",
    "\n",
    "The detect_with_transformers function takes an image file path as an input, then uses a pre-trained model called DEtection TRansformer (DETR) to detect objects within the image.\n",
    "\n",
    "The function first opens the input image using the Python Imaging Library (PIL) Image.open method. Then it instantiates two components of the DETR model: a DetrImageProcessor and a DetrForObjectDetection model. The DetrImageProcessor is responsible for processing the input image into a format that can be fed into the DetrForObjectDetection model. The DetrForObjectDetection model then takes the processed image and performs object detection by predicting bounding boxes and class labels for each detected object.\n",
    "\n",
    "Once the model has made its predictions, the function uses the processor.post_process_object_detection method to convert the bounding box and class label predictions into a format that is compatible with the Common Objects in Context (COCO) dataset. This conversion is necessary in order to use the COCO API, which provides a common framework for evaluating object detection models.\n",
    "\n",
    "The function then filters the detected objects by only keeping those with a confidence score above a certain threshold (0.9 in this case), and extracts the corresponding class labels. Finally, the function prints out a message for each detected object, indicating its class label, confidence score, and location within the image. The function returns a list of the detected object class labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def detect_with_transformers(image):\n",
    "    \"\"\"\n",
    "    This function detects objects in an image using the DETR (DEtection TRansformer) model by Facebook.\n",
    "\n",
    "    Args:\n",
    "    image: A string representing the path of the image to be processed.\n",
    "\n",
    "    Returns:\n",
    "    A list containing the labels of the detected objects in the image.\n",
    "\n",
    "    Raises:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    #image = Image.open(image)\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\")\n",
    "    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # convert outputs (bounding boxes and class logits) to COCO API\n",
    "    # let's only keep detections with score > 0.9\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "    labels = []\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        labels.append(model.config.id2label[label.item()])\n",
    "        print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "        )\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save  metadata\n",
    "\n",
    "The function save_metadata allows you to save metadata information of an image in either pickle, json, or sqlite format. The function takes four parameters: metadata, img_name, metadata_path, and save_format.\n",
    "\n",
    "metadata is a dictionary that contains the metadata information of an image. img_name is a string that represents the file name of the image. metadata_path is a string that specifies the path to the directory where the metadata will be saved. save_format is an optional parameter that specifies the format in which the metadata will be saved. The default value is pickle.\n",
    "\n",
    "The function saves the metadata in the specified format. If save_format is set to pickle, the metadata is saved in the pickle format. If save_format is set to json, the metadata is saved in the json format. If save_format is set to sqlite, the metadata is saved in the sqlite database.\n",
    "\n",
    "If an error occurs while saving the metadata, the function will print an error message indicating the image name and the error that occurred.\n",
    "\n",
    "The function does not return any value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def save_metadata(metadata, img_name, metadata_path, save_format='pickle'):\n",
    "    \"\"\"\n",
    "    This function saves the metadata information of an image in either pickle or json format.\n",
    "    Parameters:\n",
    "    metadata (dict): The metadata information of an image.\n",
    "    img_name (str): The file name of the image.\n",
    "    metadata_path (str): The path to the directory where the metadata will be saved.\n",
    "    save_format (str): The format in which the metadata will be saved. The default is 'pickle'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if save_format == 'pickle':\n",
    "            # save the metadata in pickle format\n",
    "            with open(os.path.join(metadata_path, os.path.splitext(os.path.basename(img_name))[0] + '.pickle'),\n",
    "                      'wb') as f:\n",
    "                pickle.dump(metadata, f)\n",
    "        elif save_format == 'json':\n",
    "            # save the metadata in json format\n",
    "            with open(os.path.join(metadata_path, os.path.splitext(os.path.basename(img_name))[0] + '.json'), 'w') as f:\n",
    "                json.dump(metadata, f)\n",
    "        elif save_format == 'sqlite':\n",
    "            # Get only the file name of the image\n",
    "            img_name = os.path.basename(img_name)\n",
    "            # Open a connection to the database\n",
    "            conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "            # Create a cursor\n",
    "            c = conn.cursor()\n",
    "            # Create a table if it doesn't exist : filename, key, value\n",
    "            c.execute('''CREATE TABLE IF NOT EXISTS metadata (filename text, key text, value text)''')\n",
    "            # Insert the metadata into the table\n",
    "            for key, value in metadata.items():\n",
    "                # Convert key, value to string\n",
    "                key = str(key)\n",
    "                value = str(value)\n",
    "                # Check if the key is already in the table\n",
    "                c.execute(\"SELECT * FROM metadata WHERE filename=? AND key=?\", (img_name, key))\n",
    "                # If the key is already in the table, update the value\n",
    "                if c.fetchone():\n",
    "                    c.execute(\"UPDATE metadata SET value=? WHERE filename=? AND key=?\", (value, img_name, key))\n",
    "                    # Commit the changes\n",
    "                    conn.commit()\n",
    "                # If the key is not in the table, insert the key, value pair\n",
    "                else:\n",
    "                    c.execute(\"INSERT INTO metadata VALUES (?, ?, ?)\", (img_name, key, value))\n",
    "                    # Commit the changes\n",
    "                    conn.commit()\n",
    "            # Close the connection\n",
    "            conn.close()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid save format\")\n",
    "    except Exception as e:\n",
    "        # print an error message if an error occurs\n",
    "        print(f\"An error occurred while saving metadata for {img_name}: {str(e)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read SQLite metadata\n",
    "\n",
    "The read_sqlite method is a function used to read metadata information from a SQLite database. The method takes two parameters: metadata_path, the path to the directory where the metadata is saved, and filename, the name of the file for which the metadata is to be retrieved.\n",
    "\n",
    "The method starts by connecting to the SQLite database located at metadata_path/metadata.db using the sqlite3.connect method. A cursor is then created to allow interaction with the database. If the metadata table doesn't exist in the database, it is created.\n",
    "\n",
    "The metadata for the specified filename is retrieved from the database by executing a SQL query that selects all rows where the filename column is equal to the filename parameter. The retrieved metadata is stored in a dictionary, where the keys are taken from the key column and the values from the value column.\n",
    "\n",
    "Finally, the database connection is closed and the metadata dictionary is returned as the result of the function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def read_sqlite(metadata_path, filename):\n",
    "    # Open a connection to the database\n",
    "    conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Create a table if it doesn't exist : filename, key, value\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS metadata (filename text, key text, value text)''')\n",
    "    # Insert the metadata into the table\n",
    "    c.execute(\"SELECT * FROM metadata WHERE filename=?\", (filename,))\n",
    "    # If the key is already in the table, update the value\n",
    "    metadata = {}\n",
    "    for row in c.fetchall():\n",
    "        metadata[row[1]] = row[2]\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    return metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set tags in metadata\n",
    "This function \"update_tags\" is used to run the YOLOv3 algorithm on a set of images, update the metadata of each image with the detected labels (tags) and save the updated metadata.\n",
    "\n",
    "The function takes 3 parameters:\n",
    "\n",
    "images: a list of file paths for the images that need to be processed.\n",
    "metadata_path: a file path to the directory where the metadata files are stored.\n",
    "save_format: the format of the metadata files. Can be either 'pickle' or 'sqlite'.\n",
    "The function uses the tqdm library to display a progress bar for the image processing. For each image, the function tries to retrieve its metadata based on the save_format. If the metadata file format is 'sqlite', the function calls the read_sqlite function to retrieve the metadata. If the metadata file format is 'pickle', the function reads the metadata file directly.\n",
    "\n",
    "If the metadata already contains a \"tags\" key, it means that the image has already been processed and its metadata has been updated with the labels, so the function skips that image.\n",
    "\n",
    "The function then calls the detect function to run the YOLOv3 algorithm on the image and retrieve the labels (tags). The labels are added to the metadata under the \"tags\" key.\n",
    "\n",
    "Finally, the function calls the save_metadata function to save the updated metadata. If an error occurs while processing an image (e.g. the metadata file is not found), the function prints an error message and continues processing the next image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def update_tags(images, metadata_path, save_format='pickle'):\n",
    "    # Run the YOLOv3 algorithm on each image\n",
    "    # display progress bar in the first thread only\n",
    "    for image in tqdm(images, desc=\"Updating tags\"):\n",
    "        # read pickle file from ../output/metadata/file_name.pkl\n",
    "        file_name = os.path.basename(image)\n",
    "        file_name, ext = file_name.split(\".\")\n",
    "        try:\n",
    "            if save_format == 'sqlite':\n",
    "                metadata = read_sqlite(metadata_path, file_name + \".\" + ext)\n",
    "            else:\n",
    "                with open(os.path.join(\"../output/metadata\", file_name + \".\" + metadata_extension), \"rb\") as f:\n",
    "                    if metadata_extension == \"json\":\n",
    "                        metadata = json.load(f)\n",
    "                    else:\n",
    "                        metadata = pickle.load(f)\n",
    "\n",
    "            if \"tags\" in metadata:\n",
    "                continue\n",
    "\n",
    "            image = Image.open(image)\n",
    "            # resize image to 416x416\n",
    "            image = image.resize((416, 416))\n",
    "            labels = detect_with_transformers(image)\n",
    "\n",
    "            # Remove duplicates from labels\n",
    "            labels = list(set(labels))\n",
    "            # add labels to metadata\n",
    "            metadata[\"tags\"] = labels\n",
    "            save_metadata(metadata, file_name + \".\" + ext, metadata_path, save_format)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found: \", file_name)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   0%|          | 0/1001 [00:00<?, ?it/s]/Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages/transformers/models/detr/image_processing_detr.py:776: FutureWarning: The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "  warnings.warn(\n",
      "Updating tags:   0%|          | 1/1001 [00:04<1:09:07,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected skis with confidence 0.925 at location [194.71, 310.14, 242.01, 339.13]\n",
      "Detected person with confidence 1.0 at location [161.99, 216.44, 254.45, 337.89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   0%|          | 2/1001 [00:07<59:29,  3.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected toilet with confidence 0.911 at location [-0.26, -0.94, 415.74, 218.55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   1%|          | 8/1001 [00:23<46:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.988 at location [244.12, 184.51, 278.94, 349.57]\n",
      "Detected person with confidence 0.991 at location [328.6, 185.97, 355.14, 326.3]\n",
      "Detected person with confidence 0.938 at location [265.76, 172.81, 288.09, 267.66]\n",
      "Detected horse with confidence 0.997 at location [91.65, 154.58, 258.49, 365.52]\n",
      "Detected person with confidence 0.998 at location [344.77, 177.38, 385.53, 394.41]\n",
      "Detected horse with confidence 0.999 at location [49.23, 167.49, 145.6, 353.55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 17/1001 [00:47<44:35,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.963 at location [93.36, 130.89, 204.74, 206.77]\n",
      "Detected cake with confidence 0.975 at location [-0.14, -0.14, 415.84, 415.84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 19/1001 [00:52<43:20,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 1.0 at location [161.0, 260.21, 242.09, 322.84]\n",
      "Detected snowboard with confidence 0.934 at location [161.18, 295.06, 200.24, 320.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 21/1001 [00:58<45:24,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.995 at location [109.57, 221.68, 334.35, 416.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 22/1001 [01:01<44:31,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cat with confidence 0.994 at location [35.83, 44.03, 324.9, 413.65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 24/1001 [01:07<47:05,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected donut with confidence 0.943 at location [317.51, 229.98, 415.98, 300.36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   2%|▏         | 25/1001 [01:10<46:50,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.972 at location [173.6, 156.5, 361.18, 413.6]\n",
      "Detected bird with confidence 0.994 at location [48.33, 103.41, 159.36, 322.37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   3%|▎         | 27/1001 [01:17<50:15,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cat with confidence 0.998 at location [-0.16, -0.13, 415.77, 415.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   3%|▎         | 29/1001 [01:22<49:15,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.993 at location [177.95, -0.34, 239.21, 297.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   3%|▎         | 32/1001 [01:32<50:20,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dog with confidence 0.972 at location [71.16, 81.93, 274.42, 308.4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   3%|▎         | 34/1001 [01:37<46:55,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected potted plant with confidence 0.985 at location [76.44, 294.68, 169.15, 415.28]\n",
      "Detected potted plant with confidence 0.918 at location [327.06, 280.11, 349.27, 300.36]\n",
      "Detected potted plant with confidence 0.917 at location [-0.0, 368.22, 99.63, 416.1]\n",
      "Detected potted plant with confidence 0.937 at location [306.51, 377.11, 415.76, 416.04]\n",
      "Detected potted plant with confidence 0.966 at location [167.0, 322.79, 307.66, 416.22]\n",
      "Detected potted plant with confidence 0.913 at location [313.72, 222.98, 416.14, 415.55]\n",
      "Detected potted plant with confidence 0.906 at location [-0.12, 270.71, 78.38, 395.67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   3%|▎         | 35/1001 [01:40<44:58,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bench with confidence 0.91 at location [225.47, 267.82, 303.0, 384.99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▎         | 36/1001 [01:43<44:42,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected handbag with confidence 0.987 at location [236.12, 17.25, 409.11, 280.48]\n",
      "Detected cell phone with confidence 0.997 at location [272.9, 265.27, 326.22, 360.29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▎         | 37/1001 [01:45<44:33,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.909 at location [115.56, 99.3, 223.83, 246.01]\n",
      "Detected person with confidence 0.912 at location [115.36, 98.51, 224.18, 305.73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 38/1001 [01:48<43:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cat with confidence 0.999 at location [209.45, 124.32, 303.33, 274.92]\n",
      "Detected person with confidence 0.98 at location [340.99, 1.36, 416.02, 358.15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 39/1001 [01:51<42:45,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.969 at location [36.99, 47.5, 300.24, 415.65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 40/1001 [01:53<43:25,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.999 at location [142.43, 70.15, 205.74, 232.29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 41/1001 [01:56<43:03,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.981 at location [0.3, 8.59, 355.55, 413.41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 42/1001 [01:59<42:27,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dog with confidence 0.999 at location [56.66, 111.05, 416.15, 415.52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 43/1001 [02:01<42:39,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 1.0 at location [279.53, 151.02, 323.02, 325.6]\n",
      "Detected backpack with confidence 0.997 at location [303.95, 155.3, 330.51, 216.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 44/1001 [02:04<42:17,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.994 at location [177.9, 0.71, 415.91, 411.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   4%|▍         | 45/1001 [02:07<42:12,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.995 at location [16.13, 95.38, 415.85, 367.53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   5%|▍         | 46/1001 [02:09<41:59,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected horse with confidence 0.999 at location [103.55, 127.08, 294.27, 348.83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   5%|▍         | 47/1001 [02:12<41:30,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dog with confidence 1.0 at location [149.39, 123.31, 277.95, 306.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   5%|▍         | 48/1001 [02:14<41:14,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.997 at location [187.54, 207.89, 261.3, 253.85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   5%|▌         | 54/1001 [02:30<41:59,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.999 at location [249.21, 315.79, 330.83, 386.47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▌         | 57/1001 [02:38<40:48,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected backpack with confidence 0.996 at location [207.81, 373.87, 232.68, 408.44]\n",
      "Detected person with confidence 0.999 at location [196.61, 354.62, 241.09, 415.88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▌         | 58/1001 [02:41<40:03,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected traffic light with confidence 0.911 at location [223.86, 266.84, 276.75, 319.7]\n",
      "Detected traffic light with confidence 0.936 at location [130.53, 266.31, 182.43, 319.13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▌         | 59/1001 [02:43<40:08,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected sports ball with confidence 0.938 at location [-0.57, -0.9, 159.78, 170.14]\n",
      "Detected cell phone with confidence 0.93 at location [130.92, 278.16, 194.06, 415.89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▌         | 60/1001 [02:46<39:35,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bottle with confidence 0.964 at location [230.65, 1.15, 347.05, 266.46]\n",
      "Detected wine glass with confidence 0.962 at location [-0.24, -0.87, 178.13, 301.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▌         | 62/1001 [02:51<41:55,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected potted plant with confidence 0.905 at location [20.82, 116.91, 331.88, 411.26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▋         | 64/1001 [02:56<41:29,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 1.0 at location [111.36, 240.93, 233.59, 355.74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   6%|▋         | 65/1001 [02:59<40:39,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.956 at location [165.59, 0.91, 261.38, 260.25]\n",
      "Detected bird with confidence 0.93 at location [193.44, 120.5, 260.72, 274.13]\n",
      "Detected bird with confidence 0.997 at location [252.13, 96.35, 309.79, 184.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   7%|▋         | 73/1001 [03:20<40:08,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected boat with confidence 0.997 at location [255.03, 56.27, 368.73, 196.22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 76/1001 [03:29<45:18,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.995 at location [46.98, 232.36, 55.25, 249.17]\n",
      "Detected person with confidence 0.981 at location [166.6, 197.19, 171.44, 209.97]\n",
      "Detected person with confidence 0.947 at location [150.44, 109.34, 311.86, 414.22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 77/1001 [03:32<48:08,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.941 at location [282.91, 301.53, 289.45, 322.59]\n",
      "Detected person with confidence 0.996 at location [334.42, 302.07, 343.23, 323.88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 78/1001 [03:35<46:05,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.903 at location [296.11, 264.27, 313.29, 277.05]\n",
      "Detected bird with confidence 0.949 at location [363.58, 215.97, 379.31, 234.82]\n",
      "Detected bird with confidence 0.933 at location [342.97, 250.98, 357.69, 261.97]\n",
      "Detected bird with confidence 0.931 at location [237.15, 176.24, 249.87, 194.88]\n",
      "Detected bird with confidence 0.924 at location [298.65, 242.17, 310.76, 254.14]\n",
      "Detected bird with confidence 0.916 at location [163.28, 191.83, 172.86, 204.41]\n",
      "Detected bird with confidence 0.902 at location [312.15, 174.85, 326.59, 182.49]\n",
      "Detected bird with confidence 0.919 at location [151.23, 157.36, 160.76, 175.69]\n",
      "Detected bird with confidence 0.93 at location [310.21, 184.23, 328.24, 201.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 81/1001 [03:43<43:02,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected bird with confidence 0.993 at location [271.7, 52.99, 310.89, 80.37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 83/1001 [03:48<40:48,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.991 at location [194.09, 209.81, 357.35, 410.16]\n",
      "Detected person with confidence 0.966 at location [77.68, 236.38, 195.93, 414.66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   8%|▊         | 84/1001 [03:51<41:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cow with confidence 0.962 at location [26.41, 110.89, 238.82, 352.24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   9%|▉         | 93/1001 [04:15<41:51,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.999 at location [231.29, 174.63, 251.02, 202.22]\n",
      "Detected person with confidence 0.999 at location [362.3, 293.29, 389.41, 344.28]\n",
      "Detected surfboard with confidence 0.987 at location [218.88, 195.84, 254.21, 206.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:   9%|▉         | 95/1001 [04:20<40:34,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected elephant with confidence 0.999 at location [-0.43, -0.5, 350.17, 399.48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:  10%|▉         | 97/1001 [04:26<40:31,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dog with confidence 0.999 at location [113.99, 161.65, 300.91, 415.99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:  10%|▉         | 98/1001 [04:28<40:06,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected car with confidence 0.998 at location [168.64, 18.27, 415.85, 284.85]\n",
      "Detected dog with confidence 1.0 at location [64.21, 111.24, 223.85, 379.64]\n",
      "Detected car with confidence 0.963 at location [193.73, 21.38, 351.54, 111.54]\n",
      "Detected car with confidence 0.937 at location [149.23, 83.77, 178.77, 114.35]\n",
      "Detected truck with confidence 0.938 at location [193.64, 20.61, 351.85, 111.74]\n",
      "Detected truck with confidence 0.977 at location [-0.01, -0.29, 151.71, 151.23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:  10%|▉         | 100/1001 [04:33<38:55,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.93 at location [-0.08, 137.79, 415.92, 415.75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags:  10%|█         | 101/1001 [04:36<40:00,  2.67s/it]"
     ]
    }
   ],
   "source": [
    "# Get the list of images\n",
    "images = os.listdir(images_path)\n",
    "images = [os.path.join(images_path, image) for image in images]\n",
    "\n",
    "update_tags(images, metadata_path, save_format='sqlite')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Now, find dominant colors in the images\n",
    "The functions rgb_to_hex and find_dominant_colors are used to find the dominant colors in an image.\n",
    "\n",
    "The function rgb_to_hex takes in an RGB array with 3 values, and returns the hexadecimal representation of the color. This can be useful for formatting colors in a standardized way, as hexadecimal codes are widely used in web development and other applications.\n",
    "\n",
    "The function find_dominant_colors takes in an image and optional parameters k and image_processing_size. The k parameter specifies the number of dominant colors to return, with a default value of 4. The image_processing_size parameter allows you to resize the image to a smaller size, to speed up the processing, if desired.\n",
    "\n",
    "The image is first converted from BGR to RGB, and then reshaped into a list of pixels. The KMeans algorithm is used to cluster the pixels into k clusters, and the most popular clusters are identified. The color values for each of the k clusters are converted to hexadecimal representation and returned as a list, along with the percentage of the image covered by each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % (int(rgb[0]), int(rgb[1]), int(rgb[2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_dominant_colors(image_path, k=4, downsample=2, resize=(200, 200)):\n",
    "    # Load image and convert to RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Downsample the image\n",
    "    image = cv2.resize(image, (image.shape[1] // downsample, image.shape[0] // downsample))\n",
    "\n",
    "    # Resize the image if requested\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image, resize)\n",
    "\n",
    "    # Flatten the image\n",
    "    image_flat = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "    # Cluster the pixels using KMeans and find percentage of image covered by each color\n",
    "    clt = MiniBatchKMeans(n_clusters=k, n_init=10, batch_size=100, random_state=42)\n",
    "    labels = clt.fit_predict(image_flat)\n",
    "\n",
    "    # Count the number of pixels assigned to each cluster\n",
    "    counts = np.bincount(labels)\n",
    "\n",
    "    # Calculate the percentage of pixels assigned to each cluster\n",
    "    percentages = counts / len(labels)\n",
    "\n",
    "    # Get the dominant colors\n",
    "    dominant_colors = clt.cluster_centers_\n",
    "\n",
    "    # Convert to hexadecimal format\n",
    "    dominant_colors_hex = [rgb_to_hex(color) for color in dominant_colors]\n",
    "\n",
    "    # Combine the dominant colors and their percentages into a array of tuples\n",
    "    result = list(zip(dominant_colors_hex, percentages))\n",
    "\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function takes a list of dictionaries containing metadata information of images and generates a list of SQL requests to insert the metadata into a database.\n",
    "\n",
    "The function first creates an empty list to store the SQL requests. It then loops over each metadata dictionary in the input list using the tqdm function to provide a progress bar. For each metadata dictionary, the function extracts the filename of the image and then loops over all the items in the dictionary.\n",
    "\n",
    "For each key-value pair in the metadata dictionary, the function creates an SQL request to insert the metadata into the database. The SQL request is in the form of a string that contains the filename, key, and value of the metadata item. The function adds each SQL request to the list of SQL requests.\n",
    "\n",
    "After processing all the metadata dictionaries, the function returns the list of SQL requests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen_sql_requests(filenames, colors):\n",
    "    \"\"\"\n",
    "    This function generates a list of SQL requests to insert metadata into a database.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of SQL requests to insert metadata into a database.\n",
    "    \"\"\"\n",
    "    # Create a list to store SQL requests\n",
    "    sql_requests = []\n",
    "\n",
    "    # Loop over all metadata\n",
    "    for filename, color in tqdm(zip(filenames, colors), desc=\"Generating SQL requests\"):\n",
    "        # Create SQL request to insert metadata into database (filename, key, value)\n",
    "        # format color to avoid errors with quote marks\n",
    "\n",
    "        sql_request = f\"INSERT INTO metadata VALUES ('{filename}', 'dominant_color', '{color}')\"\n",
    "        # Add SQL request to list\n",
    "        sql_requests.append(sql_request)\n",
    "\n",
    "    # Return the list of SQL requests\n",
    "    return sql_requests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method executes a SQL query on a SQLite database. The method takes a single parameter, query, which should be a valid SQL query that is compatible with the SQLite database.\n",
    "\n",
    "The method first establishes a connection to the SQLite database using the connect() method of the sqlite3 module in Python. It then executes the SQL query using the execute() method of the connection object. After executing the query, the method commits the changes to the database using the commit() method of the connection object, and then closes the connection using the close() method of the connection object.\n",
    "\n",
    "This method is typically used to insert metadata information into a SQLite database. It assumes that the SQLite database already exists and is located in the metadata_path directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Execute sql query\n",
    "def execute_query(query):\n",
    "    conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "    # Insert the metadata into the database\n",
    "    conn.execute(query)\n",
    "    # Commit the changes\n",
    "    conn.commit()\n",
    "    # Close the connection\n",
    "    conn.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code block is used to process images and find their dominant colors. The code first retrieves all the images present in the folder specified by the images_path variable. Then, it iterates over each image, reads the metadata associated with the image and finds its dominant color if it hasn't been calculated already.\n",
    "\n",
    "For each image, the code first reads the image using OpenCV's cv2.imread() function and stores the result in the img variable. The code then reads the metadata of the image. The type of metadata file (e.g. .json, .pkl, .sqlite) is specified by the metadata_extension variable. Based on the file extension, the code reads the metadata using either read_sqlite(), json.load(), or pickle.load() functions. If the metadata file is not found, the code continues to the next iteration of the loop, but if there is an error, it prints the error message and continues to the next iteration.\n",
    "\n",
    "If the metadata does not contain information about the dominant color of the image, the code calculates the dominant color by calling the find_dominant_colors() function. The result of the find_dominant_colors() function is then added to the metadata under the key \"dominant_color\". Finally, the updated metadata is saved using the save_metadata() function, which saves the metadata to the specified location using the specified file format (metadata_extension)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_all_colors(image_path):\n",
    "    \"\"\"\n",
    "    This coroutine extracts dominant colors from all images in a directory and saves the color information in the database.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the directory where the images are stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Get a list of all images in the directory\n",
    "    img_files = get_all_images(image_path)\n",
    "    colors = []\n",
    "\n",
    "    # Create a progress bar to track the progress of processing all images\n",
    "    for img in tqdm(img_files, desc=\"Processing images (Aprox: 25 minutes\"):\n",
    "        try:\n",
    "            # Create a list of coroutines to extract metadata for all images\n",
    "            color = find_dominant_colors(img, downsample=2, resize=(100, 100))\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            continue\n",
    "\n",
    "        if color:\n",
    "            # color to string to avoid errors with quote marks\n",
    "            color = str(color)\n",
    "            # replace quotes by double quotes\n",
    "            color = color.replace(\"'\", '\"')\n",
    "            colors.append(color)\n",
    "\n",
    "    img_files = [os.path.basename(img) for img in img_files]\n",
    "\n",
    "    queries = gen_sql_requests(img_files, colors)\n",
    "\n",
    "    conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "\n",
    "    for query in tqdm(queries, \"Inserting colors\"):\n",
    "        # Insert the metadata into the database\n",
    "        conn.execute(query)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    #for query in tqdm(queries, desc=\"Inserting dominant colors into the database\"):\n",
    "    #    execute_query(query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_all_colors(images_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
