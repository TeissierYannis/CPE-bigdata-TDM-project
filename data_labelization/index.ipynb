{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "The code imports several modules and packages that are needed for the implementation of the following tasks. These include:\n",
    "\n",
    "- `os`: which provides a way of using operating system dependent functionality like reading or writing to the file system.\n",
    "- `cv2`: which is an OpenCV library that provides computer vision functionality.\n",
    "- `sklearn.cluster.MiniBatchKMeans`: which is a KMeans clustering algorithm that splits a dataset into k clusters.\n",
    "- `tqdm`: which provides a progress bar for loops that takes an iterable object and returns an iterator.\n",
    "- `transformers.DetrImageProcessor`: which is a transformers library implementation of a processor for DETR (Dense Object Detection and Segmentation).\n",
    "- `transformers.DetrForObjectDetection`: which is a transformers library implementation of DETR (Dense Object Detection and Segmentation).\n",
    "- `torch`: which is a deep learning framework used for building and training neural networks.\n",
    "- `PIL`: which is a Python Imaging Library that adds image processing capabilities to Python interpreter.\n",
    "- `dotenv`: which is a library that loads environment variables from a .env file.\n",
    "- `pandas`: This library provides data structures and data analysis tools for handling and manipulating numerical tables and time series data.\n",
    "\n",
    "The code then uses the `load_dotenv` function to load the environment variables from the .env file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install opencv-python scikit-learn tqdm transformers torch Pillow python-dotenv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from tqdm import tqdm\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T08:51:58.184924Z",
     "end_time": "2023-04-23T08:51:58.189781Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set the Base Folder Paths for the Project\n",
    "\n",
    "The following code sets the base folder paths for the project, including:\n",
    "\n",
    "- `output_path`: The base folder path for the project.\n",
    "- `images_path`: The folder path for the images.\n",
    "- `metadata_path`: The folder path for the metadata.\n",
    "- `config_path`: The folder path for the configuration files.\n",
    "\n",
    "The code then creates a `list_of_paths` that contains all of these folder paths."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "config_path = os.path.join(output_path, \"config\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, config_path]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:50.747637Z",
     "end_time": "2023-04-23T09:19:50.750260Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  create_folder function\n",
    "\n",
    "The `create_folder` function is used to create a folder at a specified path. If the folder already exists, the function will print a message saying so. If there is an error creating the folder, the function will print the error message.\n",
    "\n",
    "## Parameters\n",
    "- `path` (str): The path of the folder to be created.\n",
    "\n",
    "## Returns\n",
    "- None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"\n",
    "    This function creates a folder at the specified path.\n",
    "    If the folder already exists, it will print a message saying so.\n",
    "    If there is an error creating the folder, it will print the error message.\n",
    "\n",
    "    Parameters:\n",
    "        :param path (str): The path of the folder to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use os.mkdir to create the folder at the specified path\n",
    "        os.mkdir(path)\n",
    "        print(f\"Folder {path} created\")\n",
    "    except FileExistsError:\n",
    "        # If the folder already exists, print a message saying so\n",
    "        print(f\"Folder {path} already exists\")\n",
    "    except Exception as e:\n",
    "        # If there is an error creating the folder, print the error message\n",
    "        print(f\"Error creating folder {path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:51.493419Z",
     "end_time": "2023-04-23T09:19:51.495115Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initializing Folders\n",
    "This function `init_folder` initializes the specified folders.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `folder_names (list)`: A list of folder names to be created.\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function iterates over the list of folder names and calls the `create_folder` function for each name.\n",
    "- This function is used to create the required output, images, metadata, and include folders."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_folder(folder_names: list):\n",
    "    for folder_name in folder_names:\n",
    "        create_folder(folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:52.483206Z",
     "end_time": "2023-04-23T09:19:52.490849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_folder(list_of_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:52.919031Z",
     "end_time": "2023-04-23T09:19:52.926474Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_all_images\n",
    "This function returns a list of full paths to all the images with .png or .jpg extensions in the given path. If an error occurs while fetching images, the function returns an empty list and logs the error message.\n",
    "\n",
    "### Args\n",
    "- path (str): The path to the directory containing the images.\n",
    "\n",
    "### Returns\n",
    "- list: A list of full path to all the images with .png or .jpg extensions.\n",
    "- empty list: An empty list if an error occurred while fetching images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:55.183320Z",
     "end_time": "2023-04-23T09:19:55.190139Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    \"\"\"Get all images from the given path.\n",
    "\n",
    "    Args:\n",
    "    param: image_path (str): path to the directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of full path to all the images with png or jpg extensions.\n",
    "    - empty list: an empty list if an error occurred while fetching images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # use os.walk to traverse all the subdirectories and get all images\n",
    "        return [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(path)\n",
    "                for name in files\n",
    "                if name.endswith((\".png\", \".jpg\"))]\n",
    "    except Exception as e:\n",
    "        # return an empty list and log the error message if an error occurred\n",
    "        print(f\"An error occurred while fetching images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Facebook DETR model (detr-resnet-101)\n",
    "\n",
    "The detect_with_transformers function takes an image file path as an input, then uses a pre-trained model called DEtection TRansformer (DETR) to detect objects within the image.\n",
    "\n",
    "The function first opens the input image using the Python Imaging Library (PIL) Image.open method. Then it instantiates two components of the DETR model: a DetrImageProcessor and a DetrForObjectDetection model. The DetrImageProcessor is responsible for processing the input image into a format that can be fed into the DetrForObjectDetection model. The DetrForObjectDetection model then takes the processed image and performs object detection by predicting bounding boxes and class labels for each detected object.\n",
    "\n",
    "Once the model has made its predictions, the function uses the processor.post_process_object_detection method to convert the bounding box and class label predictions into a format that is compatible with the Common Objects in Context (COCO) dataset. This conversion is necessary in order to use the COCO API, which provides a common framework for evaluating object detection models.\n",
    "\n",
    "The function then filters the detected objects by only keeping those with a confidence score above a certain threshold (0.9 in this case), and extracts the corresponding class labels. Finally, the function prints out a message for each detected object, indicating its class label, confidence score, and location within the image. The function returns a list of the detected object class labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detect_with_transformers(image):\n",
    "    \"\"\"\n",
    "    This function detects objects in an image using the DETR (DEtection TRansformer) model by Facebook.\n",
    "\n",
    "    Args:\n",
    "    image: A string representing the path of the image to be processed.\n",
    "\n",
    "    Returns:\n",
    "    A list containing the labels of the detected objects in the image.\n",
    "\n",
    "    Raises:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    #image = Image.open(image)\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-101\")\n",
    "    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-101\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # convert outputs (bounding boxes and class logits) to COCO API\n",
    "    # let's only keep detections with score > 0.9\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "    labels = []\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        labels.append(model.config.id2label[label.item()])\n",
    "        #print(\n",
    "        #    f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "        #    f\"{round(score.item(), 3)} at location {box}\"\n",
    "        #)\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:56.995659Z",
     "end_time": "2023-04-23T09:19:56.999081Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save  metadata\n",
    "\n",
    "The function save_metadata allows you to save metadata information of an image in either pickle, json, or sqlite format. The function takes four parameters: metadata, img_name, metadata_path, and save_format.\n",
    "\n",
    "metadata is a dictionary that contains the metadata information of an image. img_name is a string that represents the file name of the image. metadata_path is a string that specifies the path to the directory where the metadata will be saved. save_format is an optional parameter that specifies the format in which the metadata will be saved. The default value is pickle.\n",
    "\n",
    "The function saves the metadata in the specified format. If save_format is set to pickle, the metadata is saved in the pickle format. If save_format is set to json, the metadata is saved in the json format. If save_format is set to sqlite, the metadata is saved in the sqlite database.\n",
    "\n",
    "If an error occurs while saving the metadata, the function will print an error message indicating the image name and the error that occurred.\n",
    "\n",
    "The function does not return any value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_df(df1):\n",
    "    metadata_file = os.path.join(metadata_path, \"metadata.csv\")\n",
    "    # merge on filename column\n",
    "    df = pd.merge(df1, pd.read_csv(metadata_file), on=\"filename\")\n",
    "    df.to_csv(metadata_file, index=False)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:58.421948Z",
     "end_time": "2023-04-23T09:19:58.452584Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set tags in metadata\n",
    "This function \"update_tags\" is used to run the YOLOv3 algorithm on a set of images, update the metadata of each image with the detected labels (tags) and save the updated metadata.\n",
    "\n",
    "The function takes 3 parameters:\n",
    "\n",
    "images: a list of file paths for the images that need to be processed.\n",
    "metadata_path: a file path to the directory where the metadata files are stored.\n",
    "save_format: the format of the metadata files. Can be either 'pickle' or 'sqlite'.\n",
    "The function uses the tqdm library to display a progress bar for the image processing. For each image, the function tries to retrieve its metadata based on the save_format. If the metadata file format is 'sqlite', the function calls the read_sqlite function to retrieve the metadata. If the metadata file format is 'pickle', the function reads the metadata file directly.\n",
    "\n",
    "If the metadata already contains a \"tags\" key, it means that the image has already been processed and its metadata has been updated with the labels, so the function skips that image.\n",
    "\n",
    "The function then calls the detect function to run the YOLOv3 algorithm on the image and retrieve the labels (tags). The labels are added to the metadata under the \"tags\" key.\n",
    "\n",
    "Finally, the function calls the save_metadata function to save the updated metadata. If an error occurs while processing an image (e.g. the metadata file is not found), the function prints an error message and continues processing the next image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_tags(images):\n",
    "    # Run the YOLOv3 algorithm on each image\n",
    "    # display progress bar in the first thread only\n",
    "    metadata = {}\n",
    "    for image in tqdm(images, desc=\"Updating tags\"):\n",
    "        file_name = os.path.basename(image)\n",
    "        try:\n",
    "            file_name, ext = file_name.split(\".\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "        extensions = [\"jpg\", \"jpeg\", \"png\"]\n",
    "        if ext not in extensions:\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image)\n",
    "            # resize image to 416x416\n",
    "            image = image.resize((416, 416))\n",
    "            labels = detect_with_transformers(image)\n",
    "            image.close()\n",
    "\n",
    "            # Remove duplicates from labels\n",
    "            labels = list(set(labels))\n",
    "            # add labels to metadata\n",
    "            metadata[file_name + '.jpg'] = {\"tags\": labels}\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found: \", file_name)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Convert the metadata dictionary to a pandas dataframe\n",
    "    metadata = pd.DataFrame.from_dict(metadata, orient=\"index\")\n",
    "    # Rename the first column to filename\n",
    "    metadata = metadata.rename_axis(\"filename\").reset_index()\n",
    "    # Save the metadata\n",
    "    merge_df(metadata)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:19.224918Z",
     "end_time": "2023-04-23T09:19:19.231252Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the list of images\n",
    "images = os.listdir(images_path)\n",
    "images = [os.path.join(images_path, image) for image in images]\n",
    "\n",
    "update_tags(images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:13:55.882975Z",
     "end_time": "2023-04-23T09:17:33.963383Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Now, find dominant colors in the images\n",
    "The functions rgb_to_hex and find_dominant_colors are used to find the dominant colors in an image.\n",
    "\n",
    "The function rgb_to_hex takes in an RGB array with 3 values, and returns the hexadecimal representation of the color. This can be useful for formatting colors in a standardized way, as hexadecimal codes are widely used in web development and other applications.\n",
    "\n",
    "The function find_dominant_colors takes in an image and optional parameters k and image_processing_size. The k parameter specifies the number of dominant colors to return, with a default value of 4. The image_processing_size parameter allows you to resize the image to a smaller size, to speed up the processing, if desired.\n",
    "\n",
    "The image is first converted from BGR to RGB, and then reshaped into a list of pixels. The KMeans algorithm is used to cluster the pixels into k clusters, and the most popular clusters are identified. The color values for each of the k clusters are converted to hexadecimal representation and returned as a list, along with the percentage of the image covered by each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % (int(rgb[0]), int(rgb[1]), int(rgb[2]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:21.221769Z",
     "end_time": "2023-04-23T09:19:21.227345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_dominant_colors(image_path, k=4, downsample=2, resize=(200, 200)):\n",
    "    # Load image and convert to RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Downsample the image\n",
    "    image = cv2.resize(image, (image.shape[1] // downsample, image.shape[0] // downsample))\n",
    "\n",
    "    # Resize the image if requested\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image, resize)\n",
    "\n",
    "    # Flatten the image\n",
    "    image_flat = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "    # Cluster the pixels using KMeans and find percentage of image covered by each color\n",
    "    clt = MiniBatchKMeans(n_clusters=k, n_init=10, batch_size=100, random_state=42)\n",
    "    labels = clt.fit_predict(image_flat)\n",
    "\n",
    "    # Count the number of pixels assigned to each cluster\n",
    "    counts = np.bincount(labels)\n",
    "\n",
    "    # Calculate the percentage of pixels assigned to each cluster\n",
    "    percentages = counts / len(labels)\n",
    "\n",
    "    # Get the dominant colors\n",
    "    dominant_colors = clt.cluster_centers_\n",
    "\n",
    "    # Convert to hexadecimal format\n",
    "    dominant_colors_hex = [rgb_to_hex(color) for color in dominant_colors]\n",
    "\n",
    "    # Combine the dominant colors and their percentages into a array of tuples\n",
    "    result = list(zip(dominant_colors_hex, percentages))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:21.479056Z",
     "end_time": "2023-04-23T09:19:21.481722Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code block is used to process images and find their dominant colors. The code first retrieves all the images present in the folder specified by the images_path variable. Then, it iterates over each image, reads the metadata associated with the image and finds its dominant color if it hasn't been calculated already.\n",
    "\n",
    "For each image, the code first reads the image using OpenCV's cv2.imread() function and stores the result in the img variable. The code then reads the metadata of the image. The type of metadata file (e.g. .json, .pkl, .sqlite) is specified by the metadata_extension variable. Based on the file extension, the code reads the metadata using either read_sqlite(), json.load(), or pickle.load() functions. If the metadata file is not found, the code continues to the next iteration of the loop, but if there is an error, it prints the error message and continues to the next iteration.\n",
    "\n",
    "If the metadata does not contain information about the dominant color of the image, the code calculates the dominant color by calling the find_dominant_colors() function. The result of the find_dominant_colors() function is then added to the metadata under the key \"dominant_color\". Finally, the updated metadata is saved using the save_metadata() function, which saves the metadata to the specified location using the specified file format (metadata_extension)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_all_colors(image_path):\n",
    "    \"\"\"\n",
    "    This coroutine extracts dominant colors from all images in a directory and saves the color information in the database.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the directory where the images are stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Get a list of all images in the directory\n",
    "    img_files = get_all_images(image_path)\n",
    "    colors = []\n",
    "\n",
    "    # Create a progress bar to track the progress of processing all images\n",
    "    for img in tqdm(img_files, desc=\"Processing images (Aprox: 25 minutes\"):\n",
    "        try:\n",
    "            # Create a list of coroutines to extract metadata for all images\n",
    "            color = find_dominant_colors(img, downsample=2, resize=(100, 100))\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            continue\n",
    "\n",
    "        if color:\n",
    "            # color to string to avoid errors with quote marks\n",
    "            color = str(color)\n",
    "            # replace quotes by double quotes\n",
    "            color = color.replace(\"'\", '\"')\n",
    "            colors.append(color)\n",
    "\n",
    "    img_files = [os.path.basename(img) for img in img_files]\n",
    "\n",
    "    # Create a dataframe with the image filenames and their dominant colors\n",
    "    df = pd.DataFrame({\"filename\": img_files, \"dominant_color\": colors})\n",
    "\n",
    "    merge_df(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:27.457269Z",
     "end_time": "2023-04-23T09:19:27.463337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_all_colors(images_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T09:19:28.025316Z",
     "end_time": "2023-04-23T09:19:29.807273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
