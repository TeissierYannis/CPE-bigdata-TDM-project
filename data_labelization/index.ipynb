{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import functools\n",
    "import pathlib\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from multiprocessing import Pool\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Settings base variables and paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "config_path = os.path.join(output_path, \"config\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, config_path]\n",
    "\n",
    "# Set the base URL for the dataset\n",
    "metadata_extension = \"json\"\n",
    "\n",
    "yolo_cfg = \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\"\n",
    "yolo_weights = \"https://pjreddie.com/media/files/yolov3.weights\"\n",
    "yolo_classes = \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\"\n",
    "\n",
    "files_to_download = [\n",
    "    (yolo_cfg, os.path.join(config_path, \"yolov3.cfg\")),\n",
    "    (yolo_weights, os.path.join(config_path, \"yolov3.weights\")),\n",
    "    (yolo_classes, os.path.join(config_path, \"coco.names\")),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create folder structure\n",
    "The code creates the folder structure for the project. The folder structure is as follows:\n",
    "- output\n",
    "    - images\n",
    "    - metadata\n",
    "    - config\n",
    "\n",
    "This method creates a folder with the given path if it doesn't already exist, It also outputs a message to inform the user if the folder was created or if it already exists.\n",
    "This is useful for organizing and managing files in a project. By creating a folder to store data and resources, it keeps the working directory tidy and makes it easier to locate files. Additionally, by checking if the folder exists before creating it, it prevents the program from overwriting existing data or throwing an error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"\n",
    "    This function creates a folder at the specified path.\n",
    "    If the folder already exists, it will print a message saying so.\n",
    "    If there is an error creating the folder, it will print the error message.\n",
    "\n",
    "    Parameters:\n",
    "        :param path (str): The path of the folder to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use os.mkdir to create the folder at the specified path\n",
    "        os.mkdir(path)\n",
    "        print(f\"Folder {path} created\")\n",
    "    except FileExistsError:\n",
    "        # If the folder already exists, print a message saying so\n",
    "        print(f\"Folder {path} already exists\")\n",
    "    except Exception as e:\n",
    "        # If there is an error creating the folder, print the error message\n",
    "        print(f\"Error creating folder {path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the folder structure\n",
    "This method initializes a list of folders by calling the create_folder method for each folder in the list.\n",
    "The purpose of this method is to make sure that all necessary folders exist before the program continues its execution.\n",
    "If a folder does not exist, the create_folder method will create it. If a folder already exists, the method will simply print a message indicating that the folder already exists. In case of any other error, the method will print the error message."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def init_folder(folder_names: list):\n",
    "    for folder_name in folder_names:\n",
    "        create_folder(folder_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../output already exists\n",
      "Folder ../output/images already exists\n",
      "Folder ../output/metadata already exists\n",
      "Folder ../output/config already exists\n"
     ]
    }
   ],
   "source": [
    "init_folder(list_of_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define methods for downloading the necessary files for yolo\n",
    "The following code block is a method to download a file from a given URL and save it to a specified filename.\n",
    "The method starts by creating a session (s = requests.Session()) and then mounting it to the URL (s.mount(url, requests.adapters.HTTPAdapter(max_retries=3))). This sets the maximum number of retries to 3 if the connection to the URL fails.\n",
    "Then, the method makes a GET request to the URL (r = s.get(url, stream=True, allow_redirects=True)) and checks if it returns a successful response (r.raise_for_status()). If there was an HTTP error during the request, the error message is printed (print(f\"HTTP error occurred while downloading dataset: {e}\")).\n",
    "The method also checks the file size specified in the response headers and assigns it to the variable file_size (file_size = int(r.headers.get(‘Content-Length’, 0))). If the file size is 0, a default value of “(Unknown total file size)” is assigned to the variable desc; otherwise, the variable desc is left empty.\n",
    "Next, the method resolves the file path and creates a directory if it doesn’t already exist (path.parent.mkdir(parents=True, exist_ok=True)). The method then creates a tqdm progress bar to show the download progress (with tqdm.tqdm(total=file_size, unit=‘B’, unit_scale=True, desc=desc) as pbar:).\n",
    "Finally, the method writes the contents of the file to disk in chunks (for chunk in r.iter_content(chunk_size=1024):), updating the progress bar for each chunk that is written to disk (pbar.update(len(chunk))). If an error occurred during the download, a message with the error is printed (print(f\"Error occurred while downloading dataset: {e}\")). The file path is returned when the method is finished."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def download(url, filename):\n",
    "    \"\"\"\n",
    "    This download a file from a given URL and save it to a specified filename.\n",
    "\n",
    "    Parameters:\n",
    "        :param url (str): The URL of the file to be downloaded.\n",
    "        :param filename (str): The filename to save the file as.\n",
    "\n",
    "    Returns:\n",
    "    path (str): The path of the downloaded file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a session object to persist the state of connection\n",
    "        s = requests.Session()\n",
    "        # Retry connecting to the URL up to 3 times\n",
    "        s.mount(url, requests.adapters.HTTPAdapter(max_retries=3))\n",
    "        # Send a GET request to the URL to start the download\n",
    "        r = s.get(url, stream=True, allow_redirects=True)\n",
    "        # Raise an error if the response is not 200 OK\n",
    "        r.raise_for_status()\n",
    "        # Get the file size from the Content-Length header, default to 0 if not present\n",
    "        file_size = int(r.headers.get('Content-Length', 0))\n",
    "        # Get the absolute path to the target file\n",
    "        path = pathlib.Path(filename).expanduser().resolve()\n",
    "        # Create parent directories if they don't exist\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Set the description to display while downloading, \"(Unknown total file size)\" if file size is 0\n",
    "        desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "        # Enable decoding the response content\n",
    "        r.raw.read = functools.partial(r.raw.read, decode_content=True)\n",
    "        # Use tqdm to display the download progress\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=desc) as pbar:\n",
    "            # Open the target file in binary write mode\n",
    "            with path.open(\"wb\") as f:\n",
    "                # Write each chunk of data from the response to the file\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        # Return the path to the downloaded file\n",
    "        return path\n",
    "    # Handle HTTP error if the response is not 200 OK\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred while downloading dataset: {e}\")\n",
    "    # Handle any other exceptions that might occur while downloading the file\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while downloading dataset: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Download the yolov3 files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are downloaded\n"
     ]
    }
   ],
   "source": [
    "for url, filename in files_to_download:\n",
    "    # check if the file already exists\n",
    "    if not pathlib.Path(filename).exists():\n",
    "        # download the file\n",
    "        download(url, filename)\n",
    "\n",
    "print(\"All files are downloaded\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define methods to get all the image paths\n",
    "The get_all_images method is used to retrieve all images present in the specified image path. It uses the os.walk function to traverse through all subdirectories within the image path and collects the file names that end with either '.png' or '.jpg' extensions. The full path of each image is then generated by joining the root directory and the file name. The method returns a list of all images' full paths. In case of any error, an error message is printed and an empty list is returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    \"\"\"Get all images from the given path.\n",
    "\n",
    "    Args:\n",
    "    param: image_path (str): path to the directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of full path to all the images with png or jpg extensions.\n",
    "    - empty list: an empty list if an error occurred while fetching images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # use os.walk to traverse all the subdirectories and get all images\n",
    "        return [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(path)\n",
    "                for name in files\n",
    "                if name.endswith((\".png\", \".jpg\"))]\n",
    "    except Exception as e:\n",
    "        # return an empty list and log the error message if an error occurred\n",
    "        print(f\"An error occurred while fetching images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags: 100%|██████████| 100/100 [00:00<00:00, 10378.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000563629 jpg\n",
      "000000002746 jpg\n",
      "000000109161 jpg\n",
      "000000300857 jpg\n",
      "000000052171 jpg\n",
      "000000023788 jpg\n",
      "000000179486 jpg\n",
      "000000483911 jpg\n",
      "000000469310 jpg\n",
      "000000368241 jpg\n",
      "000000348191 jpg\n",
      "000000479665 jpg\n",
      "000000350906 jpg\n",
      "000000574433 jpg\n",
      "000000210488 jpg\n",
      "000000481860 jpg\n",
      "000000230758 jpg\n",
      "000000083258 jpg\n",
      "000000271062 jpg\n",
      "000000454091 jpg\n",
      "000000520062 jpg\n",
      "000000462523 jpg\n",
      "000000078954 jpg\n",
      "000000472730 jpg\n",
      "000000576224 jpg\n",
      "000000328895 jpg\n",
      "000000146138 jpg\n",
      "000000319490 jpg\n",
      "000000512946 jpg\n",
      "000000161587 jpg\n",
      "000000097205 jpg\n",
      "000000439269 jpg\n",
      "000000346194 jpg\n",
      "000000248813 jpg\n",
      "000000374898 jpg\n",
      "000000501084 jpg\n",
      "000000257933 jpg\n",
      "000000365995 jpg\n",
      "000000051336 jpg\n",
      "000000561770 jpg\n",
      "000000353599 jpg\n",
      "000000517180 jpg\n",
      "000000142438 jpg\n",
      "000000164399 jpg\n",
      "000000276043 jpg\n",
      "000000071958 jpg\n",
      "000000380919 jpg\n",
      "000000366522 jpg\n",
      "000000023978 jpg\n",
      "000000098650 jpg\n",
      "000000089985 jpg\n",
      "000000532328 jpg\n",
      "000000053247 jpg\n",
      "000000348807 jpg\n",
      "000000108257 jpg\n",
      "000000128187 jpg\n",
      "000000321669 jpg\n",
      "000000272231 jpg\n",
      "000000087764 jpg\n",
      "000000111712 jpg\n",
      "000000535453 jpg\n",
      "000000274898 jpg\n",
      "000000177497 jpg\n",
      "000000244783 jpg\n",
      "000000523231 jpg\n",
      "000000264453 jpg\n",
      "000000440966 jpg\n",
      "000000362988 jpg\n",
      "000000388389 jpg\n",
      "000000165093 jpg\n",
      "000000277349 jpg\n",
      "000000465516 jpg\n",
      "000000059018 jpg\n",
      "000000026814 jpg\n",
      "000000173829 jpg\n",
      "000000537244 jpg\n",
      "000000373885 jpg\n",
      "000000425132 jpg\n",
      "000000342480 jpg\n",
      "000000333279 jpg\n",
      "000000153521 jpg\n",
      "000000473374 jpg\n",
      "000000352693 jpg\n",
      "000000293965 jpg\n",
      "000000405584 jpg\n",
      "000000389929 jpg\n",
      "000000017377 jpg\n",
      "000000313817 jpg\n",
      "000000041131 jpg\n",
      "000000161593 jpg\n",
      "000000554907 jpg\n",
      "000000360621 jpg\n",
      "000000141643 jpg\n",
      "000000111074 jpg\n",
      "000000043726 jpg\n",
      "000000242494 jpg\n",
      "000000468754 jpg\n",
      "000000369163 jpg\n",
      "000000456862 jpg\n",
      "000000493280 jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_labels(label_path):\n",
    "    # check if the file exists\n",
    "    if not pathlib.Path(label_path).exists():\n",
    "        print(f\"Label file {label_path} does not exist\")\n",
    "        return []\n",
    "    return open(label_path).read().strip().split(\"\\n\")\n",
    "\n",
    "def get_colors(labels):\n",
    "    return np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "def detect(\n",
    "        path_name,\n",
    "        output_folder = \"../output/images_labelized/\",\n",
    "        label_path = \"../output/config/coco.names\",\n",
    "        weights_path = \"../output/config/yolov3.weights\",\n",
    "        config_path = \"../output/config/yolov3.cfg\",\n",
    "        CONFIDENCE = 0.5,\n",
    "        SCORE_THRESHOLD = 0.5,\n",
    "        IOU_THRESHOLD = 0.5\n",
    "):\n",
    "    labels = get_labels(label_path)\n",
    "    colors = get_colors(labels)\n",
    "\n",
    "    # load the COCO class labels our YOLO model was trained on\n",
    "    net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "    image = cv2.imread(path_name)\n",
    "    file_name = os.path.basename(path_name)\n",
    "    filename, ext = file_name.split(\".\")\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    # create 4D blob\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # sets the blob as the input of the network\n",
    "    net.setInput(blob)\n",
    "    # get all the layer names\n",
    "    ln = net.getLayerNames()\n",
    "    try:\n",
    "        ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except IndexError:\n",
    "        # in case getUnconnectedOutLayers() returns 1D array when CUDA isn't available\n",
    "        ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # feed forward (inference) and get the network output\n",
    "    # measure how much it took in seconds\n",
    "    layer_outputs = net.forward(ln)\n",
    "\n",
    "    font_scale = 1\n",
    "    thickness = 1\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    text_labels = []\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layer_outputs:\n",
    "        # loop over each of the object detections\n",
    "        for detection in output:\n",
    "            # extract the class id (label) and confidence (as a probability) of\n",
    "            # the current object detection\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # discard out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            if confidence > CONFIDENCE:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update our list of bounding box coordinates, confidences,\n",
    "                # and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in range(len(boxes)):\n",
    "            text_labels.append(labels[class_ids[i]])\n",
    "            # extract the bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            # draw a bounding box rectangle and label on the image\n",
    "            color = [int(c) for c in colors[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "            text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            # calculate text width & height to draw the transparent boxes as background of the text\n",
    "            (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "            text_offset_x = x\n",
    "            text_offset_y = y - 5\n",
    "            box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "            # add opacity (transparency to the box)\n",
    "            image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "            # now put the text (label: confidence %)\n",
    "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_folder, filename + \".\" + ext), image)\n",
    "\n",
    "    return text_labels\n",
    "\n",
    "\n",
    "\n",
    "def update_tags(images):\n",
    "    # Run the YOLOv3 algorithm on each image\n",
    "    # display progress bar in the first thread only\n",
    "    for image in tqdm(images, desc=\"Updating tags\"):\n",
    "        # read pickle file from ../output/metadata/file_name.pkl\n",
    "        file_name = os.path.basename(image)\n",
    "        file_name, ext = file_name.split(\".\")\n",
    "        print(file_name, ext)\n",
    "        try:\n",
    "            with open(os.path.join(\"../output/metadata\", file_name + \".\" + metadata_extension), \"rb\") as f:\n",
    "                if metadata_extension == \"json\":\n",
    "                    metadata = json.load(f)\n",
    "                else:\n",
    "                    metadata = pickle.load(f)\n",
    "\n",
    "            if \"tags\" in metadata:\n",
    "                continue\n",
    "\n",
    "            labels = detect(image)\n",
    "\n",
    "            # Remove duplicates from labels\n",
    "            labels = list(set(labels))\n",
    "            # add labels to metadata\n",
    "            metadata[\"tags\"] = labels\n",
    "            # save metadata to pickle file\n",
    "            with open(os.path.join(\"../output/metadata\", file_name + \".\" + metadata_extension), \"wb\") as f:\n",
    "                if metadata_extension == \"json\":\n",
    "                    json.dump(metadata, f)\n",
    "                else:\n",
    "                    pickle.dump(metadata, f)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found: \", file_name)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            continue\n",
    "\n",
    "\n",
    "# Get the list of images\n",
    "images = os.listdir(\"../output/images\")\n",
    "images = [os.path.join(\"../output/images\", image) for image in images]\n",
    "\n",
    "update_tags(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, find dominant colors in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding dominant colors:   0%|          | 0/100 [00:00<?, ?it/s][ WARN:0@25.931] global loadsave.cpp:244 findDecoder imread_('../output/images/../output/images/000000563629.jpg'): can't open/read file: check file path/integrity\n",
      "Finding dominant colors:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/opencv-cn/GHA-OCV-3/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m tqdm(images, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinding dominant colors\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     45\u001B[0m     img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../output/images/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m image)\n\u001B[0;32m---> 46\u001B[0m     dominant_color \u001B[38;5;241m=\u001B[39m \u001B[43mfind_dominant_colors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;66;03m# save the image in the folder \"../images_labelized\"\u001B[39;00m\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mprint\u001B[39m(dominant_color)\n",
      "Cell \u001B[0;32mIn[12], line 22\u001B[0m, in \u001B[0;36mfind_dominant_colors\u001B[0;34m(image, k, image_processing_size)\u001B[0m\n\u001B[1;32m     20\u001B[0m     image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(image, image_processing_size, interpolation\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mINTER_AREA)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Convert to RGB from BGR\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvtColor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOLOR_BGR2RGB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Reshape the image to be a list of pixels\u001B[39;00m\n\u001B[1;32m     24\u001B[0m image \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mreshape((image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m3\u001B[39m))\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.7.0) /Users/opencv-cn/GHA-OCV-3/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Convert RGB to HEX (RGB is an array of 3 values)\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % (int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
    "\n",
    "\n",
    "# Find 4 dominant colors in the image\n",
    "def find_dominant_colors(image, k=4, image_processing_size=None):\n",
    "    # Need to return a list of 4 colors\n",
    "    assert k <= 4, \"k needs to be less than or equal to 4\"\n",
    "    # Resize image if new dims provided, just to speed up processing\n",
    "    if image_processing_size is not None:\n",
    "        image = cv2.resize(image, image_processing_size, interpolation=cv2.INTER_AREA)\n",
    "    # Convert to RGB from BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Reshape the image to be a list of pixels\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    # Cluster and assign labels to the pixels\n",
    "    clt = KMeans(n_clusters=k, n_init=10)\n",
    "    labels = clt.fit_predict(image)\n",
    "    # Count labels to find most popular\n",
    "    label_counts = Counter(labels)\n",
    "    # Subset out most popular centroid\n",
    "    dominant_colors = [clt.cluster_centers_[i] for i in label_counts.keys()]\n",
    "    # For each color, convert to hex and append to list\n",
    "    dominant_colors = [rgb_to_hex(color) for color in dominant_colors]\n",
    "\n",
    "    # find percent of each color in the image\n",
    "    percent = [int((label_counts[i] / len(labels)) * 100) for i in label_counts.keys()]\n",
    "\n",
    "    # return the 4 dominant colors and their percent\n",
    "    dominant_colors = list(zip(dominant_colors, percent))\n",
    "    return dominant_colors\n",
    "\n",
    "\n",
    "# For each image in the folder \"../images_labelized\"\n",
    "for image in tqdm(images, desc=\"Finding dominant colors\"):\n",
    "    img = cv2.imread(\"../output/images/\" + image)\n",
    "    dominant_color = find_dominant_colors(img)\n",
    "    # save the image in the folder \"../images_labelized\"\n",
    "    print(dominant_color)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of the dominant colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Creating color pie charts\"):\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"dominant_color\" in line:\n",
    "                # Get the dominant color\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                # Create the pie chart\n",
    "                labels = [i[0] for i in dominant_color]\n",
    "                sizes = [i[1] for i in dominant_color]\n",
    "                fig1, ax1 = plt.subplots()\n",
    "                # change the colors of the pie chart\n",
    "                colors = [i[0] for i in dominant_color]\n",
    "                ax1.pie(sizes, colors=colors, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "                ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "                # Save the pie chart in the folder \"../histogram\"\n",
    "                plt.savefig(\"../output/histogram/\" + image.split(\".\")[0] + \".png\")\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the images by multiple data\n",
    "# there is multiple ways to group the images (in the folder labels, we can find the label, the dominant color), in metadata folder, we have the metadata of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Create a dataframe with the metadata of each image, one pikle file per image\n",
    "df = pd.DataFrame(columns=[\"image\", \"label\", \"dominant_color\", \"metadata\"])\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Creating dataframe\"):\n",
    "    # Example of lines :\n",
    "    # label:person,posX:113,posY:120,width:134,height:360,confidence:0.9987273216247559%\n",
    "    # label:horse,posX:325,posY:187,width:282,height:270,confidence:0.9985314607620239%\n",
    "    # label:handbag,posX:143,posY:385,width:82,height:91,confidence:0.5130287408828735%\n",
    "    # dominant_color:[('#3e4542', 37), ('#6d6f6d', 22), ('#a6a4a7', 9), ('#191b1d', 30)]\n",
    "\n",
    "    # Get the label\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        # it's possible to have more than one label per image\n",
    "        label = \"\"\n",
    "        dominant_color = \"\"\n",
    "\n",
    "        for line in f:\n",
    "            if \"label\" in line:\n",
    "                raw_label = line.split(\":\")[1]\n",
    "                # cut as the first , is the end of the label\n",
    "                label += raw_label.split(\",\")[0]\n",
    "                label += \",\"\n",
    "            if \"dominant_color\" in line:\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                dominant_color = [i[0] for i in dominant_color]\n",
    "                dominant_color = \",\".join(dominant_color)\n",
    "        # Get the metadata\n",
    "        with open(\"../output/metadata/\" + image.split(\".\")[0] + \".pickle\", \"rb\") as f:\n",
    "            metadata = pickle.load(f)\n",
    "            # Convert metadata to string : key:value,key:value\n",
    "            metadata = \",\".join([f\"{key}:{value}\" for key, value in metadata.items()])\n",
    "\n",
    "        # Add the image to the dataframe by using panda.concat\n",
    "        df = pd.concat([df, pd.DataFrame([[image, label, dominant_color, metadata]],\n",
    "                                         columns=[\"image\", \"label\", \"dominant_color\", \"metadata\"])])\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(\"../output/dataframe.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the images by label\n",
    "import os\n",
    "\n",
    "# Create a folder for each label\n",
    "for label in df[\"label\"].unique():\n",
    "    if not os.path.exists(\"../output/grouped_by_label/\" + label):\n",
    "        os.makedirs(\"../output/grouped_by_label/\" + label)\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by label\"):\n",
    "    # Get the label\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"label\" in line:\n",
    "                label = line.split(\":\")[1]\n",
    "                label = label.split(\",\")[0]\n",
    "    # Copy the image in the folder \"../grouped_by_label\"\n",
    "    os.system(f\"cp ../output/images/{image} ../output/grouped_by_label/{label}/{image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group image by dominant color, take the color one by one and create a folder for each color\n",
    "for colors in df[\"dominant_color\"].unique():\n",
    "    # split colors by , to get individual colors\n",
    "    colors = colors.split(\",\")\n",
    "    for color in colors:\n",
    "        if not os.path.exists(\"../output/grouped_by_dominant_color/\" + color):\n",
    "            os.makedirs(\"../output/grouped_by_dominant_color/\" + color)\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by dominant color\"):\n",
    "    # Get the dominant color\n",
    "    with open(\"../output/labels/\" + image.split(\".\")[0] + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"dominant_color\" in line:\n",
    "                dominant_color = line.split(\":\")[1]\n",
    "                dominant_color = eval(dominant_color)\n",
    "                dominant_color = [i[0] for i in dominant_color]\n",
    "                dominant_color = \",\".join(dominant_color)\n",
    "                # split colors by , to get individual colors\n",
    "                dominant_color = dominant_color.split(\",\")\n",
    "                for color in dominant_color:\n",
    "                    # Copy the image in the folder \"../grouped_by_dominant_color\"\n",
    "                    os.system(f\"cp ../output/images/{image} ../output/grouped_by_dominant_color/{color}/{image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all metadata and group by similar metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metadata in df[\"metadata\"].unique():\n",
    "    # Metadata are in string formated as key:value,key:value\n",
    "    # Split the metadata by , to get individual metadata\n",
    "    metadata = metadata.split(\",\")\n",
    "    for meta in metadata:\n",
    "        try:\n",
    "            # Split the metadata by : to get the key and the value\n",
    "            key, value = meta.split(\":\")\n",
    "            if not os.path.exists(f\"../output/grouped_by_metadata/{key}/{value}\"):\n",
    "                os.makedirs(f\"../output/grouped_by_metadata/{key}/{value}\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# For each image in the folder \"../images_labelized\" get the line that contains the dominant color\n",
    "for image in tqdm(images, desc=\"Grouping images by metadata\"):\n",
    "    # Get the metadata\n",
    "    with open(\"../output/metadata/\" + image.split(\".\")[0] + \".pickle\", \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "        # Convert metadata to string : key:value,key:value\n",
    "        metadata = \",\".join([f\"{key}:{value}\" for key, value in metadata.items()])\n",
    "        # Split the metadata by , to get individual metadata\n",
    "        metadata = metadata.split(\",\")\n",
    "        for meta in metadata:\n",
    "            try:\n",
    "                # Split the metadata by : to get the key and the value\n",
    "                key, value = meta.split(\":\")\n",
    "            except:\n",
    "                continue\n",
    "            # Copy the image in the folder \"../grouped_by_metadata\"\n",
    "            os.system(f\"cp ../output/images/{image} ../output/grouped_by_metadata/{key}/{value}/{image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
