{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "This code imports several libraries in order to perform some data processing tasks. The libraries used are:\n",
    "\n",
    "requests: A library that is used to make HTTP requests to web servers and retrieve the response data.\n",
    "\n",
    "functools: A module that provides several tools for functional programming in Python, including tools for working with higher-order functions.\n",
    "\n",
    "pathlib: A library that provides an object-oriented interface for working with files and directories on your system.\n",
    "\n",
    "pickle: A library that provides a way to serialize and deserialize Python objects to and from binary data streams.\n",
    "\n",
    "os: A library that provides a way to interact with the operating system, such as reading and writing files, checking the current directory, and executing shell commands.\n",
    "\n",
    "sqlite3: A library that provides a way to interact with SQLite databases, including creating and executing SQL queries.\n",
    "\n",
    "json: A library that provides a way to encode and decode JSON data.\n",
    "\n",
    "cv2: A library that provides an interface to the OpenCV computer vision library, allowing you to perform tasks such as image processing, object detection, and video analysis.\n",
    "\n",
    "numpy: A library that provides support for arrays and matrices, and includes functions for linear algebra, random number generation, and Fourier transforms.\n",
    "\n",
    "sklearn.cluster.KMeans: A class from the scikit-learn machine learning library that implements the k-means clustering algorithm.\n",
    "\n",
    "collections.Counter: A class from the collections module that provides a convenient way to count elements in a collection, such as a list or a dictionary.\n",
    "\n",
    "tqdm: A library that provides a convenient way to display progress bars for long-running tasks.\n",
    "\n",
    "With these libraries, you should be able to perform a wide range of data processing and analysis tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import requests\n",
    "import functools\n",
    "import pathlib\n",
    "import pickle\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Settings base variables and paths\n",
    "This code sets up the file structure and URL's for a project that uses data from an image dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "config_path = os.path.join(output_path, \"config\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, config_path]\n",
    "\n",
    "# Set the base URL for the dataset\n",
    "metadata_extension = \"sqlite\"\n",
    "\n",
    "yolo_cfg = \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\"\n",
    "yolo_weights = \"https://pjreddie.com/media/files/yolov3.weights\"\n",
    "yolo_classes = \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\"\n",
    "\n",
    "files_to_download = [\n",
    "    (yolo_cfg, os.path.join(config_path, \"yolov3.cfg\")),\n",
    "    (yolo_weights, os.path.join(config_path, \"yolov3.weights\")),\n",
    "    (yolo_classes, os.path.join(config_path, \"coco.names\")),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create folder structure\n",
    "The code creates the folder structure for the project. The folder structure is as follows:\n",
    "- output\n",
    "    - images\n",
    "    - metadata\n",
    "    - config\n",
    "\n",
    "This method creates a folder with the given path if it doesn't already exist, It also outputs a message to inform the user if the folder was created or if it already exists.\n",
    "This is useful for organizing and managing files in a project. By creating a folder to store data and resources, it keeps the working directory tidy and makes it easier to locate files. Additionally, by checking if the folder exists before creating it, it prevents the program from overwriting existing data or throwing an error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"\n",
    "    This function creates a folder at the specified path.\n",
    "    If the folder already exists, it will print a message saying so.\n",
    "    If there is an error creating the folder, it will print the error message.\n",
    "\n",
    "    Parameters:\n",
    "        :param path (str): The path of the folder to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use os.mkdir to create the folder at the specified path\n",
    "        os.mkdir(path)\n",
    "        print(f\"Folder {path} created\")\n",
    "    except FileExistsError:\n",
    "        # If the folder already exists, print a message saying so\n",
    "        print(f\"Folder {path} already exists\")\n",
    "    except Exception as e:\n",
    "        # If there is an error creating the folder, print the error message\n",
    "        print(f\"Error creating folder {path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the folder structure\n",
    "This method initializes a list of folders by calling the create_folder method for each folder in the list.\n",
    "The purpose of this method is to make sure that all necessary folders exist before the program continues its execution.\n",
    "If a folder does not exist, the create_folder method will create it. If a folder already exists, the method will simply print a message indicating that the folder already exists. In case of any other error, the method will print the error message."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def init_folder(folder_names: list):\n",
    "    for folder_name in folder_names:\n",
    "        create_folder(folder_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../output already exists\n",
      "Folder ../output/images already exists\n",
      "Folder ../output/metadata already exists\n",
      "Folder ../output/config already exists\n"
     ]
    }
   ],
   "source": [
    "init_folder(list_of_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define methods for downloading the necessary files for yolo\n",
    "The following code block is a method to download a file from a given URL and save it to a specified filename.\n",
    "The method starts by creating a session (s = requests.Session()) and then mounting it to the URL (s.mount(url, requests.adapters.HTTPAdapter(max_retries=3))). This sets the maximum number of retries to 3 if the connection to the URL fails.\n",
    "Then, the method makes a GET request to the URL (r = s.get(url, stream=True, allow_redirects=True)) and checks if it returns a successful response (r.raise_for_status()). If there was an HTTP error during the request, the error message is printed (print(f\"HTTP error occurred while downloading dataset: {e}\")).\n",
    "The method also checks the file size specified in the response headers and assigns it to the variable file_size (file_size = int(r.headers.get(‘Content-Length’, 0))). If the file size is 0, a default value of “(Unknown total file size)” is assigned to the variable desc; otherwise, the variable desc is left empty.\n",
    "Next, the method resolves the file path and creates a directory if it doesn’t already exist (path.parent.mkdir(parents=True, exist_ok=True)). The method then creates a tqdm progress bar to show the download progress (with tqdm.tqdm(total=file_size, unit=‘B’, unit_scale=True, desc=desc) as pbar:).\n",
    "Finally, the method writes the contents of the file to disk in chunks (for chunk in r.iter_content(chunk_size=1024):), updating the progress bar for each chunk that is written to disk (pbar.update(len(chunk))). If an error occurred during the download, a message with the error is printed (print(f\"Error occurred while downloading dataset: {e}\")). The file path is returned when the method is finished."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def download(url, filename):\n",
    "    \"\"\"\n",
    "    This download a file from a given URL and save it to a specified filename.\n",
    "\n",
    "    Parameters:\n",
    "        :param url (str): The URL of the file to be downloaded.\n",
    "        :param filename (str): The filename to save the file as.\n",
    "\n",
    "    Returns:\n",
    "    path (str): The path of the downloaded file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a session object to persist the state of connection\n",
    "        s = requests.Session()\n",
    "        # Retry connecting to the URL up to 3 times\n",
    "        s.mount(url, requests.adapters.HTTPAdapter(max_retries=3))\n",
    "        # Send a GET request to the URL to start the download\n",
    "        r = s.get(url, stream=True, allow_redirects=True)\n",
    "        # Raise an error if the response is not 200 OK\n",
    "        r.raise_for_status()\n",
    "        # Get the file size from the Content-Length header, default to 0 if not present\n",
    "        file_size = int(r.headers.get('Content-Length', 0))\n",
    "        # Get the absolute path to the target file\n",
    "        path = pathlib.Path(filename).expanduser().resolve()\n",
    "        # Create parent directories if they don't exist\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Set the description to display while downloading, \"(Unknown total file size)\" if file size is 0\n",
    "        desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "        # Enable decoding the response content\n",
    "        r.raw.read = functools.partial(r.raw.read, decode_content=True)\n",
    "        # Use tqdm to display the download progress\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=desc) as pbar:\n",
    "            # Open the target file in binary write mode\n",
    "            with path.open(\"wb\") as f:\n",
    "                # Write each chunk of data from the response to the file\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        # Return the path to the downloaded file\n",
    "        return path\n",
    "    # Handle HTTP error if the response is not 200 OK\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred while downloading dataset: {e}\")\n",
    "    # Handle any other exceptions that might occur while downloading the file\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while downloading dataset: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download the yolov3 files if they don't already exist\n",
    "This code block downloads the yolov3 files if they don't already exist. The files_to_download list contains tuples of the URL and the filename to save the file as. The method iterates through the list and checks if the file already exists. If the file doesn't exist, the download method is called to download the file. If the file already exists, a message is printed indicating that the file already exists."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99.6M/99.6M [00:02<00:00, 47.6MB/s]\n",
      "100%|██████████| 95.6M/95.6M [00:02<00:00, 39.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for url, filename in files_to_download:\n",
    "    # check if the file already exists\n",
    "    if not pathlib.Path(filename).exists():\n",
    "        # download the file\n",
    "        download(url, filename)\n",
    "\n",
    "print(\"All files are downloaded\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define methods to get all the image paths\n",
    "The get_all_images method is used to retrieve all images present in the specified image path. It uses the os.walk function to traverse through all subdirectories within the image path and collects the file names that end with either '.png' or '.jpg' extensions. The full path of each image is then generated by joining the root directory and the file name. The method returns a list of all images' full paths. In case of any error, an error message is printed and an empty list is returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    \"\"\"Get all images from the given path.\n",
    "\n",
    "    Args:\n",
    "    param: image_path (str): path to the directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of full path to all the images with png or jpg extensions.\n",
    "    - empty list: an empty list if an error occurred while fetching images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # use os.walk to traverse all the subdirectories and get all images\n",
    "        return [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(path)\n",
    "                for name in files\n",
    "                if name.endswith((\".png\", \".jpg\"))]\n",
    "    except Exception as e:\n",
    "        # return an empty list and log the error message if an error occurred\n",
    "        print(f\"An error occurred while fetching images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yolo for tagging\n",
    "\n",
    "This part of contains code for object detection using YOLO (You Only Look Once) deep learning architecture. The code is implemented using OpenCV and Python.\n",
    "\n",
    "The code contains three functions get_labels, get_colors, and detect that work together to perform the object detection task.\n",
    "\n",
    "get_labels takes the path to a label file as input and returns the labels in the file. If the label file does not exist, it prints a message and returns an empty list.\n",
    "\n",
    "get_colors generates random RGB color codes for each label in the input list.\n",
    "\n",
    "detect is the main function that performs the object detection task. It takes several parameters such as the path to the image, the paths to the pre-trained model files (weights, configuration, and labels), and several hyperparameters (confidence, score threshold, and IOU threshold).\n",
    "\n",
    "The function first loads the labels using the get_labels function and generates random colors for each label using the get_colors function. Then, it loads the pre-trained YOLO model using OpenCV's cv2.dnn.readNetFromDarknet method.\n",
    "\n",
    "The input image is then passed through the network, and the output is obtained by calling the net.forward method. The output is then processed to get the class IDs, confidences, and bounding box coordinates for each detected object.\n",
    "\n",
    "Finally, the bounding boxes are drawn on the image, and the labels and confidences scores are displayed on the image. The output image is saved to the specified output folder.\n",
    "\n",
    "In summary, this code provides an implementation of the YOLO object detection algorithm using OpenCV and Python."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n",
    "def get_labels(label_path):\n",
    "    # check if the file exists\n",
    "    if not pathlib.Path(label_path).exists():\n",
    "        print(f\"Label file {label_path} does not exist\")\n",
    "        return []\n",
    "    return open(label_path).read().strip().split(\"\\n\")\n",
    "\n",
    "def get_colors(labels):\n",
    "    return np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "def detect(\n",
    "        path_name,\n",
    "        output_folder=\"../output/images_labelized/\",\n",
    "        label_path=\"../output/config/coco.names\",\n",
    "        weights_path=\"../output/config/yolov3.weights\",\n",
    "        config_path=\"../output/config/yolov3.cfg\",\n",
    "        CONFIDENCE=0.5,\n",
    "        SCORE_THRESHOLD=0.5,\n",
    "        IOU_THRESHOLD=0.5\n",
    "):\n",
    "    labels = get_labels(label_path)\n",
    "    colors = get_colors(labels)\n",
    "\n",
    "    # load the COCO class labels our YOLO model was trained on\n",
    "    net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "    image = cv2.imread(path_name)\n",
    "    file_name = os.path.basename(path_name)\n",
    "    filename, ext = file_name.split(\".\")\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    # create 4D blob\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # sets the blob as the input of the network\n",
    "    net.setInput(blob)\n",
    "    # get all the layer names\n",
    "    ln = net.getLayerNames()\n",
    "    print(ln)\n",
    "    try:\n",
    "        ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except IndexError:\n",
    "        # in case getUnconnectedOutLayers() returns 1D array when CUDA isn't available\n",
    "        ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # feed forward (inference) and get the network output\n",
    "    # measure how much it took in seconds\n",
    "    layer_outputs = net.forward(ln)\n",
    "\n",
    "    font_scale = 1\n",
    "    thickness = 1\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    text_labels = []\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layer_outputs:\n",
    "        # loop over each of the object detections\n",
    "        for detection in output:\n",
    "            # extract the class id (label) and confidence (as a probability) of\n",
    "            # the current object detection\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # discard out weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            if confidence > CONFIDENCE:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update our list of bounding box coordinates, confidences,\n",
    "                # and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in range(len(boxes)):\n",
    "            text_labels.append(labels[class_ids[i]])\n",
    "            # extract the bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            # draw a bounding box rectangle and label on the image\n",
    "            color = [int(c) for c in colors[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "            text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            # calculate text width & height to draw the transparent boxes as background of the text\n",
    "            (text_width, text_height) = \\\n",
    "            cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "            text_offset_x = x\n",
    "            text_offset_y = y - 5\n",
    "            box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "            # add opacity (transparency to the box)\n",
    "            image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "            # now put the text (label: confidence %)\n",
    "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_folder, filename + \".\" + ext), image)\n",
    "\n",
    "    return text_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save  metadata\n",
    "\n",
    "The function save_metadata allows you to save metadata information of an image in either pickle, json, or sqlite format. The function takes four parameters: metadata, img_name, metadata_path, and save_format.\n",
    "\n",
    "metadata is a dictionary that contains the metadata information of an image. img_name is a string that represents the file name of the image. metadata_path is a string that specifies the path to the directory where the metadata will be saved. save_format is an optional parameter that specifies the format in which the metadata will be saved. The default value is pickle.\n",
    "\n",
    "The function saves the metadata in the specified format. If save_format is set to pickle, the metadata is saved in the pickle format. If save_format is set to json, the metadata is saved in the json format. If save_format is set to sqlite, the metadata is saved in the sqlite database.\n",
    "\n",
    "If an error occurs while saving the metadata, the function will print an error message indicating the image name and the error that occurred.\n",
    "\n",
    "The function does not return any value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def save_metadata(metadata, img_name, metadata_path, save_format='pickle'):\n",
    "    \"\"\"\n",
    "    This function saves the metadata information of an image in either pickle or json format.\n",
    "    Parameters:\n",
    "    metadata (dict): The metadata information of an image.\n",
    "    img_name (str): The file name of the image.\n",
    "    metadata_path (str): The path to the directory where the metadata will be saved.\n",
    "    save_format (str): The format in which the metadata will be saved. The default is 'pickle'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if save_format == 'pickle':\n",
    "            # save the metadata in pickle format\n",
    "            with open(os.path.join(metadata_path, os.path.splitext(os.path.basename(img_name))[0] + '.pickle'),\n",
    "                      'wb') as f:\n",
    "                pickle.dump(metadata, f)\n",
    "        elif save_format == 'json':\n",
    "            # save the metadata in json format\n",
    "            with open(os.path.join(metadata_path, os.path.splitext(os.path.basename(img_name))[0] + '.json'), 'w') as f:\n",
    "                json.dump(metadata, f)\n",
    "        elif save_format == 'sqlite':\n",
    "            # Get only the file name of the image\n",
    "            img_name = os.path.basename(img_name)\n",
    "            # Open a connection to the database\n",
    "            conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "            # Create a cursor\n",
    "            c = conn.cursor()\n",
    "            # Create a table if it doesn't exist : filename, key, value\n",
    "            c.execute('''CREATE TABLE IF NOT EXISTS metadata (filename text, key text, value text)''')\n",
    "            # Insert the metadata into the table\n",
    "            for key, value in metadata.items():\n",
    "                # Convert key, value to string\n",
    "                key = str(key)\n",
    "                value = str(value)\n",
    "                # Check if the key is already in the table\n",
    "                c.execute(\"SELECT * FROM metadata WHERE filename=? AND key=?\", (img_name, key))\n",
    "                # If the key is already in the table, update the value\n",
    "                if c.fetchone():\n",
    "                    c.execute(\"UPDATE metadata SET value=? WHERE filename=? AND key=?\", (value, img_name, key))\n",
    "                    # Commit the changes\n",
    "                    conn.commit()\n",
    "                # If the key is not in the table, insert the key, value pair\n",
    "                else:\n",
    "                    c.execute(\"INSERT INTO metadata VALUES (?, ?, ?)\", (img_name, key, value))\n",
    "                    # Commit the changes\n",
    "                    conn.commit()\n",
    "            # Close the connection\n",
    "            conn.close()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid save format\")\n",
    "    except Exception as e:\n",
    "        # print an error message if an error occurs\n",
    "        print(f\"An error occurred while saving metadata for {img_name}: {str(e)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read SQLite metadata\n",
    "\n",
    "The read_sqlite method is a function used to read metadata information from a SQLite database. The method takes two parameters: metadata_path, the path to the directory where the metadata is saved, and filename, the name of the file for which the metadata is to be retrieved.\n",
    "\n",
    "The method starts by connecting to the SQLite database located at metadata_path/metadata.db using the sqlite3.connect method. A cursor is then created to allow interaction with the database. If the metadata table doesn't exist in the database, it is created.\n",
    "\n",
    "The metadata for the specified filename is retrieved from the database by executing a SQL query that selects all rows where the filename column is equal to the filename parameter. The retrieved metadata is stored in a dictionary, where the keys are taken from the key column and the values from the value column.\n",
    "\n",
    "Finally, the database connection is closed and the metadata dictionary is returned as the result of the function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def read_sqlite(metadata_path, filename):\n",
    "    # Open a connection to the database\n",
    "    conn = sqlite3.connect(os.path.join(metadata_path, 'metadata.db'))\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Create a table if it doesn't exist : filename, key, value\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS metadata (filename text, key text, value text)''')\n",
    "    # Insert the metadata into the table\n",
    "    c.execute(\"SELECT * FROM metadata WHERE filename=?\", (filename,))\n",
    "    # If the key is already in the table, update the value\n",
    "    metadata = {}\n",
    "    for row in c.fetchall():\n",
    "        metadata[row[1]] = row[2]\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    return metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set tags in metadata\n",
    "This function \"update_tags\" is used to run the YOLOv3 algorithm on a set of images, update the metadata of each image with the detected labels (tags) and save the updated metadata.\n",
    "\n",
    "The function takes 3 parameters:\n",
    "\n",
    "images: a list of file paths for the images that need to be processed.\n",
    "metadata_path: a file path to the directory where the metadata files are stored.\n",
    "save_format: the format of the metadata files. Can be either 'pickle' or 'sqlite'.\n",
    "The function uses the tqdm library to display a progress bar for the image processing. For each image, the function tries to retrieve its metadata based on the save_format. If the metadata file format is 'sqlite', the function calls the read_sqlite function to retrieve the metadata. If the metadata file format is 'pickle', the function reads the metadata file directly.\n",
    "\n",
    "If the metadata already contains a \"tags\" key, it means that the image has already been processed and its metadata has been updated with the labels, so the function skips that image.\n",
    "\n",
    "The function then calls the detect function to run the YOLOv3 algorithm on the image and retrieve the labels (tags). The labels are added to the metadata under the \"tags\" key.\n",
    "\n",
    "Finally, the function calls the save_metadata function to save the updated metadata. If an error occurs while processing an image (e.g. the metadata file is not found), the function prints an error message and continues processing the next image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def update_tags(images, metadata_path, save_format='pickle'):\n",
    "    # Run the YOLOv3 algorithm on each image\n",
    "    # display progress bar in the first thread only\n",
    "    for image in tqdm(images, desc=\"Updating tags\"):\n",
    "        # read pickle file from ../output/metadata/file_name.pkl\n",
    "        file_name = os.path.basename(image)\n",
    "        file_name, ext = file_name.split(\".\")\n",
    "        try:\n",
    "            if save_format == 'sqlite':\n",
    "                metadata = read_sqlite(metadata_path, file_name + \".\" + ext)\n",
    "            else:\n",
    "                with open(os.path.join(\"../output/metadata\", file_name + \".\" + metadata_extension), \"rb\") as f:\n",
    "                    if metadata_extension == \"json\":\n",
    "                        metadata = json.load(f)\n",
    "                    else:\n",
    "                        metadata = pickle.load(f)\n",
    "\n",
    "            if \"tags\" in metadata:\n",
    "                continue\n",
    "\n",
    "            labels = detect(image)\n",
    "\n",
    "            # Remove duplicates from labels\n",
    "            labels = list(set(labels))\n",
    "            # add labels to metadata\n",
    "            metadata[\"tags\"] = labels\n",
    "\n",
    "            save_metadata(metadata, file_name + \".\" + ext, metadata_path, save_format)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found: \", file_name)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", e)\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating tags: 100%|██████████| 101/101 [00:00<00:00, 277.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the list of images\n",
    "images = os.listdir(images_path)\n",
    "images = [os.path.join(images_path, image) for image in images]\n",
    "\n",
    "update_tags(images, metadata_path, save_format='sqlite')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, find dominant colors in the images\n",
    "The functions rgb_to_hex and find_dominant_colors are used to find the dominant colors in an image.\n",
    "\n",
    "The function rgb_to_hex takes in an RGB array with 3 values, and returns the hexadecimal representation of the color. This can be useful for formatting colors in a standardized way, as hexadecimal codes are widely used in web development and other applications.\n",
    "\n",
    "The function find_dominant_colors takes in an image and optional parameters k and image_processing_size. The k parameter specifies the number of dominant colors to return, with a default value of 4. The image_processing_size parameter allows you to resize the image to a smaller size, to speed up the processing, if desired.\n",
    "\n",
    "The image is first converted from BGR to RGB, and then reshaped into a list of pixels. The KMeans algorithm is used to cluster the pixels into k clusters, and the most popular clusters are identified. The color values for each of the k clusters are converted to hexadecimal representation and returned as a list, along with the percentage of the image covered by each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Convert RGB to HEX (RGB is an array of 3 values)\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % (int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
    "\n",
    "# Find 4 dominant colors in the image\n",
    "def find_dominant_colors(image, k=4, image_processing_size=None):\n",
    "    # Resize image if new dims provided, just to speed up processing\n",
    "    if image_processing_size is not None:\n",
    "        image = cv2.resize(image, image_processing_size, interpolation=cv2.INTER_AREA)\n",
    "    # Convert to RGB from BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Reshape the image to be a list of pixels\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    # Cluster and assign labels to the pixels\n",
    "    clt = KMeans(n_clusters=k, n_init=10)\n",
    "    labels = clt.fit_predict(image)\n",
    "    # Count labels to find most popular\n",
    "    label_counts = Counter(labels)\n",
    "    # Subset out most popular centroid\n",
    "    dominant_colors = [clt.cluster_centers_[i] for i in label_counts.keys()]\n",
    "    # For each color, convert to hex and append to list\n",
    "    dominant_colors = [rgb_to_hex(color) for color in dominant_colors]\n",
    "\n",
    "    # find percent of each color in the image\n",
    "    percent = [int((label_counts[i] / len(labels)) * 100) for i in label_counts.keys()]\n",
    "\n",
    "    # return the 4 dominant colors and their percent\n",
    "    dominant_colors = list(zip(dominant_colors, percent))\n",
    "    return dominant_colors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code block is used to process images and find their dominant colors. The code first retrieves all the images present in the folder specified by the images_path variable. Then, it iterates over each image, reads the metadata associated with the image and finds its dominant color if it hasn't been calculated already.\n",
    "\n",
    "For each image, the code first reads the image using OpenCV's cv2.imread() function and stores the result in the img variable. The code then reads the metadata of the image. The type of metadata file (e.g. .json, .pkl, .sqlite) is specified by the metadata_extension variable. Based on the file extension, the code reads the metadata using either read_sqlite(), json.load(), or pickle.load() functions. If the metadata file is not found, the code continues to the next iteration of the loop, but if there is an error, it prints the error message and continues to the next iteration.\n",
    "\n",
    "If the metadata does not contain information about the dominant color of the image, the code calculates the dominant color by calling the find_dominant_colors() function. The result of the find_dominant_colors() function is then added to the metadata under the key \"dominant_color\". Finally, the updated metadata is saved using the save_metadata() function, which saves the metadata to the specified location using the specified file format (metadata_extension)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding dominant colors: 100%|██████████| 100/100 [31:45<00:00, 19.05s/it]\n"
     ]
    }
   ],
   "source": [
    "images = get_all_images(images_path)\n",
    "\n",
    "# For each image in the folder \"../images_labelized\"\n",
    "for image in tqdm(images, desc=\"Finding dominant colors\"):\n",
    "    img = cv2.imread(image)\n",
    "    # Save the dominant color\n",
    "    # First read metadata from the file\n",
    "    file_name = os.path.basename(image)\n",
    "    file_name, ext = file_name.split(\".\")\n",
    "    try:\n",
    "        if metadata_extension == 'sqlite':\n",
    "            metadata = read_sqlite(\"../output/metadata\", file_name + \".\" + ext)\n",
    "        else:\n",
    "            with open(os.path.join(\"../output/metadata\", file_name + \".\" + metadata_extension), \"rb\") as f:\n",
    "                if metadata_extension == \"json\":\n",
    "                    metadata = json.load(f)\n",
    "                else:\n",
    "                    metadata = pickle.load(f)\n",
    "\n",
    "        if \"dominant_color\" in metadata:\n",
    "            continue\n",
    "\n",
    "        dominant_color = find_dominant_colors(img)\n",
    "\n",
    "        # Add the dominant color to the metadata\n",
    "        metadata[\"dominant_color\"] = dominant_color\n",
    "        # Save the metadata\n",
    "        save_metadata(metadata, file_name + \".\" + ext, \"../output/metadata\", metadata_extension)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \", file_name)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        continue\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
