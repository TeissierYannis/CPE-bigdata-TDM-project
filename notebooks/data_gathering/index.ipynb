{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "This code block imports several libraries that are used in the code.\n",
    "\n",
    "- `os`: This library provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "- `zipfile`: This library provides tools to create, read, write, append, and list a ZIP file.\n",
    "\n",
    "- `requests`: This library is used for making HTTP requests to retrieve data from a specified URL.\n",
    "\n",
    "- `functools`: This library provides tools for working with functions.\n",
    "\n",
    "- `pathlib`: This library provides an object-oriented way of working with file paths.\n",
    "\n",
    "- `tqdm`: This library provides a progress bar to indicate the progress of a task.\n",
    "\n",
    "- `pandas`: This library provides data structures and data analysis tools for handling and manipulating numerical tables and time series data.\n",
    "\n",
    "- `nest_asyncio`: This library is used to run multiple asyncio loops in the same thread.\n",
    "\n",
    "- `aiohttp`: This library provides an asynchronous HTTP client/server for asyncio.\n",
    "\n",
    "- `time`: This library provides functions to work with time.\n",
    "\n",
    "- `asyncio`: This library provides asynchronous I/O, event loop, and concurrency tools.\n",
    "\n",
    "- `csv`: This library provides functionality to read from and write to CSV (Comma-Separated Values) files.\n",
    "\n",
    "- `load_dotenv`: This function is imported from the `dotenv` library and is used to load environment variables from a .env file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:12:45.409094Z",
     "end_time": "2023-04-23T14:12:48.094201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (2.28.2)\n",
      "Requirement already satisfied: pathlib in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (1.5.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (0.21.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from requests) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from aiohttp) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\woloz\\scoop\\apps\\python37\\current\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pathlib tqdm pandas pillow nest_asyncio aiohttp python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import functools\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import asyncio\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:12:49.901660Z",
     "end_time": "2023-04-23T14:12:50.804572Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Paths and Variables\n",
    "This code block sets several paths and variables that are used throughout the code.\n",
    "\n",
    "- `output_path`: This variable stores the base folder path for the project.\n",
    "\n",
    "- `images_path`, `metadata_path`, `include_path`: These variables store the paths for the images, metadata, and include folders, respectively. The paths are constructed by joining the base folder path with the respective sub-folder names.\n",
    "\n",
    "- `list_of_paths`: This list stores the paths of the output, images, metadata, and include folders.\n",
    "\n",
    "- `dataset_url`: This variable stores the base URL for the dataset.\n",
    "\n",
    "- `num_images`: This variable stores the number of images to be downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:14:24.113679Z",
     "end_time": "2023-04-23T14:14:24.135112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "include_path = os.path.join(output_path, \"include\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, include_path]\n",
    "\n",
    "# Set the base URL for the dataset\n",
    "dataset_url = \"https://unsplash.com/data/lite/latest\"\n",
    "\n",
    "# Set the number of images to download\n",
    "num_images = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Folder\n",
    "This function `create_folder` creates a folder at the specified path.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `path (str)`: The path of the folder to be created.\n",
    "\n",
    "**Function Returns:**\n",
    "\n",
    "- `None`\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function uses the `os.mkdir` method to create the folder at the specified path.\n",
    "- If the folder already exists, the function prints a message saying so.\n",
    "- If there is an error creating the folder, the function prints the error message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:12:53.487912Z",
     "end_time": "2023-04-23T14:12:53.533513Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \"\"\"\n",
    "    This function creates a folder at the specified path.\n",
    "    If the folder already exists, it will print a message saying so.\n",
    "    If there is an error creating the folder, it will print the error message.\n",
    "\n",
    "    Parameters:\n",
    "        :param path (str): The path of the folder to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use os.mkdir to create the folder at the specified path\n",
    "        os.mkdir(path)\n",
    "        print(f\"Folder {path} created\")\n",
    "    except FileExistsError:\n",
    "        # If the folder already exists, print a message saying so\n",
    "        print(f\"Folder {path} already exists\")\n",
    "    except Exception as e:\n",
    "        # If there is an error creating the folder, print the error message\n",
    "        print(f\"Error creating folder {path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Folders\n",
    "This function `init_folder` initializes the specified folders.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `folder_names (list)`: A list of folder names to be created.\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function iterates over the list of folder names and calls the `create_folder` function for each name.\n",
    "- This function is used to create the required output, images, metadata, and include folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:19.925708Z",
     "end_time": "2023-04-23T14:13:19.933708Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_folder(folder_names: list):\n",
    "    for folder_name in folder_names:\n",
    "        create_folder(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:20.461274Z",
     "end_time": "2023-04-23T14:13:20.506921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../output created\n",
      "Folder ../output\\images created\n",
      "Folder ../output\\metadata created\n",
      "Folder ../output\\include created\n"
     ]
    }
   ],
   "source": [
    "init_folder(list_of_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a File\n",
    "This function `download` downloads a file from a given URL and saves it to a specified filename.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `url (str)`: The URL of the file to be downloaded.\n",
    "- `filename (str)`: The filename to save the file as.\n",
    "\n",
    "**Function Returns:**\n",
    "\n",
    "- `path (str)`: The path of the downloaded file.\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function creates a `requests.Session` object to persist the state of the connection.\n",
    "- The function then sends a GET request to the URL to start the download.\n",
    "- The function raises an error if the response is not 200 OK.\n",
    "- The function retrieves the file size from the `Content-Length` header and uses it to display the download progress using the `tqdm` library.\n",
    "- The function opens the target file in binary write mode and writes each chunk of data from the response to the file.\n",
    "- The function returns the path to the downloaded file.\n",
    "- If an HTTP error occurs while downloading the file, the function prints an error message.\n",
    "- If any other error occurs while downloading the file, the function prints a general error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:22.627280Z",
     "end_time": "2023-04-23T14:13:22.650290Z"
    }
   },
   "outputs": [],
   "source": [
    "def download(url, filename):\n",
    "    \"\"\"\n",
    "    This download a file from a given URL and save it to a specified filename.\n",
    "\n",
    "    Parameters:\n",
    "        :param url (str): The URL of the file to be downloaded.\n",
    "        :param filename (str): The filename to save the file as.\n",
    "\n",
    "    Returns:\n",
    "    path (str): The path of the downloaded file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a session object to persist the state of connection\n",
    "        s = requests.Session()\n",
    "        # Retry connecting to the URL up to 3 times\n",
    "        s.mount(url, requests.adapters.HTTPAdapter(max_retries=3))\n",
    "        # Send a GET request to the URL to start the download\n",
    "        r = s.get(url, stream=True, allow_redirects=True)\n",
    "        # Raise an error if the response is not 200 OK\n",
    "        r.raise_for_status()\n",
    "        # Get the file size from the Content-Length header, default to 0 if not present\n",
    "        file_size = int(r.headers.get('Content-Length', 0))\n",
    "        # Get the absolute path to the target file\n",
    "        path = pathlib.Path(filename).expanduser().resolve()\n",
    "        # Create parent directories if they don't exist\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Set the description to display while downloading, \"(Unknown total file size)\" if file size is 0\n",
    "        desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "        # Enable decoding the response content\n",
    "        r.raw.read = functools.partial(r.raw.read, decode_content=True)\n",
    "        # Use tqdm to display the download progress\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=desc) as pbar:\n",
    "            # Open the target file in binary write mode\n",
    "            with path.open(\"wb\") as f:\n",
    "                # Write each chunk of data from the response to the file\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        # Return the path to the downloaded file\n",
    "        return path\n",
    "    # Handle HTTP error if the response is not 200 OK\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred while downloading dataset: {e}\")\n",
    "    # Handle any other exceptions that might occur while downloading the file\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while downloading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Extracting the Dataset\n",
    "This function `download_dataset` downloads the dataset from a given URL, unzips it, and stores the images in a specified image path.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `dataset_url (str)`: The URL of the dataset to be downloaded.\n",
    "- `image_path (str)`: The path to store the images after unzipping the dataset.\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function first checks if the dataset has already been downloaded by checking if the `archive.zip` file exists or if the images folder is empty.\n",
    "- If the dataset has not been downloaded, the function downloads it from the given URL using the `download` function.\n",
    "- The function then uses the `zipfile` library to extract the contents of the `archive.zip` file to the specified image path.\n",
    "- The function then removes the `archive.zip` file.\n",
    "- If an error occurs while unzipping the dataset, the function prints an error message.\n",
    "- If an error occurs while removing the `archive.zip` file, the function prints an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:23.854467Z",
     "end_time": "2023-04-23T14:13:23.876762Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_dataset(dataset_url, image_path):\n",
    "    \"\"\"\n",
    "    Downloads the dataset from the given URL, unzips it, and stores the images in the specified image path.\n",
    "\n",
    "    Args:\n",
    "        :param dataset_url (str): URL of the dataset to be downloaded\n",
    "        :param image_path (str): Path to store the images after unzipping the dataset\n",
    "    \"\"\"\n",
    "    # Check if the dataset has already been downloaded\n",
    "    # Check if the archive.zip file exists or if the images folder is empty\n",
    "    if not os.path.exists('archive.zip'):\n",
    "        # Download the dataset from the given url\n",
    "        download(dataset_url, 'archive.zip')\n",
    "        print(\"Dataset downloaded!\")\n",
    "        try:\n",
    "            # Extract the contents of the archive.zip to the specified image path\n",
    "            with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(image_path)\n",
    "            print(\"Dataset unzipped\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while unzipping dataset: {e}\")\n",
    "        try:\n",
    "            # Remove the archive.zip file\n",
    "            os.remove('archive.zip')\n",
    "            print(\"archive.zip removed\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while removing archive.zip: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:24.724704Z",
     "end_time": "2023-04-23T14:13:55.135873Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 632M/632M [00:20<00:00, 31.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded!\n",
      "Dataset unzipped\n",
      "archive.zip removed\n"
     ]
    }
   ],
   "source": [
    "download_dataset(dataset_url, images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and Processing the Photos Data\n",
    "This code block reads the `photos.tsv000` file in the images folder and processes the data.\n",
    "\n",
    "- The `pd.read_csv` method is used to read the `photos.tsv000` file, and the `sep` parameter is set to `'\\t'` to indicate that the data is separated by tabs.\n",
    "- The resulting data is stored in a Pandas DataFrame called `photo_df`.\n",
    "- The `photo_df` DataFrame is then modified to only include the `photo_id` and `photo_image_url` columns.\n",
    "- The `print(photo_df.head())` statement is used to display the first 5 rows of the `photo_df` DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:55.137875Z",
     "end_time": "2023-04-23T14:13:55.170022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      photo_id                                    photo_image_url\n",
      "0  XMyPniM9LF0  https://images.unsplash.com/uploads/1411949294...\n",
      "1  rDLBArZUl1c  https://images.unsplash.com/photo-141633941111...\n",
      "2  cNDGZ2sQ3Bo  https://images.unsplash.com/photo-142014251503...\n",
      "3  iuZ_D1eoq9k  https://images.unsplash.com/photo-141487280988...\n",
      "4  BeD3vjQ8SI0  https://images.unsplash.com/photo-141700759404...\n"
     ]
    }
   ],
   "source": [
    "# Read photo.tsv file in images folder\n",
    "photo_df = pd.read_csv(os.path.join(images_path, 'photos.tsv000'), sep='\\t')\n",
    "# read photo_image_url column and photo_id in index\n",
    "photo_df = photo_df[['photo_id', 'photo_image_url']]\n",
    "\n",
    "print(photo_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:13:55.154877Z",
     "end_time": "2023-04-23T14:13:55.403514Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downloading an Image Asynchronously\n",
    "This is an asynchronous function `download_image` that downloads an image from a given URL and saves it to the local file system.\n",
    "\n",
    "**Function Parameters:**\n",
    "\n",
    "- `session (aiohttp.ClientSession)`: An `aiohttp` client session that manages HTTP requests and responses.\n",
    "- `url (str)`: The URL of the image to download.\n",
    "- `i (int)`: An integer representing the index of the image to download.\n",
    "- `err_cnt (int, optional)`: An optional integer representing the number of times that the download has failed due to a client error. Defaults to 0.\n",
    "\n",
    "**Function Returns:**\n",
    "\n",
    "- This function does not return anything.\n",
    "\n",
    "**Function Behavior:**\n",
    "\n",
    "- The function uses the `session.get` method from the `aiohttp` library to send a GET request to the URL of the image.\n",
    "- The function opens a file in binary write mode with the filename `image_i.jpg`, where `i` is the index of the image, and writes the content of the response to the file.\n",
    "- If a `ClientError` occurs while downloading the image, the function retries the download up to 10 times, with a 10-second delay between each retry.\n",
    "- If the download still fails after 10 retries, the function stops trying and prints an error message."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "async def download_image(session: aiohttp.ClientSession, url: str, i: int, err_cnt=None):\n",
    "    \"\"\"\n",
    "    Downloads an image from the given URL using an aiohttp client session and saves it to the local file system.\n",
    "\n",
    "    Args:\n",
    "        session: An aiohttp client session that manages HTTP requests and responses.\n",
    "        url: The URL of the image to download.\n",
    "        i: An integer representing the index of the image to download.\n",
    "        err_cnt: An optional integer representing the number of times that the download has failed due to a client error.\n",
    "                 If not provided, it defaults to 0.\n",
    "\n",
    "    Raises:\n",
    "        This method does not raise any exceptions.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    if err_cnt is None:\n",
    "        err_cnt = 0\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            filename = os.path.join(images_path, \"image_\" + str(i) + \".jpg\")\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(await response.content.read())\n",
    "            print(f\"Downloaded {url} to {filename} idx: {i}\")\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"Error occurred while downloading {url}: {e}\")\n",
    "        if err_cnt == 10:\n",
    "            return\n",
    "        await asyncio.sleep(10)\n",
    "        err_cnt += 1\n",
    "        await download_image(session, url, i, err_cnt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:14:03.145001Z",
     "end_time": "2023-04-23T14:14:03.168972Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download Images\n",
    "\n",
    "This code defines an asynchronous function `download_images` that downloads a list of images from a set of given URLs. The function uses the `aiohttp` library to manage the HTTP requests and responses during the download process. The function takes two arguments: `image_urls`, a list of strings representing the URLs of the images to be downloaded, and `images_ids`, a list of integers representing the indices of the images to be downloaded.\n",
    "\n",
    "The function starts by creating a new `aiohttp` client session, which will be used to manage the HTTP requests and responses during the download process. A semaphore with a limit of 5000 concurrent downloads is created to prevent overloading the server. The function then loops through the `image_urls` list and creates a new task for each URL using the `asyncio.ensure_future` method. Before creating the task, the function acquires a permit from the semaphore to limit the number of concurrent downloads. Each task calls the `download_image` function to download the image from the URL and save it to the local file system. After the task is created, the function releases the semaphore permit when the task completes.\n",
    "\n",
    "Once all the tasks are created, the function waits for all download tasks to complete using the `asyncio.wait` method. The results of all the tasks are then gathered using the `asyncio.gather` method, although this step is not necessary as the tasks have already completed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "async def download_images(image_urls, images_ids):\n",
    "    \"\"\"\n",
    "    Downloads a list of images from the given URLs using an aiohttp client session and saves them to the local file system.\n",
    "\n",
    "    Args:\n",
    "        image_urls: A list of strings representing the URLs of the images to download.\n",
    "        images_ids: A list of integers representing the indices of the images to download.\n",
    "\n",
    "    Raises:\n",
    "        This method does not raise any exceptions.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    # Create a new aiohttp client session to manage HTTP requests and responses\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []  # Create an empty list to hold the tasks that will download the images\n",
    "        semaphore = asyncio.Semaphore(5000)  # Create a semaphore to limit the number of concurrent downloads\n",
    "        # Loop through the image URLs and create a new task for each one\n",
    "        for i, url in enumerate(image_urls):\n",
    "            try:\n",
    "                await semaphore.acquire()  # Acquire a permit from the semaphore to limit concurrency\n",
    "                #url = url + \"?w=1000&fm=jpg&fit=max\"  # Append query parameters to resize and optimize the image\n",
    "                task = asyncio.ensure_future(download_image(session, url, images_ids[i]))  # Create a new download task\n",
    "                task.add_done_callback(\n",
    "                    lambda x: semaphore.release())  # Release the semaphore permit when the task completes\n",
    "                tasks.append(task)  # Add the task to the list of download tasks\n",
    "            except Exception:\n",
    "                print(f\"Error occurred while downloading {url}\")\n",
    "                semaphore.release()  # Release the semaphore permit if an exception occurs\n",
    "        # Wait for all download tasks to complete\n",
    "        await asyncio.wait(tasks)\n",
    "        # Gather the results of all download tasks (not necessary because the tasks have already completed)\n",
    "        await asyncio.gather(*tasks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:14:31.870866Z",
     "end_time": "2023-04-23T14:14:31.882892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images to download: 100\n"
     ]
    }
   ],
   "source": [
    "# Get the list of image urls and image ids\n",
    "image_urls = photo_df['photo_image_url'].values.tolist()[:num_images]\n",
    "# img id are from 0 to size of the list\n",
    "images_ids = [i for i in range(len(image_urls))][:num_images]\n",
    "# filter by looking if the image already exist in fact of the image_id is already in the folder\n",
    "# Loop on the image_id and check if the image exist in the folder\n",
    "image_urls = [url for url, image_id in zip(image_urls, images_ids) if\n",
    "              not os.path.exists(os.path.join(images_path, \"image_\" + str(image_id) + \".jpg\"))]\n",
    "print(f\"Number of images to download: {len(image_urls)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:14:32.551344Z",
     "end_time": "2023-04-23T14:14:32.616680Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code filters a list of image URLs and their respective image IDs by checking if the images already exist in a specified folder.\n",
    "\n",
    "1. The `image_urls` list is populated with the values of the `photo_image_url` column of the `photo_df` dataframe. The list is then sliced to a specified number of images using the `[:num_images]` syntax.\n",
    "\n",
    "2. The `images_ids` list is created by generating a range of integers from 0 to the length of the `image_urls` list and slicing it to the specified number of images.\n",
    "\n",
    "3. The code then creates a new list `image_urls` that only contains URLs of images that do not already exist in the specified folder. This is done by looping through the `image_urls` and `images_ids` lists and checking if the image file with the corresponding ID exists in the folder. If it does, the URL is not added to the new list.\n",
    "\n",
    "4. Finally, the code prints the number of images that will be downloaded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://images.unsplash.com/photo-1428550670225-15f007f6f1ba to ../output\\images\\image_7.jpg idx: 7\n",
      "Downloaded https://images.unsplash.com/reserve/m6rT4MYFQ7CT8j9m2AEC_JakeGivens%20-%20Sunset%20in%20the%20Park.JPG to ../output\\images\\image_6.jpg idx: 6\n",
      "Downloaded https://images.unsplash.com/uploads/1411476843343e89a8f76/bda95c47 to ../output\\images\\image_5.jpg idx: 5\n",
      "Downloaded https://images.unsplash.com/photo-1501275578-61eff411d8bf to ../output\\images\\image_67.jpg idx: 67\n",
      "Downloaded https://images.unsplash.com/photo-1492644233019-549102aa44f7 to ../output\\images\\image_61.jpg idx: 61\n",
      "Downloaded https://images.unsplash.com/photo-1420142515034-86cc8c508475 to ../output\\images\\image_2.jpg idx: 2\n",
      "Downloaded https://images.unsplash.com/photo-1455655100973-2a0d5f567386 to ../output\\images\\image_16.jpg idx: 16\n",
      "Downloaded https://images.unsplash.com/photo-1502977249166-824b3a8a4d6d to ../output\\images\\image_47.jpg idx: 47\n",
      "Downloaded https://images.unsplash.com/photo-1505962372142-dcf8ddcf4c72 to ../output\\images\\image_82.jpg idx: 82\n",
      "Downloaded https://images.unsplash.com/photo-1516415640404-0ca8b3b68958 to ../output\\images\\image_78.jpg idx: 78\n",
      "Downloaded https://images.unsplash.com/photo-1508178828646-9dddefd2b4e1 to ../output\\images\\image_73.jpg idx: 73\n",
      "Downloaded https://images.unsplash.com/photo-1510248703225-7f7838dfd579 to ../output\\images\\image_76.jpg idx: 76\n",
      "Downloaded https://images.unsplash.com/photo-1517842193836-33a9a05e19aa to ../output\\images\\image_89.jpg idx: 89\n",
      "Downloaded https://images.unsplash.com/photo-1415912364061-78a25859c0fa to ../output\\images\\image_19.jpg idx: 19\n",
      "Downloaded https://images.unsplash.com/photo-1483621150297-aa62559c634b to ../output\\images\\image_58.jpg idx: 58\n",
      "Downloaded https://images.unsplash.com/photo-1476860184138-af609b4e8a3a to ../output\\images\\image_55.jpg idx: 55\n",
      "Downloaded https://images.unsplash.com/uploads/14119492946973137ce46/f1f2ebf3 to ../output\\images\\image_0.jpg idx: 0\n",
      "Downloaded https://images.unsplash.com/photo-1505886410478-e9e273c2ac09 to ../output\\images\\image_68.jpg idx: 68\n",
      "Downloaded https://images.unsplash.com/photo-1444210971048-6130cf0c46cf to ../output\\images\\image_30.jpg idx: 30\n",
      "Downloaded https://images.unsplash.com/reserve/mW95rWmYSRe4nTMVaRaW_French-Mountain.jpg to ../output\\images\\image_20.jpg idx: 20\n",
      "Downloaded https://images.unsplash.com/photo-1476922027627-aa7293e3aaa8 to ../output\\images\\image_54.jpg idx: 54\n",
      "Downloaded https://images.unsplash.com/photo-1416339411116-62e1226aacd8 to ../output\\images\\image_1.jpg idx: 1\n",
      "Downloaded https://images.unsplash.com/photo-1494198525982-6e4625132b9e to ../output\\images\\image_64.jpg idx: 64\n",
      "Downloaded https://images.unsplash.com/photo-1461869974586-6b4245936154 to ../output\\images\\image_51.jpg idx: 51\n",
      "Downloaded https://images.unsplash.com/photo-1473731149742-97a189111276 to ../output\\images\\image_53.jpg idx: 53\n",
      "Downloaded https://images.unsplash.com/photo-1511519991062-53acadf7be18 to ../output\\images\\image_74.jpg idx: 74\n",
      "Downloaded https://images.unsplash.com/photo-1505567745926-ba89000d255a to ../output\\images\\image_69.jpg idx: 69\n",
      "Downloaded https://images.unsplash.com/photo-1486895756674-b48b9b2eacf3 to ../output\\images\\image_40.jpg idx: 40\n",
      "Downloaded https://images.unsplash.com/photo-1431321327469-8f1a5e7afc6a to ../output\\images\\image_24.jpg idx: 24\n",
      "Downloaded https://images.unsplash.com/photo-1503343870946-44cccad5de1b to ../output\\images\\image_46.jpg idx: 46\n",
      "Downloaded https://images.unsplash.com/photo-1429270958905-78f90e2dca75 to ../output\\images\\image_8.jpg idx: 8\n",
      "Downloaded https://images.unsplash.com/photo-1495304490888-4818cc97ec1b to ../output\\images\\image_65.jpg idx: 65\n",
      "Downloaded https://images.unsplash.com/reserve/l48Eloe0RGm3l0OQfHNd_13112213395_dbe69fe6de_o.jpg to ../output\\images\\image_21.jpg idx: 21\n",
      "Downloaded https://images.unsplash.com/photo-1485892286759-7a4cc553fb3d to ../output\\images\\image_57.jpg idx: 57\n",
      "Downloaded https://images.unsplash.com/photo-1496421516509-6f6df8495edd to ../output\\images\\image_44.jpg idx: 44\n",
      "Downloaded https://images.unsplash.com/photo-1437149310981-0f2690a6069d to ../output\\images\\image_25.jpg idx: 25\n",
      "Downloaded https://images.unsplash.com/photo-1458682375064-2970d354b9bd to ../output\\images\\image_32.jpg idx: 32\n",
      "Downloaded https://images.unsplash.com/photo-1471899236350-e3016bf1e69e to ../output\\images\\image_35.jpg idx: 35\n",
      "Downloaded https://images.unsplash.com/photo-1456973336295-46fc683d4276 to ../output\\images\\image_33.jpg idx: 33\n",
      "Downloaded https://images.unsplash.com/photo-1526409108006-75dd603c1d67 to ../output\\images\\image_99.jpg idx: 99\n",
      "Downloaded https://images.unsplash.com/photo-1487349384428-12b47aca925e to ../output\\images\\image_59.jpg idx: 59\n",
      "Downloaded https://images.unsplash.com/photo-1431576882097-3c68310a480f to ../output\\images\\image_23.jpg idx: 23\n",
      "Downloaded https://images.unsplash.com/photo-1512149086943-7937461d6bf2 to ../output\\images\\image_85.jpg idx: 85\n",
      "Downloaded https://images.unsplash.com/photo-1492117410584-db7b8a2e1460 to ../output\\images\\image_63.jpg idx: 63\n",
      "Downloaded https://images.unsplash.com/photo-1458046913496-b049204810ac to ../output\\images\\image_50.jpg idx: 50\n",
      "Downloaded https://images.unsplash.com/photo-1436891620584-47fd0e565afb to ../output\\images\\image_12.jpg idx: 12\n",
      "Downloaded https://images.unsplash.com/photo-1508873787497-1b513a18217a to ../output\\images\\image_83.jpg idx: 83\n",
      "Downloaded https://images.unsplash.com/photo-1462834254122-801b9e967783 to ../output\\images\\image_34.jpg idx: 34\n",
      "Downloaded https://images.unsplash.com/photo-1433018705870-ecc677a093f2 to ../output\\images\\image_9.jpg idx: 9\n",
      "Downloaded https://images.unsplash.com/photo-1500327324249-e434c1bfdfab to ../output\\images\\image_45.jpg idx: 45\n",
      "Downloaded https://images.unsplash.com/photo-1515369983363-bafb28a9f3e4 to ../output\\images\\image_81.jpg idx: 81\n",
      "Downloaded https://images.unsplash.com/photo-1448988301245-000401bb1ee7 to ../output\\images\\image_15.jpg idx: 15\n",
      "Downloaded https://images.unsplash.com/photo-1492683513054-55277abccd99 to ../output\\images\\image_41.jpg idx: 41\n",
      "Downloaded https://images.unsplash.com/photo-1446376271024-d83b7f98ed83 to ../output\\images\\image_14.jpg idx: 14\n",
      "Downloaded https://images.unsplash.com/photo-1414872809883-7620d2ae7566 to ../output\\images\\image_3.jpg idx: 3\n",
      "Downloaded https://images.unsplash.com/photo-1445264760308-f80de105f42d to ../output\\images\\image_13.jpg idx: 13\n",
      "Downloaded https://images.unsplash.com/photo-1516610627349-1b52a4ff315e to ../output\\images\\image_80.jpg idx: 80\n",
      "Downloaded https://images.unsplash.com/photo-1441906551230-a0352e3dbcd9 to ../output\\images\\image_28.jpg idx: 28\n",
      "Downloaded https://images.unsplash.com/photo-1493271870018-04f0e7c336e6 to ../output\\images\\image_62.jpg idx: 62\n",
      "Downloaded https://images.unsplash.com/photo-1430826032205-b84a31521ea6 to ../output\\images\\image_10.jpg idx: 10\n",
      "Downloaded https://images.unsplash.com/photo-1540808450974-f61b32d7db7d to ../output\\images\\image_96.jpg idx: 96\n",
      "Downloaded https://images.unsplash.com/photo-1445249310874-ddfd23018ee3 to ../output\\images\\image_31.jpg idx: 31\n",
      "Downloaded https://images.unsplash.com/photo-1480429186140-9a4af08f827c to ../output\\images\\image_38.jpg idx: 38\n",
      "Downloaded https://images.unsplash.com/photo-1475500992832-e9aabbe88168 to ../output\\images\\image_37.jpg idx: 37\n",
      "Downloaded https://images.unsplash.com/photo-1433621611134-008713dc0321 to ../output\\images\\image_11.jpg idx: 11\n",
      "Downloaded https://images.unsplash.com/photo-1421992617193-7ce245f5cb08 to ../output\\images\\image_18.jpg idx: 18\n",
      "Downloaded https://images.unsplash.com/photo-1540799063343-730a78bce96a to ../output\\images\\image_95.jpg idx: 95\n",
      "Downloaded https://images.unsplash.com/photo-1485561331122-5b7098c62fcc to ../output\\images\\image_56.jpg idx: 56\n",
      "Downloaded https://images.unsplash.com/photo-1513842844317-1b117223f211 to ../output\\images\\image_77.jpg idx: 77\n",
      "Downloaded https://images.unsplash.com/photo-1417007594043-344e0104c3ce to ../output\\images\\image_4.jpg idx: 4\n",
      "Downloaded https://images.unsplash.com/photo-1514910125310-826067e8dfdf to ../output\\images\\image_86.jpg idx: 86\n",
      "Downloaded https://images.unsplash.com/photo-1495401653488-227df3698efa to ../output\\images\\image_43.jpg idx: 43\n",
      "Downloaded https://images.unsplash.com/photo-1503925008906-d20ab3489c35 to ../output\\images\\image_48.jpg idx: 48\n",
      "Downloaded https://images.unsplash.com/photo-1433030447984-21d24eb0c5ba to ../output\\images\\image_22.jpg idx: 22\n",
      "Downloaded https://images.unsplash.com/photo-1505623776320-7edecf5f0771 to ../output\\images\\image_70.jpg idx: 70\n",
      "Downloaded https://images.unsplash.com/photo-1506809494389-a68c51c9e6a1 to ../output\\images\\image_71.jpg idx: 71\n",
      "Downloaded https://images.unsplash.com/photo-1509702713478-5441be3d911c to ../output\\images\\image_84.jpg idx: 84\n",
      "Downloaded https://images.unsplash.com/photo-1415353115981-9bb4c22bafed to ../output\\images\\image_17.jpg idx: 17\n",
      "Downloaded https://images.unsplash.com/photo-1518155852009-65246ff44395 to ../output\\images\\image_97.jpg idx: 97\n",
      "Downloaded https://images.unsplash.com/photo-1473073826085-dafe61d85c04 to ../output\\images\\image_36.jpg idx: 36\n",
      "Downloaded https://images.unsplash.com/photo-1515224526905-51c7d77c7bb8 to ../output\\images\\image_87.jpg idx: 87\n",
      "Downloaded https://images.unsplash.com/photo-1485956547186-2c8e67895f72 to ../output\\images\\image_60.jpg idx: 60\n",
      "Downloaded https://images.unsplash.com/photo-1517259227355-de4b20b3fe46 to ../output\\images\\image_88.jpg idx: 88\n",
      "Downloaded https://images.unsplash.com/photo-1465232377925-cce9a9d87843 to ../output\\images\\image_52.jpg idx: 52\n",
      "Downloaded https://images.unsplash.com/photo-1445122734110-5ccd170eded6 to ../output\\images\\image_29.jpg idx: 29\n",
      "Downloaded https://images.unsplash.com/photo-1526393947515-c4e35d7debde to ../output\\images\\image_91.jpg idx: 91\n",
      "Downloaded https://images.unsplash.com/photo-1436377734980-0ee004df570b to ../output\\images\\image_26.jpg idx: 26\n",
      "Downloaded https://images.unsplash.com/photo-1534842628439-bcc9e12f826e to ../output\\images\\image_94.jpg idx: 94\n",
      "Downloaded https://images.unsplash.com/photo-1440524897680-0d6613af4ca3 to ../output\\images\\image_27.jpg idx: 27\n",
      "Downloaded https://images.unsplash.com/photo-1511895235435-f34285c6d3be to ../output\\images\\image_75.jpg idx: 75\n",
      "Downloaded https://images.unsplash.com/photo-1518459951661-02d921b3a9ce to ../output\\images\\image_98.jpg idx: 98\n",
      "Downloaded https://images.unsplash.com/photo-1495890467381-2eba2c4c48b2 to ../output\\images\\image_42.jpg idx: 42\n",
      "Downloaded https://images.unsplash.com/photo-1498522437123-3a7624402acb to ../output\\images\\image_66.jpg idx: 66\n",
      "Downloaded https://images.unsplash.com/photo-1529348592009-6ed8b9fddc1e to ../output\\images\\image_92.jpg idx: 92\n",
      "Downloaded https://images.unsplash.com/photo-1530485101558-6cf3cf206f39 to ../output\\images\\image_93.jpg idx: 93\n",
      "Downloaded https://images.unsplash.com/photo-1486393418071-83cd9b65f9e8 to ../output\\images\\image_39.jpg idx: 39\n",
      "Downloaded https://images.unsplash.com/photo-1509212232536-8d5fb32736d5 to ../output\\images\\image_72.jpg idx: 72\n",
      "Downloaded https://images.unsplash.com/photo-1506258998-82810ddc75a3 to ../output\\images\\image_49.jpg idx: 49\n",
      "Downloaded https://images.unsplash.com/photo-1518410240146-36aeeed0e4f9 to ../output\\images\\image_90.jpg idx: 90\n",
      "Downloaded https://images.unsplash.com/photo-1516425096928-77244e2965e5 to ../output\\images\\image_79.jpg idx: 79\n",
      "[Chunk 0] Downloaded 100 images in 21.985536813735962 seconds\n",
      "Downloaded 100 images in 21.986537218093872 seconds\n"
     ]
    }
   ],
   "source": [
    "# Split the list of image urls into chunks of max and add a timeout of 30 seconds\n",
    "chunks = [image_urls[i:i + 5000] for i in range(0, len(image_urls), 5000)]\n",
    "start_t = time.time()\n",
    "loop = None\n",
    "for i, chunk in enumerate(chunks):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        loop.run_until_complete(download_images(chunk, images_ids[i * 5000:(i + 1) * 5000]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while downloading chunk {i}: {e}\")\n",
    "    finally:\n",
    "        loop.close()\n",
    "        print(f\"[Chunk {i}] Downloaded {len(chunk)} images in {time.time() - start} seconds\")\n",
    "\n",
    "print(f'Downloaded {len(image_urls)} images in {time.time() - start_t} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:14:34.876895Z",
     "end_time": "2023-04-23T14:14:56.877737Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code removes all files in the `images_path` directory except for `.jpg` files. It uses the `os.listdir()` method to get a list of all files in the directory and loops through each file. If the file ends with `.jpg`, it continues to the next file. If the file does not end with `.jpg`, it uses the `os.remove()` method to delete the file. However, if the file is named `TERMS.md`, it skips it and does not delete it. If an exception occurs while removing a file, the code continues to the next file.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Remove all files except images\n",
    "for file in os.listdir(images_path):\n",
    "    if file.endswith('.jpg'):\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            # Don't delete TERMS.md\n",
    "            if file == 'TERMS.md':\n",
    "                continue\n",
    "            os.remove(os.path.join(images_path, file))\n",
    "        except Exception as e:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:15:01.133526Z",
     "end_time": "2023-04-23T14:15:01.461729Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_all_images\n",
    "This function returns a list of full paths to all the images with .png or .jpg extensions in the given path. If an error occurs while fetching images, the function returns an empty list and logs the error message.\n",
    "\n",
    "### Args\n",
    "- path (str): The path to the directory containing the images.\n",
    "\n",
    "### Returns\n",
    "- list: A list of full path to all the images with .png or .jpg extensions.\n",
    "- empty list: An empty list if an error occurred while fetching images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T14:15:04.002208Z",
     "end_time": "2023-04-23T14:15:04.027049Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    \"\"\"Get all images from the given path.\n",
    "\n",
    "    Args:\n",
    "    param: image_path (str): path to the directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of full path to all the images with png or jpg extensions.\n",
    "    - empty list: an empty list if an error occurred while fetching images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # use os.walk to traverse all the subdirectories and get all images\n",
    "        return [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(path)\n",
    "                for name in files\n",
    "                if name.endswith((\".png\", \".jpg\"))]\n",
    "    except Exception as e:\n",
    "        # return an empty list and log the error message if an error occurred\n",
    "        print(f\"An error occurred while fetching images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `get_all_metadata` coroutine function extracts metadata from all images in a directory and saves the metadata information in either pickle or json format. The function takes two parameters, `images_path` and `metadata_path`, which are the paths to the directory where the images are stored and the directory where the metadata will be saved, respectively.\n",
    "\n",
    "The function starts by executing the binary `exifextract` from the `include_path` and passing `images_path` and `metadata_path/metadata.csv` as arguments. The function then waits for the process to terminate and checks if the process terminated successfully. If the process is not successful, a `subprocess.CalledProcessError` is raised.\n",
    "\n",
    "Once the metadata has been extracted, the function opens the `metadata.csv` file and loads the metadata using a `csv.reader` object. The metadata is stored in a list and the first row of the list is treated as the header. The metadata is then processed and stored in a dictionary where each key represents the index of a metadata item and the value is another dictionary containing the metadata information. The `filename` is also added to the metadata for each item.\n",
    "\n",
    "Finally, the metadata dictionary is converted to a pandas dataframe, and the dataframe is saved to a `metadata.csv` file in the `metadata_path` directory.\n",
    "\n",
    "\n",
    "# Note : https://github.com/TeissierYannis/cpe-bigdata-project-cpp-dependencies (exifextract) build the binary from this repository"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "async def get_all_metadata(images_path):\n",
    "    \"\"\"\n",
    "    This coroutine extracts metadata from all images in a directory and saves the metadata information in either pickle or json format.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the directory where the images are stored.\n",
    "    metadata_path (str): The path to the directory where the metadata will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Use the binary exifextract from include path\n",
    "    binary = include_path + '/exifextract' # https://github.com/TeissierYannis/cpe-bigdata-project-cpp-dependencies (exifextract) build the binary from this repository\n",
    "    command = [binary, images_path, metadata_path + '/metadata.csv']\n",
    "    import subprocess\n",
    "    # execute command\n",
    "    popen = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "    popen.wait()\n",
    "\n",
    "    # wait for the process to terminate\n",
    "    output, error = popen.communicate()\n",
    "\n",
    "    while popen.poll() is None:\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # check if the process terminated successfully\n",
    "    if popen.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(popen.returncode, command)\n",
    "\n",
    "    # load metadata from csv\n",
    "    with open(metadata_path + '/metadata.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        metadata = list(reader)\n",
    "        header = metadata[0]\n",
    "\n",
    "    metadata = metadata[1:]\n",
    "    metadata_dict = {}\n",
    "    for i, row in enumerate(metadata):\n",
    "        metadata_dict[i] = {}\n",
    "        for j in range(1, len(header)):\n",
    "            metadata_dict[i][header[j]] = row[j]\n",
    "        # add filename to metadata\n",
    "        # remove ' from row[0]\n",
    "        row[0] = row[0].replace(\"'\", '')\n",
    "        metadata_dict[i]['filename'] = row[0]\n",
    "\n",
    "    # convert dict to dataframe\n",
    "    metadata_df = pd.DataFrame.from_dict(metadata_dict, orient='index')\n",
    "    # save metadata to csv\n",
    "    metadata_df.to_csv(metadata_path + '/metadata.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:15:05.426029Z",
     "end_time": "2023-04-23T14:15:05.450582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Le fichier spécifié est introuvable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27252\\1032667937.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0masyncio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_all_metadata\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\nest_asyncio.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[0mtask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0masyncio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_future\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mloop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_until_complete\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\nest_asyncio.py\u001B[0m in \u001B[0;36mrun_until_complete\u001B[1;34m(self, future)\u001B[0m\n\u001B[0;32m     88\u001B[0m                 raise RuntimeError(\n\u001B[0;32m     89\u001B[0m                     'Event loop stopped before Future completed.')\n\u001B[1;32m---> 90\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     91\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\asyncio\\futures.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    179\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__log_traceback\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_exception\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 181\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    182\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\asyncio\\tasks.py\u001B[0m in \u001B[0;36m__step\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    247\u001B[0m                 \u001B[1;31m# We use the `send` method directly, because coroutines\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    248\u001B[0m                 \u001B[1;31m# don't have `__iter__` and `__next__` methods.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 249\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcoro\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    250\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    251\u001B[0m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcoro\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mthrow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27252\\913298295.py\u001B[0m in \u001B[0;36mget_all_metadata\u001B[1;34m(images_path)\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mimport\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[1;31m# execute command\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mpopen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstdout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msubprocess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPIPE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m     \u001B[0mpopen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\subprocess.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001B[0m\n\u001B[0;32m    798\u001B[0m                                 \u001B[0mc2pread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc2pwrite\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m                                 \u001B[0merrread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrwrite\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 800\u001B[1;33m                                 restore_signals, start_new_session)\n\u001B[0m\u001B[0;32m    801\u001B[0m         \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    802\u001B[0m             \u001B[1;31m# Cleanup if the child failed starting.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\subprocess.py\u001B[0m in \u001B[0;36m_execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001B[0m\n\u001B[0;32m   1205\u001B[0m                                          \u001B[0menv\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1206\u001B[0m                                          \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfspath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcwd\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mcwd\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1207\u001B[1;33m                                          startupinfo)\n\u001B[0m\u001B[0;32m   1208\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1209\u001B[0m                 \u001B[1;31m# Child is launched. Close the parent's copy of those pipe\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] Le fichier spécifié est introuvable"
     ]
    }
   ],
   "source": [
    "asyncio.run(get_all_metadata(images_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T08:36:30.214124Z",
     "end_time": "2023-04-23T08:36:33.666388Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read metadata from CSV file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output\\\\metadata/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27252\\3841439458.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mread_metadata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmetadata_path\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'/metadata.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    227\u001B[0m             \u001B[0mmemory_map\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"memory_map\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m             \u001B[0mstorage_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"storage_options\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 229\u001B[1;33m             \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"encoding_errors\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"strict\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    230\u001B[0m         )\n\u001B[0;32m    231\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\python37\\current\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    705\u001B[0m                 \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    706\u001B[0m                 \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 707\u001B[1;33m                 \u001B[0mnewline\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    708\u001B[0m             )\n\u001B[0;32m    709\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../output\\\\metadata/metadata.csv'"
     ]
    }
   ],
   "source": [
    "read_metadata = pd.read_csv(metadata_path + '/metadata.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T08:36:49.664094Z",
     "end_time": "2023-04-23T08:36:49.681594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read_metadata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T08:36:52.975718Z",
     "end_time": "2023-04-23T08:36:53.006570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
