{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recommender system\n",
    "# 1 Get user preferences from the user profile file\n",
    "# 2 Get all items that match the user preferences (SQL query to the database) (10 items) and adapt if there is no result\n",
    "\n",
    "\n",
    "===========\n",
    "- Retrive user preferences (load it from json file and extract prefered items)\n",
    "- Query all metadata from the database.\n",
    "- Rank images based on the user preferences (Clustering, similarity, collaborative filtering)\n",
    "- Recommend the top 10 images to the user\n",
    "\n",
    "Rank images :\n",
    "- Convert data to a matrix or a dataframe\n",
    "- Apply clustering algorithm (K-means, DBSCAN, Hierarchical clustering)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "\n",
    "database_path = os.path.join(metadata_path, \"metadata.db\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_users():\n",
    "    # Connect to the database and get all users from the database\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT * FROM users\")\n",
    "    # Dictionary of users with keys (pseudo, fav_color, fav_orientation, fav_height, fav_width)\n",
    "    users = c.fetchall()\n",
    "\n",
    "    users = {user[0]: user[1:] for user in users}\n",
    "\n",
    "    return users"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_user_preferences(username):\n",
    "    # Get the user preferences from the user profile file\n",
    "    # Return a dictionary with keys (fav_color, fav_orientation, fav_height, fav_width)\n",
    "    users = get_users()\n",
    "    return users[username]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_metadata_from_sqlite_db(db_name='metadata.db'):\n",
    "    \"\"\"\n",
    "    Get the metadata from the sqlite database\n",
    "\n",
    "    :param db_name: The name of the database\n",
    "    :return: A dictionary with the metadata\n",
    "    \"\"\"\n",
    "    # Open a connection to the database\n",
    "    conn = sqlite3.connect(os.path.join(metadata_path, db_name))\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Retrieve all key-value pairs concatenated by filename\n",
    "    c.execute(\"SELECT filename, GROUP_CONCAT(key || ':' || value, '; ') AS metadata FROM metadata GROUP BY filename\")\n",
    "    rows = c.fetchall()\n",
    "\n",
    "    # Store the concatenated key-value pairs in a dictionary\n",
    "    metadata_dict = {}\n",
    "    for row in rows:\n",
    "        filename, metadata_str = row\n",
    "        metadata_list = metadata_str.split('; ')\n",
    "        metadata_dict[filename] = {}\n",
    "        for metadata_item in metadata_list:\n",
    "            key, value = metadata_item.split(':', 1)\n",
    "            # if the key is tags, convert the string to a list\n",
    "            if key == 'tags':\n",
    "                metadata_dict[filename][key] = eval(value)\n",
    "            else:\n",
    "                metadata_dict[filename][key] = value\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return metadata_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "        filename               Make     DateTimeOriginal      File Name  \\\n0    image_0.jpg              Canon  2014:09:24 20:09:26    image_0.jpg   \n1    image_1.jpg          Panasonic  2013:12:07 12:17:20    image_1.jpg   \n2   image_10.jpg               SONY  2014:12:03 17:04:16   image_10.jpg   \n3  image_100.jpg               SONY  2018:07:14 21:07:22  image_100.jpg   \n4  image_101.jpg  NIKON CORPORATION  2018:08:06 23:53:48  image_101.jpg   \n\n       tags                                     dominant_color  Artist  \\\n0  [person]  [(\"#15170e\", 0.3704), (\"#4a6423\", 0.1965), (\"#...     NaN   \n1        []  [(\"#274210\", 0.2402), (\"#e0e2e3\", 0.3357), (\"#...  Ugmonk   \n2    [bird]  [(\"#d9d9d9\", 0.3352), (\"#474747\", 0.0161), (\"#...     NaN   \n3        []  [(\"#243a45\", 0.3002), (\"#e4d3de\", 0.1578), (\"#...     NaN   \n4        []  [(\"#100e1d\", 0.4205), (\"#2e3248\", 0.192), (\"#1...     NaN   \n\n                                             GPSInfo Width Height  ...  \\\n0                                                NaN   NaN    NaN  ...   \n1                                                NaN   NaN    NaN  ...   \n2  {0: b'\\x02\\x03\\x00\\x00', 1: 'S', 2: (38.0, 28....  6000   4000  ...   \n3                                                NaN   NaN    NaN  ...   \n4                                                NaN   NaN    NaN  ...   \n\n  LightSource Flash FocalLength ExifImageWidth ExifImageHeight ExposureTime  \\\n0         NaN   NaN         NaN            NaN             NaN          NaN   \n1         NaN   NaN         NaN            NaN             NaN          NaN   \n2         NaN   NaN         NaN            NaN             NaN          NaN   \n3         NaN   NaN         NaN            NaN             NaN          NaN   \n4         NaN   NaN         NaN            NaN             NaN          NaN   \n\n  FNumber ExposureProgram ISOSpeedRatings LensModel  \n0     NaN             NaN             NaN       NaN  \n1     NaN             NaN             NaN       NaN  \n2     NaN             NaN             NaN       NaN  \n3     NaN             NaN             NaN       NaN  \n4     NaN             NaN             NaN       NaN  \n\n[5 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Make</th>\n      <th>DateTimeOriginal</th>\n      <th>File Name</th>\n      <th>tags</th>\n      <th>dominant_color</th>\n      <th>Artist</th>\n      <th>GPSInfo</th>\n      <th>Width</th>\n      <th>Height</th>\n      <th>...</th>\n      <th>LightSource</th>\n      <th>Flash</th>\n      <th>FocalLength</th>\n      <th>ExifImageWidth</th>\n      <th>ExifImageHeight</th>\n      <th>ExposureTime</th>\n      <th>FNumber</th>\n      <th>ExposureProgram</th>\n      <th>ISOSpeedRatings</th>\n      <th>LensModel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_0.jpg</td>\n      <td>Canon</td>\n      <td>2014:09:24 20:09:26</td>\n      <td>image_0.jpg</td>\n      <td>[person]</td>\n      <td>[(\"#15170e\", 0.3704), (\"#4a6423\", 0.1965), (\"#...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_1.jpg</td>\n      <td>Panasonic</td>\n      <td>2013:12:07 12:17:20</td>\n      <td>image_1.jpg</td>\n      <td>[]</td>\n      <td>[(\"#274210\", 0.2402), (\"#e0e2e3\", 0.3357), (\"#...</td>\n      <td>Ugmonk</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_10.jpg</td>\n      <td>SONY</td>\n      <td>2014:12:03 17:04:16</td>\n      <td>image_10.jpg</td>\n      <td>[bird]</td>\n      <td>[(\"#d9d9d9\", 0.3352), (\"#474747\", 0.0161), (\"#...</td>\n      <td>NaN</td>\n      <td>{0: b'\\x02\\x03\\x00\\x00', 1: 'S', 2: (38.0, 28....</td>\n      <td>6000</td>\n      <td>4000</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_100.jpg</td>\n      <td>SONY</td>\n      <td>2018:07:14 21:07:22</td>\n      <td>image_100.jpg</td>\n      <td>[]</td>\n      <td>[(\"#243a45\", 0.3002), (\"#e4d3de\", 0.1578), (\"#...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_101.jpg</td>\n      <td>NIKON CORPORATION</td>\n      <td>2018:08:06 23:53:48</td>\n      <td>image_101.jpg</td>\n      <td>[]</td>\n      <td>[(\"#100e1d\", 0.4205), (\"#2e3248\", 0.192), (\"#1...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = get_metadata_from_sqlite_db()\n",
    "df_metadata = pd.DataFrame(metadata)\n",
    "# reverse the columns and rows\n",
    "df_metadata = df_metadata.transpose()\n",
    "# add name for the first column\n",
    "df_metadata = df_metadata.rename_axis('filename').reset_index()\n",
    "df_metadata.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get user preferences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "   pseudo fav_color fav_orientation fav_height fav_width  \\\n0       0   #28a46a       Landscape       1900       100   \n\n                       fav_tags  \n0  bird,person,surfboard,person  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pseudo</th>\n      <th>fav_color</th>\n      <th>fav_orientation</th>\n      <th>fav_height</th>\n      <th>fav_width</th>\n      <th>fav_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>#28a46a</td>\n      <td>Landscape</td>\n      <td>1900</td>\n      <td>100</td>\n      <td>bird,person,surfboard,person</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = get_user_preferences('Yannis')\n",
    "df_user = pd.DataFrame(user)\n",
    "df_user = df_user.transpose()\n",
    "df_user = df_user.rename_axis('user').reset_index()\n",
    "# rename the columns : ,ID,fav_color,fav_orientation, fav_height, fav_width, fav_tags\n",
    "df_user = df_user.rename(\n",
    "    columns={'user': 'pseudo', 0: 'fav_color', 1: 'fav_orientation', 2: 'fav_height', 3: 'fav_width', 4: 'fav_tags'})\n",
    "# format fav_tags to remove () and ''\n",
    "df_user['fav_tags'] = df_user['fav_tags'].str.replace('(', '', regex=False)\n",
    "df_user['fav_tags'] = df_user['fav_tags'].str.replace(')', '', regex=False)\n",
    "df_user['fav_tags'] = df_user['fav_tags'].str.replace(\"'\", '', regex=False)\n",
    "df_user['fav_tags'] = df_user['fav_tags'].str.replace(\" \", '', regex=False)\n",
    "# add the name of the column for the user name (pseudo)\n",
    "df_user.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find the nearest tags to the user preferences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: gensim in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (4.3.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from nltk) (2022.10.31)\r\n",
      "Requirement already satisfied: click in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from nltk) (8.1.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from nltk) (4.64.1)\r\n",
      "Requirement already satisfied: joblib in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from gensim) (1.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from gensim) (1.24.1)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from gensim) (6.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     /Users/yannisteissier/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yannisteissier/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yannisteissier/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yannisteissier/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import genesis\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('genesis')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# get tags from the dataframe and clean it to get a list of tags\n",
    "tags = df_metadata['tags']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['person',\n 'bird',\n 'surfboard',\n 'backpack',\n 'fire hydrant',\n 'traffic light',\n 'dog',\n 'vase',\n 'potted plant',\n 'boat',\n 'horse',\n 'bottle',\n 'wine glass',\n 'car',\n 'cat',\n 'truck',\n 'cup',\n 'dining table',\n 'bear',\n 'frisbee',\n 'carrot',\n 'kite',\n 'bed',\n 'giraffe',\n 'orange',\n 'oven',\n 'clock',\n 'sheep',\n 'umbrella',\n 'cow',\n 'zebra',\n 'snowboard',\n 'train',\n 'mouse',\n 'cell phone',\n 'cake',\n 'tv',\n 'pizza',\n 'skateboard',\n 'handbag',\n 'toilet',\n 'chair',\n 'broccoli',\n 'banana',\n 'book',\n 'bench',\n 'donut',\n 'refrigerator',\n 'sports ball',\n 'apple',\n 'spoon',\n 'bowl',\n 'airplane',\n 'couch',\n 'elephant',\n 'suitcase',\n 'tie',\n 'parking meter']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of all tags\n",
    "all_tags = []\n",
    "for tag in tags:\n",
    "    try:\n",
    "        for t in tag:\n",
    "            if t not in all_tags:\n",
    "                all_tags.append(t)\n",
    "    except:\n",
    "        pass\n",
    "all_tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "           tags\n0        person\n1          bird\n2     surfboard\n3      backpack\n4  fire hydrant",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>surfboard</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>backpack</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fire hydrant</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the list of tags to a dataframe\n",
    "df_all_tags = pd.DataFrame(all_tags)\n",
    "# rename the column\n",
    "df_all_tags = df_all_tags.rename(columns={0: 'tags'})\n",
    "df_all_tags.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (2.4.5)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (8.1.7)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (2.0.7)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (0.10.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (3.0.8)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (1.0.9)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (1.0.4)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (4.64.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (3.1.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (1.24.1)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (1.10.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (1.1.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (2.28.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (23.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (3.3.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (6.3.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (2.0.8)\r\n",
      "Requirement already satisfied: setuptools in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy) (65.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from jinja2->spacy) (2.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.8/42.8 MB\u001B[0m \u001B[31m30.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from en-core-web-md==3.5.0) (3.5.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (65.5.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.28.2)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.24.1)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.7)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_md')\r\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# download the model\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "           tags                                             vector\n0        person  [-1.0079, -0.025288, -3.5855, -1.278, 2.7287, ...\n1          bird  [4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....\n2     surfboard  [-2.3111, 6.0281, 0.40919, -0.054451, -1.5307,...\n3      backpack  [-0.88119, 3.1579, -3.6337, 0.77035, -0.19718,...\n4  fire hydrant  [-2.10155, 0.19204998, -5.1029, 1.7569599, 3.2...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>person</td>\n      <td>[-1.0079, -0.025288, -3.5855, -1.278, 2.7287, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bird</td>\n      <td>[4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>surfboard</td>\n      <td>[-2.3111, 6.0281, 0.40919, -0.054451, -1.5307,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>backpack</td>\n      <td>[-0.88119, 3.1579, -3.6337, 0.77035, -0.19718,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fire hydrant</td>\n      <td>[-2.10155, 0.19204998, -5.1029, 1.7569599, 3.2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to convert a word to its vector representation\n",
    "def word_to_vector(word):\n",
    "    return nlp(word).vector\n",
    "\n",
    "\n",
    "# Apply the function to all words in the dataframe\n",
    "df_all_tags['vector'] = df_all_tags['tags'].apply(word_to_vector)\n",
    "df_all_tags.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Define a function to compute the cosine similarity between two vectors\n",
    "def cosine_sim(a, b):\n",
    "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6135187\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "vector1 = word_to_vector(\"apple\")\n",
    "vector2 = word_to_vector(\"orange\")\n",
    "similarity = cosine_sim(vector1, vector2)\n",
    "print(similarity)  # Output: 0.613587"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Define a function to compute the similarity between a word and a list of words\n",
    "def word_to_list_similarity(word, word_list):\n",
    "    word_vector = word_to_vector(word)\n",
    "    word_list_vectors = word_list.apply(word_to_vector)\n",
    "    similarities = word_list_vectors.apply(lambda x: cosine_sim(word_vector, x))\n",
    "    return similarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['bird', 'person', 'surfboard', 'person']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each fav_tags in user_df get the similarity between the word and all words in the dataframe and update the dataframe\n",
    "user_tags = df_user['fav_tags'][0]\n",
    "user_tags = user_tags.split(',')\n",
    "user_tags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "        tags                                             vector      bird  \\\n1       bird  [4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....  1.000000   \n30     zebra  [0.032863, 1.8007, -1.3854, -3.5269, -0.24236,...  0.567889   \n23   giraffe  [-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...  0.563594   \n54  elephant  [-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...  0.563594   \n14       cat  [3.7032, 4.1982, -5.0002, -11.322, 0.031702, -...  0.536937   \n\n      person  surfboard  \n1   0.190218   0.213882  \n30  0.095144   0.192323  \n23  0.194894   0.236857  \n54  0.194894   0.236857  \n14  0.205691   0.142983  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>vector</th>\n      <th>bird</th>\n      <th>person</th>\n      <th>surfboard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>bird</td>\n      <td>[4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....</td>\n      <td>1.000000</td>\n      <td>0.190218</td>\n      <td>0.213882</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>zebra</td>\n      <td>[0.032863, 1.8007, -1.3854, -3.5269, -0.24236,...</td>\n      <td>0.567889</td>\n      <td>0.095144</td>\n      <td>0.192323</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>giraffe</td>\n      <td>[-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...</td>\n      <td>0.563594</td>\n      <td>0.194894</td>\n      <td>0.236857</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>elephant</td>\n      <td>[-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...</td>\n      <td>0.563594</td>\n      <td>0.194894</td>\n      <td>0.236857</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>cat</td>\n      <td>[3.7032, 4.1982, -5.0002, -11.322, 0.031702, -...</td>\n      <td>0.536937</td>\n      <td>0.205691</td>\n      <td>0.142983</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tag in user_tags:\n",
    "    similarities = word_to_list_similarity(tag, df_all_tags['tags'])\n",
    "    df_all_tags[tag] = similarities\n",
    "\n",
    "# sort each similarity column in descending order\n",
    "df_all_tags = df_all_tags.sort_values(by=user_tags, ascending=False)\n",
    "df_all_tags.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "        tags                                             vector      bird  \\\n1       bird  [4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....  1.000000   \n30     zebra  [0.032863, 1.8007, -1.3854, -3.5269, -0.24236,...  0.567889   \n23   giraffe  [-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...  0.563594   \n54  elephant  [-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...  0.563594   \n14       cat  [3.7032, 4.1982, -5.0002, -11.322, 0.031702, -...  0.536937   \n\n      person  surfboard  similarity  \n1   0.190218   0.213882    0.231750  \n30  0.095144   0.192323    0.102425  \n23  0.194894   0.236857    0.160907  \n54  0.194894   0.236857    0.160907  \n14  0.205691   0.142983    0.092770  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>vector</th>\n      <th>bird</th>\n      <th>person</th>\n      <th>surfboard</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>bird</td>\n      <td>[4.8752, -1.9177, -1.3281, -5.278, 2.2977, -0....</td>\n      <td>1.000000</td>\n      <td>0.190218</td>\n      <td>0.213882</td>\n      <td>0.231750</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>zebra</td>\n      <td>[0.032863, 1.8007, -1.3854, -3.5269, -0.24236,...</td>\n      <td>0.567889</td>\n      <td>0.095144</td>\n      <td>0.192323</td>\n      <td>0.102425</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>giraffe</td>\n      <td>[-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...</td>\n      <td>0.563594</td>\n      <td>0.194894</td>\n      <td>0.236857</td>\n      <td>0.160907</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>elephant</td>\n      <td>[-0.84077, 2.6076, -1.6748, -3.81, 0.60447, -0...</td>\n      <td>0.563594</td>\n      <td>0.194894</td>\n      <td>0.236857</td>\n      <td>0.160907</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>cat</td>\n      <td>[3.7032, 4.1982, -5.0002, -11.322, 0.031702, -...</td>\n      <td>0.536937</td>\n      <td>0.205691</td>\n      <td>0.142983</td>\n      <td>0.092770</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the similarity between the words in user_preferences and all words in the dataframe and update the dataframe\n",
    "similarities = word_to_list_similarity(\"water\", df_all_tags['tags'])\n",
    "df_all_tags['similarity'] = similarities\n",
    "df_all_tags.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "             tags                                             vector  \\\n4    fire hydrant  [-2.10155, 0.19204998, -5.1029, 1.7569599, 3.2...   \n8    potted plant  [-1.6188099, -2.70715, -5.14225, 3.5575, 4.762...   \n5   traffic light  [-0.895235, 2.24475, -4.0668, 4.0631, -0.25559...   \n47   refrigerator  [0.62057, 0.5426, -1.8448, 2.2689, 1.4919, -1....   \n11         bottle  [-1.0871, -0.41328, -1.353, 2.3119, -0.10389, ...   \n\n        bird    person  surfboard  similarity  \n4   0.253747  0.182810   0.321466    0.827036  \n8   0.263577  0.247293   0.089527    0.503158  \n5   0.200752  0.335850   0.249778    0.495233  \n47  0.120834  0.156021   0.248682    0.475892  \n11  0.245645  0.196740   0.291589    0.457597  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>vector</th>\n      <th>bird</th>\n      <th>person</th>\n      <th>surfboard</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>fire hydrant</td>\n      <td>[-2.10155, 0.19204998, -5.1029, 1.7569599, 3.2...</td>\n      <td>0.253747</td>\n      <td>0.182810</td>\n      <td>0.321466</td>\n      <td>0.827036</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>potted plant</td>\n      <td>[-1.6188099, -2.70715, -5.14225, 3.5575, 4.762...</td>\n      <td>0.263577</td>\n      <td>0.247293</td>\n      <td>0.089527</td>\n      <td>0.503158</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>traffic light</td>\n      <td>[-0.895235, 2.24475, -4.0668, 4.0631, -0.25559...</td>\n      <td>0.200752</td>\n      <td>0.335850</td>\n      <td>0.249778</td>\n      <td>0.495233</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>refrigerator</td>\n      <td>[0.62057, 0.5426, -1.8448, 2.2689, 1.4919, -1....</td>\n      <td>0.120834</td>\n      <td>0.156021</td>\n      <td>0.248682</td>\n      <td>0.475892</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>bottle</td>\n      <td>[-1.0871, -0.41328, -1.353, 2.3119, -0.10389, ...</td>\n      <td>0.245645</td>\n      <td>0.196740</td>\n      <td>0.291589</td>\n      <td>0.457597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the dataframe by similarity\n",
    "df_all_tags = df_all_tags.sort_values(by=['similarity'], ascending=False)\n",
    "df_all_tags.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-macos in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (2.11.0)\r\n",
      "Requirement already satisfied: tensorflow-metal in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (0.7.1)\r\n",
      "Requirement already satisfied: keras in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (2.11.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (3.3.0)\r\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (2.11.2)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (2.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.14.1)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (2.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.16.0)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (3.19.6)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (0.2.0)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (0.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.24.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (4.4.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (3.8.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (15.0.6.1)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (23.1.21)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.51.1)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.6.3)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (1.4.0)\r\n",
      "Requirement already satisfied: packaging in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (23.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-macos) (65.5.1)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorflow-metal) (0.38.4)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (1.8.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (0.6.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (3.4.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (2.28.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (2.2.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (0.4.6)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow-macos) (2.16.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-macos) (5.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-macos) (4.9)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-macos) (0.2.8)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-macos) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-macos) (6.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-macos) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-macos) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-macos) (3.0.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-macos) (3.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-macos) (2.1.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-macos) (3.12.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-macos) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-macos) (3.2.2)\r\n",
      "1.2.1\n",
      "Requirement already satisfied: scikit-learn in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (1.2.1)\r\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-macosx_12_0_arm64.whl (8.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.5/8.5 MB\u001B[0m \u001B[31m29.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from scikit-learn) (1.24.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from scikit-learn) (1.10.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.1\r\n",
      "    Uninstalling scikit-learn-1.2.1:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.1\r\n",
      "Successfully installed scikit-learn-1.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-macos tensorflow-metal keras\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "!pip install -U scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import ast"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannisteissier/Documents/bigdata/projet/venv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import ast\n",
    "\n",
    "metadata = get_metadata_from_sqlite_db()\n",
    "df_metadata = pd.DataFrame(metadata)\n",
    "# reverse the columns and rows\n",
    "df_metadata = df_metadata.transpose()\n",
    "# add name for the first column\n",
    "df_metadata = df_metadata.rename_axis('filename').reset_index()\n",
    "\n",
    "# convert the dataframe to a csv file\n",
    "df_metadata.to_csv('metadata.csv', index=False)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('metadata.csv')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "data = data[['filename', 'Make', 'tags', 'dominant_color', 'Width', 'Height']]\n",
    "\n",
    "# check if there is nan in dominant_color\n",
    "if data['dominant_color'].isna().sum() > 0:\n",
    "    # remove the rows with nan in dominant_color\n",
    "    data = data.dropna(subset=['dominant_color'])\n",
    "\n",
    "# Split the dominant_color column into three columns\n",
    "data[['color1', 'color2', 'color3', 'color4']] = pd.DataFrame(\n",
    "    data['dominant_color'].apply(lambda x: [c[0] for c in ast.literal_eval(x)]).tolist(), index=data.index)\n",
    "\n",
    "# Convert the tags column to a list of strings\n",
    "data['tags'] = data['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# One-hot encode the Make column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "make_encoded = encoder.fit_transform(data[['Make']])\n",
    "data = pd.concat([data.drop('Make', axis=1),\n",
    "                  pd.DataFrame(make_encoded, columns=encoder.get_feature_names_out(['Make']), index=data.index)],\n",
    "                 axis=1)\n",
    "\n",
    "# Fill missing values in dominant_color column\n",
    "most_common_color = data['dominant_color'].mode()[0]\n",
    "data['dominant_color'].fillna(most_common_color, inplace=True)\n",
    "\n",
    "# Scale selected columns\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = ['Width', 'Height']\n",
    "data[scaled_columns] = scaler.fit_transform(data[scaled_columns])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[107], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdam(lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Train model on image dataset\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Get feature vector for an input image\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_feature_vector\u001B[39m(image_path):\n",
      "File \u001B[0;32m~/Documents/bigdata/projet/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/bigdata/projet/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define CNN architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
    "\n",
    "# Train model on image dataset\n",
    "model.fit(data, epochs=10)\n",
    "\n",
    "\n",
    "# Get feature vector for an input image\n",
    "def get_feature_vector(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0\n",
    "    features = model.predict(img)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "# Compute similarity between two images\n",
    "def get_similarity(image1_path, image2_path):\n",
    "    features1 = get_feature_vector(image1_path)\n",
    "    features2 = get_feature_vector(image2_path)\n",
    "    similarity = cosine_similarity([features1], [features2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Make recommendations for an input image\n",
    "def get_recommendations(image_path, dataset, k=5):\n",
    "    similarities = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        similarity = get_similarity(image_path, row['filename'])\n",
    "        similarities.append((row['filename'], similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    recommendations = similarities[1:k + 1]\n",
    "    return recommendations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# content-based filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def hex_to_rgb(color):\n",
    "    try:\n",
    "        # remove the # from the color\n",
    "        color = color[1:]\n",
    "        # convert the color to rgb values\n",
    "        rgb = tuple(int(color[i:i + 2], 16) for i in (0, 2, 4))\n",
    "        return rgb\n",
    "    except:\n",
    "        return 0, 0, 0\n",
    "\n",
    "\n",
    "def get_clean_dataset():\n",
    "    metadata = get_metadata_from_sqlite_db()\n",
    "    df_metadata = pd.DataFrame(metadata)\n",
    "    # reverse the columns and rows\n",
    "    df_metadata = df_metadata.transpose()\n",
    "    # add name for the first column\n",
    "    df_metadata = df_metadata.rename_axis('filename').reset_index()\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_metadata = df_metadata.dropna(subset=['dominant_color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    df_metadata[['color1', 'color2', 'color3', 'color4']] = pd.DataFrame(\n",
    "        df_metadata['dominant_color'].apply(lambda x: [c[0] for c in ast.literal_eval(x)]).tolist(),\n",
    "        index=df_metadata.index)\n",
    "    # convert colors to rgb values\n",
    "    df_metadata['color1'] = df_metadata['color1'].apply(lambda x: hex_to_rgb(x))\n",
    "    df_metadata['color2'] = df_metadata['color2'].apply(lambda x: hex_to_rgb(x))\n",
    "    df_metadata['color3'] = df_metadata['color3'].apply(lambda x: hex_to_rgb(x))\n",
    "    df_metadata['color4'] = df_metadata['color4'].apply(lambda x: hex_to_rgb(x))\n",
    "    df_metadata = df_metadata.drop('dominant_color', axis=1)\n",
    "    # convert the tags column to a list of strings\n",
    "    df_metadata = df_metadata.fillna(0)\n",
    "    # remove all columns except filename, tags, color1, color2, color3, color4, Make, Width, Height\n",
    "    df_metadata = df_metadata[['filename', 'tags', 'color1', 'color2', 'color3', 'color4', 'Make', 'Width', 'Height']]\n",
    "    # replace all 0 values with empty strings\n",
    "    df_metadata['Make'] = df_metadata['Make'].replace(0, '')\n",
    "\n",
    "    return df_metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "        filename      tags           color1           color2           color3  \\\n0    image_0.jpg  [person]     (21, 23, 14)    (74, 100, 35)   (123, 150, 82)   \n1    image_1.jpg        []     (39, 66, 16)  (224, 226, 227)   (101, 127, 79)   \n2   image_10.jpg    [bird]  (217, 217, 217)     (71, 71, 71)  (190, 190, 190)   \n3  image_100.jpg        []     (36, 58, 69)  (228, 211, 222)      (8, 31, 17)   \n4  image_101.jpg        []     (16, 14, 29)     (46, 50, 72)     (29, 30, 47)   \n\n            color4               Make Width Height  \n0     (45, 54, 24)              Canon     0      0  \n1  (172, 181, 167)          Panasonic     0      0  \n2  (206, 206, 206)               SONY  6000   4000  \n3   (76, 104, 141)               SONY     0      0  \n4   (92, 109, 143)  NIKON CORPORATION     0      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>tags</th>\n      <th>color1</th>\n      <th>color2</th>\n      <th>color3</th>\n      <th>color4</th>\n      <th>Make</th>\n      <th>Width</th>\n      <th>Height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_0.jpg</td>\n      <td>[person]</td>\n      <td>(21, 23, 14)</td>\n      <td>(74, 100, 35)</td>\n      <td>(123, 150, 82)</td>\n      <td>(45, 54, 24)</td>\n      <td>Canon</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_1.jpg</td>\n      <td>[]</td>\n      <td>(39, 66, 16)</td>\n      <td>(224, 226, 227)</td>\n      <td>(101, 127, 79)</td>\n      <td>(172, 181, 167)</td>\n      <td>Panasonic</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_10.jpg</td>\n      <td>[bird]</td>\n      <td>(217, 217, 217)</td>\n      <td>(71, 71, 71)</td>\n      <td>(190, 190, 190)</td>\n      <td>(206, 206, 206)</td>\n      <td>SONY</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_100.jpg</td>\n      <td>[]</td>\n      <td>(36, 58, 69)</td>\n      <td>(228, 211, 222)</td>\n      <td>(8, 31, 17)</td>\n      <td>(76, 104, 141)</td>\n      <td>SONY</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_101.jpg</td>\n      <td>[]</td>\n      <td>(16, 14, 29)</td>\n      <td>(46, 50, 72)</td>\n      <td>(29, 30, 47)</td>\n      <td>(92, 109, 143)</td>\n      <td>NIKON CORPORATION</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_dataset().head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def get_clean_preferences():\n",
    "    preferences = get_user_preferences('Yannis')\n",
    "    df_preferences = pd.DataFrame(preferences)\n",
    "    # reverse the columns and rows\n",
    "    df_preferences = df_preferences.transpose()\n",
    "    # 0, is the color, 1 is the orientation, 2 is the height, 3 is the width, 4 is the tags, name the columns\n",
    "    df_preferences.columns = ['color', 'orientation', 'height', 'width', 'tags']\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_preferences = df_preferences.dropna(subset=['color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    df_preferences = df_preferences.drop('orientation', axis=1)\n",
    "    # convert the tags column to a list of strings\n",
    "    df_preferences['tags'] = df_preferences['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    # Replace all NaN values with empty strings with the fillna() method\n",
    "    df_preferences = df_preferences.fillna(0)\n",
    "    # remove all columns except filename, tags, color1, color2, color3, color4, Make, Width, Height\n",
    "    df_preferences = df_preferences[['color', 'height', 'width', 'tags']]\n",
    "    # convert colors to rgb values\n",
    "    df_preferences['color'] = df_preferences['color'].apply(lambda x: hex_to_rgb(x))\n",
    "    # replace all 0 values with empty strings\n",
    "    df_preferences['color'] = df_preferences['color'].replace(0, '')\n",
    "\n",
    "    return df_preferences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "            color  height  width                               tags\n0  (40, 164, 106)    1900    100  (bird, person, surfboard, person)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>height</th>\n      <th>width</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(40, 164, 106)</td>\n      <td>1900</td>\n      <td>100</td>\n      <td>(bird, person, surfboard, person)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_preferences().head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "dataset = get_clean_dataset()\n",
    "preferences = get_clean_preferences()\n",
    "# Save dataset as csv file\n",
    "dataset.to_csv('dataset.csv', index=False)\n",
    "# Save preferences as csv file\n",
    "preferences.to_csv('preferences.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          filename           color1           color2           color3  \\\n",
      "940  image_946.jpg   (100, 92, 100)   (54, 125, 170)  (101, 147, 170)   \n",
      "297  image_366.jpg    (40, 98, 135)  (140, 109, 141)  (101, 119, 155)   \n",
      "171  image_252.jpg  (148, 204, 210)    (9, 183, 198)  (203, 220, 223)   \n",
      "147  image_230.jpg  (164, 173, 195)  (201, 205, 216)  (141, 152, 177)   \n",
      "636  image_671.jpg  (189, 184, 229)  (115, 112, 182)  (160, 175, 241)   \n",
      "503  image_551.jpg  (218, 231, 224)   (98, 200, 184)  (229, 245, 244)   \n",
      "368   image_43.jpg   (70, 131, 150)  (164, 195, 196)  (138, 138, 122)   \n",
      "279   image_35.jpg  (137, 164, 166)  (225, 202, 199)  (152, 179, 186)   \n",
      "882  image_894.jpg  (191, 232, 245)  (201, 170, 162)  (240, 231, 233)   \n",
      "386  image_446.jpg  (215, 214, 226)  (180, 193, 199)  (244, 239, 241)   \n",
      "\n",
      "              color4  cosine_sim  \n",
      "940   (72, 110, 136)    0.978719  \n",
      "297   (65, 117, 153)    0.976374  \n",
      "171   (82, 195, 205)    0.970197  \n",
      "147  (183, 190, 207)    0.969345  \n",
      "636  (157, 133, 196)    0.968437  \n",
      "503  (165, 215, 207)    0.967228  \n",
      "368  (124, 171, 179)    0.966734  \n",
      "279  (160, 187, 192)    0.964594  \n",
      "882  (174, 225, 240)    0.962247  \n",
      "386  (159, 177, 190)    0.960950  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def recommend_colors(rgb, dataset_path):\n",
    "    # Load the dataset into a Pandas DataFrame\n",
    "    data = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Extract the individual r, g, and b values from the color columns and create new columns for them\n",
    "    data[['r1', 'g1', 'b1']] = pd.DataFrame(data['color1'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "    data[['r2', 'g2', 'b2']] = pd.DataFrame(data['color2'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "    data[['r3', 'g3', 'b3']] = pd.DataFrame(data['color3'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "    data[['r4', 'g4', 'b4']] = pd.DataFrame(data['color4'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "\n",
    "    # Normalize the r, g, and b columns to be between 0 and 1\n",
    "    data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = data[['r1', 'g1', 'b1', 'r2', 'g2',\n",
    "                                                                                           'b2', 'r3', 'g3', 'b3', 'r4',\n",
    "                                                                                           'g4', 'b4']] / 255\n",
    "\n",
    "    # Normalize the input RGB color to be between 0 and 1\n",
    "    r, g, b = rgb\n",
    "    r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "    # Compute the cosine similarity between the input color and all the colors in the dataset\n",
    "    data['cosine_sim'] = cosine_similarity(\n",
    "        [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "        data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "    # Sort the dataset by cosine similarity in descending order and return the top 10 closest matches\n",
    "    closest_matches = data.sort_values('cosine_sim', ascending=False).head(10)[\n",
    "        ['filename', 'color1', 'color2', 'color3', 'color4', 'cosine_sim']]\n",
    "\n",
    "    return closest_matches\n",
    "\n",
    "\n",
    "rgb = (94, 166, 199)\n",
    "dataset_path = \"dataset.csv\"\n",
    "closest_matches = recommend_colors(rgb, dataset_path)\n",
    "print(closest_matches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.79017373, 0.73772845, ..., 0.70405334, 0.59775274,\n        0.5979558 ],\n       [0.79017373, 1.        , 0.72152618, ..., 0.7231484 , 0.9082249 ,\n        0.92287648],\n       [0.73772845, 0.72152618, 1.        , ..., 0.95905934, 0.81252094,\n        0.78990573],\n       ...,\n       [0.70405334, 0.7231484 , 0.95905934, ..., 1.        , 0.81775104,\n        0.80504648],\n       [0.59775274, 0.9082249 , 0.81252094, ..., 0.81775104, 1.        ,\n        0.98435904],\n       [0.5979558 , 0.92287648, 0.78990573, ..., 0.80504648, 0.98435904,\n        1.        ]])"
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2170 - val_loss: 0.0582\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0220\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 935us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 939us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 906us/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 965us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 939us/step - loss: 0.0044 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 925us/step - loss: 0.0044 - val_loss: 0.0066\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 952us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "          filename          color1           color2           color3  \\\n",
      "989  image_990.jpg   (238, 125, 6)      (23, 10, 4)   (254, 189, 62)   \n",
      "880  image_892.jpg  (237, 121, 19)     (48, 15, 12)  (239, 193, 170)   \n",
      "179   image_26.jpg   (166, 31, 38)  (173, 160, 152)  (116, 108, 103)   \n",
      "312   image_38.jpg   (138, 13, 10)  (227, 175, 176)     (96, 84, 50)   \n",
      "655  image_689.jpg   (192, 77, 14)     (24, 12, 11)   (233, 154, 82)   \n",
      "355  image_418.jpg   (153, 32, 23)   (221, 129, 35)       (47, 7, 8)   \n",
      "534   image_58.jpg   (142, 10, 50)  (203, 128, 139)     (56, 21, 30)   \n",
      "962  image_966.jpg   (249, 212, 3)      (89, 36, 4)    (197, 115, 5)   \n",
      "32   image_127.jpg  (218, 122, 79)    (159, 60, 25)  (247, 179, 146)   \n",
      "761  image_784.jpg   (195, 93, 66)     (32, 17, 11)     (98, 44, 40)   \n",
      "\n",
      "              color4  cosine_sim  \n",
      "989     (146, 58, 2)    0.776133  \n",
      "880    (148, 38, 18)    0.771746  \n",
      "179     (52, 48, 46)    0.758664  \n",
      "312    (221, 87, 91)    0.748349  \n",
      "655    (108, 33, 10)    0.745086  \n",
      "355  (217, 182, 169)    0.738764  \n",
      "534    (173, 71, 90)    0.736992  \n",
      "962    (229, 167, 1)    0.724193  \n",
      "32        (40, 7, 6)    0.707405  \n",
      "761    (155, 55, 40)    0.706551  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract the individual r, g, and b values from the color columns and create new columns for them\n",
    "data[['r1', 'g1', 'b1']] = pd.DataFrame(data['color1'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r2', 'g2', 'b2']] = pd.DataFrame(data['color2'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r3', 'g3', 'b3']] = pd.DataFrame(data['color3'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r4', 'g4', 'b4']] = pd.DataFrame(data['color4'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "\n",
    "# Normalize the r, g, and b columns to be between 0 and 1\n",
    "data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = data[['r1', 'g1', 'b1', 'r2', 'g2',\n",
    "                                                                                       'b2', 'r3', 'g3', 'b3', 'r4',\n",
    "                                                                                       'g4', 'b4']] / 255\n",
    "\n",
    "# Normalize the input RGB color to be between 0 and 1\n",
    "r, g, b = rgb\n",
    "r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "# Compute the cosine similarity between the input color and all the colors in the dataset\n",
    "data['cosine_sim'] = \\\n",
    "    cosine_similarity(\n",
    "        [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "        data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(3,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['r1', 'g1', 'b1']], data[['cosine_sim']], test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Normalize the input RGB color to be between 0 and 1\n",
    "rgb = (94, 166, 199)\n",
    "r_norm, g_norm, b_norm = rgb[0] / 255, rgb[1] / 255, rgb[2] / 255\n",
    "\n",
    "# Predict the cosine similarity between the input color and all the colors in the dataset\n",
    "cosine_sims = model.predict(data[['r1', 'g1', 'b1']])\n",
    "\n",
    "# Add the cosine similarity values to the dataset\n",
    "data['cosine_sim'] = cosine_sims\n",
    "\n",
    "# Sort the dataset by cosine similarity in descending order and return the top 10 closest matches\n",
    "closest_matches = data.sort_values('cosine_sim', ascending=False).head(10)[\n",
    "    ['filename', 'color1', 'color2', 'color3', 'color4', 'cosine_sim']]\n",
    "\n",
    "print(closest_matches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class ColorMatch:\n",
    "    def __init__(self, dataset_path):\n",
    "        if not isinstance(dataset_path, str):\n",
    "            raise TypeError(\"dataset_path should be a string\")\n",
    "        self.dataset_path = dataset_path\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            # Load the dataset into a Pandas DataFrame\n",
    "            self.data = pd.read_csv(self.dataset_path)\n",
    "\n",
    "            # Extract the individual r, g, and b values from the color columns and create new columns for them\n",
    "            self.data[['r1', 'g1', 'b1']] = pd.DataFrame(\n",
    "                self.data['color1'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "            self.data[['r2', 'g2', 'b2']] = pd.DataFrame(\n",
    "                self.data['color2'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "            self.data[['r3', 'g3', 'b3']] = pd.DataFrame(\n",
    "                self.data['color3'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "            self.data[['r4', 'g4', 'b4']] = pd.DataFrame(\n",
    "                self.data['color4'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "\n",
    "            # Normalize the r, g, and b columns to be between 0 and 1\n",
    "            self.data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = self.data[\n",
    "                                                                                                      ['r1', 'g1', 'b1',\n",
    "                                                                                                       'r2', 'g2', 'b2',\n",
    "                                                                                                       'r3', 'g3', 'b3',\n",
    "                                                                                                       'r4', 'g4',\n",
    "                                                                                                       'b4']] / 255\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            self.data = None\n",
    "\n",
    "    def train_model(self):\n",
    "        try:\n",
    "            # Define the neural network architecture\n",
    "            def create_model():\n",
    "                model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Dense(32, activation='relu', input_shape=(3,)),\n",
    "                    tf.keras.layers.Dense(64, activation='relu'),\n",
    "                    tf.keras.layers.Dense(1, activation='linear')\n",
    "                ])\n",
    "                model.compile(optimizer='adam', loss='mse')\n",
    "                return model\n",
    "\n",
    "            # Wrap Keras model in KerasRegressor\n",
    "            model = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "            # Split the dataset into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.data[['r1', 'g1', 'b1']],\n",
    "                                                                self.data[['cosine_sim']],\n",
    "                                                                test_size=0.2)\n",
    "\n",
    "            # Define the hyperparameters to search over\n",
    "            param_grid = {\n",
    "                'batch_size': [32, 64, 128],\n",
    "                'epochs': [10, 20, 30]\n",
    "            }\n",
    "\n",
    "            # Perform grid search over the hyperparameters\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "\n",
    "            # Fit the grid search to the training data\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Set the best hyperparameters\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "            # Train the model using the best hyperparameters on the full training set\n",
    "            self.model = create_model()\n",
    "            self.model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training model: {str(e)}\")\n",
    "            self.model = None\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        try:\n",
    "            # Save the trained model\n",
    "            self.model.save(model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {str(e)}\")\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        try:\n",
    "            # Load the trained model\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            self.model = None\n",
    "\n",
    "    def cosine_similarity(self, rgb):\n",
    "        try:\n",
    "            # Validate that the RGB values are integers between 0 and 255\n",
    "            if not all(isinstance(x, int) and 0 <= x <= 255 for x in rgb):\n",
    "                raise ValueError(\"RGB values should be integers between 0 and 255\")\n",
    "            # Normalize the input RGB color to be between 0 and 1\n",
    "            r, g, b = rgb\n",
    "            r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "            # Compute the cosine similarity between the input color and all the colors in the dataset\n",
    "            self.data['cosine_sim'] = cosine_similarity(\n",
    "                [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "                self.data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "            # Get the index of the color in the dataset with the 10 highest cosine similarity scores\n",
    "            idx = self.data['cosine_sim'].nlargest(10).index\n",
    "\n",
    "            # Return the matching color name\n",
    "            return self.data.loc[idx, 'filename'].tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing cosine similarity: {str(e)}\")\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/wyqs41z16v53xn4gssj1tz2h0000gn/T/ipykernel_44159/1618847847.py:58: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 677us/step - loss: 0.4234\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.1077\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 651us/step - loss: 0.0492\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 637us/step - loss: 0.0266\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 592us/step - loss: 0.0106\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 517us/step - loss: 0.0038\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.0034\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 554us/step - loss: 0.0031\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.0029\n",
      "9/9 [==============================] - 0s 621us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 606us/step - loss: 0.3917\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 555us/step - loss: 0.1280\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 571us/step - loss: 0.0581\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.0333\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 612us/step - loss: 0.0155\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 521us/step - loss: 0.0064\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.0043\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.0033\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.0030\n",
      "9/9 [==============================] - 0s 454us/step\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 639us/step - loss: 0.3210\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 580us/step - loss: 0.1021\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 540us/step - loss: 0.0695\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 620us/step - loss: 0.0386\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 548us/step - loss: 0.0179\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 542us/step - loss: 0.0068\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 504us/step - loss: 0.0043\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.0039\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 516us/step - loss: 0.0036\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.0033\n",
      "9/9 [==============================] - 0s 519us/step\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.4355\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 575us/step - loss: 0.1059\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 621us/step - loss: 0.0556\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.0252\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 623us/step - loss: 0.0085\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.0038\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.0032\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.0028\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.0026\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.0025\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.0025\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.0024\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.0023\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.0022\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.0021\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.0022\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 570us/step - loss: 0.0021\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.0021\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.0021\n",
      "9/9 [==============================] - 0s 493us/step\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 0s 611us/step - loss: 0.4253\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.1420\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 605us/step - loss: 0.0488\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 617us/step - loss: 0.0258\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 572us/step - loss: 0.0084\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 563us/step - loss: 0.0042\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.0035\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.0031\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.0028\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.0027\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 493us/step - loss: 0.0026\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 577us/step - loss: 0.0025\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.0025\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.0024\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.0024\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.0023\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.0023\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 460us/step - loss: 0.0024\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.0024\n",
      "9/9 [==============================] - 0s 456us/step\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 0s 618us/step - loss: 0.2726\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.0909\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 581us/step - loss: 0.0587\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.0243\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 541us/step - loss: 0.0085\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.0050\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.0039\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.0035\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.0032\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.0031\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.0030\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 456us/step - loss: 0.0029\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.0029\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 465us/step - loss: 0.0028\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.0027\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 547us/step - loss: 0.0027\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.0026\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.0027\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.0026\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 538us/step - loss: 0.0026\n",
      "9/9 [==============================] - 0s 423us/step\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 0s 594us/step - loss: 0.5224\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 566us/step - loss: 0.1828\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.0656\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 595us/step - loss: 0.0476\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 572us/step - loss: 0.0238\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.0094\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 550us/step - loss: 0.0048\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 523us/step - loss: 0.0032\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.0029\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.0028\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.0027\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.0026\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.0026\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.0025\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 453us/step - loss: 0.0025\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.0025\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.0025\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 472us/step - loss: 0.0024\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.0024\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.0024\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.0023\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.0023\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.0023\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.0023\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.0023\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.0023\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.0022\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.0022\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.0022\n",
      "9/9 [==============================] - 0s 426us/step\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 1s 760us/step - loss: 0.2591\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 636us/step - loss: 0.0826\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 995us/step - loss: 0.0225\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 817us/step - loss: 0.0083\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 949us/step - loss: 0.0053\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.0043\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 764us/step - loss: 0.0031\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 877us/step - loss: 0.0028\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 554us/step - loss: 0.0026\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 739us/step - loss: 0.0024\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 618us/step - loss: 0.0023\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 691us/step - loss: 0.0023\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 579us/step - loss: 0.0022\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.0022\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 965us/step - loss: 0.0022\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.0021\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 720us/step - loss: 0.0021\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 594us/step - loss: 0.0021\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 687us/step - loss: 0.0021\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 922us/step - loss: 0.0022\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 955us/step - loss: 0.0021\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 912us/step - loss: 0.0021\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.0020\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.0021\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.0020\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 472us/step - loss: 0.0021\n",
      "9/9 [==============================] - 0s 460us/step\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 0s 595us/step - loss: 0.1592\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 599us/step - loss: 0.0909\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 602us/step - loss: 0.0511\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 593us/step - loss: 0.0230\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.0081\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 572us/step - loss: 0.0050\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.0039\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.0034\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 580us/step - loss: 0.0031\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.0029\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.0027\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.0027\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.0026\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.0025\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.0025\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.0025\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.0024\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 521us/step - loss: 0.0024\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.0024\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.0024\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.0024\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.0024\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.0024\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.0024\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.0023\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.0023\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.0023\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.0023\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.0024\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 457us/step - loss: 0.0023\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 755us/step - loss: 0.5039\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 574us/step - loss: 0.2565\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.1211\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.0843\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 731us/step - loss: 0.0792\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 919us/step - loss: 0.0619\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 708us/step - loss: 0.0467\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.0341\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.0223\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.0133\n",
      "5/5 [==============================] - 0s 567us/step\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.3721\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 730us/step - loss: 0.1852\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.0854\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.0712\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 630us/step - loss: 0.0515\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 699us/step - loss: 0.0310\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 612us/step - loss: 0.0188\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 690us/step - loss: 0.0105\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 619us/step - loss: 0.0068\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.0057\n",
      "5/5 [==============================] - 0s 545us/step\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 786us/step - loss: 0.4063\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.2167\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.1038\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 753us/step - loss: 0.0609\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.0510\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 752us/step - loss: 0.0337\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 708us/step - loss: 0.0204\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.0126\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.0079\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.0056\n",
      "5/5 [==============================] - 0s 636us/step\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 716us/step - loss: 0.3222\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.1763\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 592us/step - loss: 0.0987\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 680us/step - loss: 0.0772\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 626us/step - loss: 0.0622\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.0425\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.0274\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.0166\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.0099\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.0067\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 635us/step - loss: 0.0052\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 600us/step - loss: 0.0043\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.0039\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.0034\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 602us/step - loss: 0.0031\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.0029\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 580us/step - loss: 0.0028\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.0027\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.0026\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 582us/step - loss: 0.0026\n",
      "5/5 [==============================] - 0s 641us/step\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 700us/step - loss: 0.3976\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.1917\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.0903\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.0732\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.0535\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.0320\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.0189\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.0100\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.0063\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.0052\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.0046\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.0042\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.0038\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 607us/step - loss: 0.0036\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.0034\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.0032\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.0031\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 649us/step - loss: 0.0029\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.0028\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 604us/step - loss: 0.0028\n",
      "5/5 [==============================] - 0s 617us/step\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 720us/step - loss: 0.4722\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.1992\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.0932\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.0801\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.0617\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.0411\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.0257\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 538us/step - loss: 0.0143\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 715us/step - loss: 0.0070\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.0043\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 760us/step - loss: 0.0040\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.0038\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.0035\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 599us/step - loss: 0.0034\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.0033\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 583us/step - loss: 0.0032\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.0031\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.0031\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 636us/step - loss: 0.0031\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.0030\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 0s 734us/step - loss: 0.4450\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.2414\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.1187\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.0634\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.0506\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 689us/step - loss: 0.0337\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 636us/step - loss: 0.0170\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.0088\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 599us/step - loss: 0.0066\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 606us/step - loss: 0.0056\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.0046\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 619us/step - loss: 0.0041\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.0038\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 629us/step - loss: 0.0035\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 759us/step - loss: 0.0034\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.0031\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.0029\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.0028\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.0027\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.0026\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.0025\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 552us/step - loss: 0.0024\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 570us/step - loss: 0.0024\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.0023\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 582us/step - loss: 0.0023\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 536us/step - loss: 0.0022\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 604us/step - loss: 0.0022\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.0021\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.0021\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 525us/step - loss: 0.0021\n",
      "5/5 [==============================] - 0s 631us/step\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4197\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.2128\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.0924\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.0594\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 606us/step - loss: 0.0501\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 636us/step - loss: 0.0301\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 697us/step - loss: 0.0163\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.0097\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.0063\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.0051\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 571us/step - loss: 0.0045\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.0042\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 578us/step - loss: 0.0038\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.0036\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 622us/step - loss: 0.0034\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 587us/step - loss: 0.0032\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 649us/step - loss: 0.0031\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.0029\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 587us/step - loss: 0.0029\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 600us/step - loss: 0.0028\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 603us/step - loss: 0.0027\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.0027\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 616us/step - loss: 0.0027\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.0026\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.0025\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 538us/step - loss: 0.0025\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 569us/step - loss: 0.0024\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.0024\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 584us/step - loss: 0.0024\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 502us/step - loss: 0.0024\n",
      "5/5 [==============================] - 0s 584us/step\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.6940\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.3604\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.1577\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 602us/step - loss: 0.0767\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.0666\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 579us/step - loss: 0.0560\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 727us/step - loss: 0.0427\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.0337\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 615us/step - loss: 0.0261\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.0198\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.0146\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.0109\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.0082\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.0064\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 607us/step - loss: 0.0052\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.0045\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.0040\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.0037\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.0035\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 540us/step - loss: 0.0033\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.0032\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 593us/step - loss: 0.0031\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 583us/step - loss: 0.0031\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.0030\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 536us/step - loss: 0.0030\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 572us/step - loss: 0.0029\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.0028\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.0028\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.0027\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.0027\n",
      "5/5 [==============================] - 0s 615us/step\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.7718\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 838us/step - loss: 0.6282\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 844us/step - loss: 0.5041\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.3860\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 884us/step - loss: 0.2709\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 717us/step - loss: 0.1703\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 766us/step - loss: 0.0889\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.0418\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.0311\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 843us/step - loss: 0.0351\n",
      "3/3 [==============================] - 0s 790us/step\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.3679\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.2565\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.1690\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.1101\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.0829\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 969us/step - loss: 0.0798\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0750\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.0621\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.0498\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 842us/step - loss: 0.0401\n",
      "3/3 [==============================] - 0s 861us/step\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.4624\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 848us/step - loss: 0.3098\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.1994\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 874us/step - loss: 0.1264\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 848us/step - loss: 0.0857\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 752us/step - loss: 0.0727\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 824us/step - loss: 0.0706\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 762us/step - loss: 0.0573\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.0436\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 759us/step - loss: 0.0328\n",
      "3/3 [==============================] - 0s 895us/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.3686\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.2534\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 878us/step - loss: 0.1643\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.1067\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 830us/step - loss: 0.0824\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0796\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 760us/step - loss: 0.0711\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 864us/step - loss: 0.0555\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 822us/step - loss: 0.0406\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.0285\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 792us/step - loss: 0.0188\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.0116\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 832us/step - loss: 0.0071\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 753us/step - loss: 0.0048\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0038\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 824us/step - loss: 0.0038\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 765us/step - loss: 0.0037\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 870us/step - loss: 0.0034\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 838us/step - loss: 0.0031\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.0030\n",
      "3/3 [==============================] - 0s 748us/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 880us/step - loss: 0.4007\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 722us/step - loss: 0.2883\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 685us/step - loss: 0.1997\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 733us/step - loss: 0.1363\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 821us/step - loss: 0.0987\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.0858\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 665us/step - loss: 0.0824\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 838us/step - loss: 0.0756\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 708us/step - loss: 0.0646\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 908us/step - loss: 0.0544\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 836us/step - loss: 0.0451\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 909us/step - loss: 0.0368\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 895us/step - loss: 0.0297\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 664us/step - loss: 0.0234\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.0180\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0136\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.0104\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 806us/step - loss: 0.0082\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 689us/step - loss: 0.0068\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 705us/step - loss: 0.0059\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 882us/step - loss: 0.4447\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.2976\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.1867\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 885us/step - loss: 0.1123\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0774\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.0697\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 728us/step - loss: 0.0647\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 820us/step - loss: 0.0523\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0390\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0289\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 707us/step - loss: 0.0199\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.0132\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 908us/step - loss: 0.0090\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 762us/step - loss: 0.0067\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 655us/step - loss: 0.0054\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 843us/step - loss: 0.0049\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.0047\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.0046\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.0045\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.0042\n",
      "3/3 [==============================] - 0s 744us/step\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.4946\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.3497\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 909us/step - loss: 0.2383\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.1579\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 875us/step - loss: 0.1081\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.0837\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.0780\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0733\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0641\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0519\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0404\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0309\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 733us/step - loss: 0.0224\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0159\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 934us/step - loss: 0.0110\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 854us/step - loss: 0.0081\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 734us/step - loss: 0.0064\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0056\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 704us/step - loss: 0.0049\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 890us/step - loss: 0.0043\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.0039\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 776us/step - loss: 0.0036\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.0033\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 770us/step - loss: 0.0031\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0030\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 663us/step - loss: 0.0029\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0028\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.0027\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 768us/step - loss: 0.0027\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.0026\n",
      "3/3 [==============================] - 0s 966us/step\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.2506\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.1515\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 868us/step - loss: 0.1101\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 787us/step - loss: 0.1055\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 831us/step - loss: 0.0981\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.0805\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 733us/step - loss: 0.0662\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 866us/step - loss: 0.0545\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 770us/step - loss: 0.0434\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0337\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 833us/step - loss: 0.0257\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0184\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0126\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.0081\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 826us/step - loss: 0.0056\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 850us/step - loss: 0.0042\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 719us/step - loss: 0.0039\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 836us/step - loss: 0.0038\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 673us/step - loss: 0.0038\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0037\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 735us/step - loss: 0.0035\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.0034\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0033\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 670us/step - loss: 0.0032\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.0032\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 766us/step - loss: 0.0031\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 763us/step - loss: 0.0031\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 736us/step - loss: 0.0030\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 698us/step - loss: 0.0030\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 676us/step - loss: 0.0029\n",
      "3/3 [==============================] - 0s 893us/step\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 842us/step - loss: 0.6046\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.4391\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 709us/step - loss: 0.3079\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.2072\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.1336\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.0872\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 877us/step - loss: 0.0665\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 827us/step - loss: 0.0617\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 704us/step - loss: 0.0562\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0449\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.0337\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.0245\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0169\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 880us/step - loss: 0.0113\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.0083\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0064\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 879us/step - loss: 0.0052\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 913us/step - loss: 0.0049\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.0047\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 821us/step - loss: 0.0046\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.0044\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.0042\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0041\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.0040\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0039\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.0038\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.0037\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 859us/step - loss: 0.0036\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.0035\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.0034\n",
      "3/3 [==============================] - 0s 744us/step\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 537us/step - loss: 0.3679\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 547us/step - loss: 0.0781\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 543us/step - loss: 0.0373\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 509us/step - loss: 0.0114\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 475us/step - loss: 0.0043\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 489us/step - loss: 0.0035\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 480us/step - loss: 0.0032\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 470us/step - loss: 0.0030\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 488us/step - loss: 0.0028\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 463us/step - loss: 0.0026\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 499us/step - loss: 0.0025\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 454us/step - loss: 0.0025\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 479us/step - loss: 0.0024\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 474us/step - loss: 0.0024\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 465us/step - loss: 0.0023\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 448us/step - loss: 0.0023\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 486us/step - loss: 0.0023\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 443us/step - loss: 0.0022\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 440us/step - loss: 0.0022\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 497us/step - loss: 0.0022\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 571us/step - loss: 0.2263\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 544us/step - loss: 0.0755\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 584us/step - loss: 0.0302\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 523us/step - loss: 0.0079\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 476us/step - loss: 0.0033\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 461us/step - loss: 0.0030\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 517us/step - loss: 0.0028\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 456us/step - loss: 0.0027\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 500us/step - loss: 0.0026\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 473us/step - loss: 0.0025\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 454us/step - loss: 0.0024\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 497us/step - loss: 0.0024\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 470us/step - loss: 0.0024\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 437us/step - loss: 0.0024\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 499us/step - loss: 0.0024\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 451us/step - loss: 0.0024\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 455us/step - loss: 0.0024\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 498us/step - loss: 0.0023\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 492us/step - loss: 0.0023\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 428us/step - loss: 0.0023\n",
      "Top 10 most similar colors to (25, 100, 38):\n",
      "1. image_403.jpg\n",
      "2. image_944.jpg\n",
      "3. image_252.jpg\n",
      "4. image_551.jpg\n",
      "5. image_43.jpg\n",
      "6. image_35.jpg\n",
      "7. image_894.jpg\n",
      "8. image_895.jpg\n",
      "9. image_446.jpg\n",
      "10. image_946.jpg\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Extract the individual r, g, and b values from the color columns and create new columns for them\n",
    "data[['r1', 'g1', 'b1']] = pd.DataFrame(data['color1'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r2', 'g2', 'b2']] = pd.DataFrame(data['color2'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r3', 'g3', 'b3']] = pd.DataFrame(data['color3'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "data[['r4', 'g4', 'b4']] = pd.DataFrame(data['color4'].apply(lambda x: eval(x.strip('()'))).tolist())\n",
    "\n",
    "# Normalize the r, g, and b columns to be between 0 and 1\n",
    "data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = data[['r1', 'g1', 'b1', 'r2', 'g2',\n",
    "                                                                                       'b2', 'r3', 'g3', 'b3', 'r4',\n",
    "                                                                                       'g4', 'b4']] / 255\n",
    "\n",
    "# Normalize the input RGB color to be between 0 and 1\n",
    "r, g, b = rgb\n",
    "r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "# Compute the cosine similarity between the input color and all the colors in the dataset\n",
    "data['cosine_sim'] = \\\n",
    "    cosine_similarity(\n",
    "        [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "        data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "# save data to file\n",
    "data.to_csv('dataset.csv', index=False)\n",
    "\n",
    "# Instantiate a ColorMatch object with the path to the dataset\n",
    "color_match = ColorMatch('dataset.csv')\n",
    "\n",
    "# Load the data from the dataset\n",
    "color_match.load_data()\n",
    "\n",
    "# Train the model\n",
    "color_match.train_model()\n",
    "\n",
    "# Save the trained model to a file\n",
    "color_match.save_model('color_match_model.h5')\n",
    "\n",
    "# Load the trained model from a file\n",
    "color_match.load_model('color_match_model.h5')\n",
    "\n",
    "# Compute the cosine similarity between an input RGB color and all the colors in the dataset\n",
    "rgb = (25, 100, 38)\n",
    "cosine_similarities = color_match.cosine_similarity(rgb)\n",
    "\n",
    "# Print the top 5 most similar colors to the input color\n",
    "\n",
    "print(f\"Top 10 most similar colors to {rgb}:\")\n",
    "for i, color in enumerate(cosine_similarities):\n",
    "    print(f\"{i + 1}. {color}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "['image_403.jpg',\n 'image_944.jpg',\n 'image_252.jpg',\n 'image_551.jpg',\n 'image_43.jpg',\n 'image_35.jpg',\n 'image_894.jpg',\n 'image_895.jpg',\n 'image_446.jpg',\n 'image_946.jpg']"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
