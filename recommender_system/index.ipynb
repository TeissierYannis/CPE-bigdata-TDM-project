{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mysql.connector import pooling\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preferences = {\n",
    "    'Make': '',\n",
    "    'ImageWidth': '',\n",
    "    'ImageHeight': '',\n",
    "    'Orientation': 1,\n",
    "    'dominant_color': '#73AD3D',\n",
    "    'tags': ['vase', 'toilet']\n",
    "}\n",
    "\n",
    "# Set SQL variables\n",
    "sql_host = os.getenv(\"SQL_HOST\")\n",
    "sql_user = os.getenv(\"SQL_USER\")\n",
    "sql_password = os.getenv(\"SQL_PASSWORD\")\n",
    "sql_database = os.getenv(\"SQL_DATABASE\")\n",
    "\n",
    "# set the database config\n",
    "config = {\n",
    "    'user': sql_user,\n",
    "    'password': sql_password,\n",
    "    'host': sql_host,\n",
    "    'port': '3306',\n",
    "    'database': sql_database,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a connection pool\n",
    "connection_pool = pooling.MySQLConnectionPool(pool_name=\"mypool\",\n",
    "                                              pool_size=2,\n",
    "                                              **config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_metadata_from_mariadb_db():\n",
    "    \"\"\"\n",
    "    Get the metadata from the MariaDB database\n",
    "\n",
    "    :return: A pandas DataFrame with the metadata\n",
    "    \"\"\"\n",
    "    # Open a connection to the database\n",
    "    conn = connection_pool.get_connection()\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Retrieve the metadata\n",
    "    c.execute(\"\"\"\n",
    "        SELECT filename, GROUP_CONCAT(CONCAT(mkey, '\\t', mvalue) SEPARATOR '\\n') AS metadata\n",
    "        FROM metadata\n",
    "        GROUP BY filename;\n",
    "    \"\"\")\n",
    "    metadata = c.fetchall()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Create an empty DataFrame with the desired columns\n",
    "    columns = ['filename', 'Make', 'Software', 'ImageWidth', 'ImageHeight', 'Orientation', 'DateTimeOriginal',\n",
    "               'dominant_color', 'tags']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Fill the DataFrame with the metadata\n",
    "    for image in tqdm(metadata, desc=\"Get metadata from database\"):\n",
    "        try:\n",
    "            props = {'filename': image[0]}\n",
    "            metadata_str = image[1].split('\\n')\n",
    "            for prop in metadata_str:\n",
    "                if prop:\n",
    "                    k, value = prop.split('\\t')\n",
    "                    if k in columns[1:]:\n",
    "                        if k == 'dominant_color':\n",
    "                            color_list = eval(value)\n",
    "                            color_list = [c[0] for c in color_list]\n",
    "                            props[k] = color_list\n",
    "                        elif k == 'tags':\n",
    "                            props[k] = eval(value)\n",
    "                        else:\n",
    "                            props[k] = value\n",
    "            df = df.append(props, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(e, image)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hex_to_rgb(color):\n",
    "    try:\n",
    "        # remove the # from the color\n",
    "        color = color[1:]\n",
    "        # convert the color to rgb values\n",
    "        rgb = tuple(int(color[i:i + 2], 16) for i in (0, 2, 4))\n",
    "        return rgb\n",
    "    except:\n",
    "        return 0, 0, 0\n",
    "\n",
    "\n",
    "def get_clean_preferences(df_preferences):\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_preferences = df_preferences.dropna(subset=['dominant_color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    # convert the tags column to a list of strings\n",
    "    # Replace all NaN values with empty strings with the fillna() method\n",
    "    df_preferences = df_preferences.fillna(0)\n",
    "    # convert colors to rgb values\n",
    "    df_preferences['dominant_color'] = df_preferences['dominant_color'].apply(lambda x: hex_to_rgb(x))\n",
    "    # replace all 0 values with empty strings\n",
    "    df_preferences['dominant_color'] = df_preferences['dominant_color'].replace(0, '')\n",
    "\n",
    "    return df_preferences\n",
    "\n",
    "\n",
    "def get_clean_dataset():\n",
    "    metadata = get_metadata_from_mariadb_db()\n",
    "    df_metadata = pd.DataFrame(metadata)\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_metadata = df_metadata.dropna(subset=['dominant_color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    if 'dominant_color' in df_metadata.columns:\n",
    "        df_metadata['color1'] = df_metadata['dominant_color'].apply(lambda x: x[0] if len(x) >= 1 else 0)\n",
    "        df_metadata['color2'] = df_metadata['dominant_color'].apply(lambda x: x[1] if len(x) >= 2 else 0)\n",
    "        df_metadata['color3'] = df_metadata['dominant_color'].apply(lambda x: x[2] if len(x) == 3 else 0)\n",
    "        df_metadata['color4'] = df_metadata['dominant_color'].apply(lambda x: x[3] if len(x) == 4 else 0)\n",
    "        # convert colors to rgb values\n",
    "        df_metadata['color1'] = df_metadata['color1'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color2'] = df_metadata['color2'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color3'] = df_metadata['color3'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color4'] = df_metadata['color4'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata = df_metadata.drop('dominant_color', axis=1)\n",
    "    else:\n",
    "        df_metadata['color1'] = 0\n",
    "        df_metadata['color2'] = 0\n",
    "        df_metadata['color3'] = 0\n",
    "        df_metadata['color4'] = 0\n",
    "\n",
    "    # convert the tags column to a list of strings\n",
    "    df_metadata = df_metadata.fillna(0)\n",
    "    # remove all columns except filename, tags, color1, color2, color3, color4, Make, Width, Height\n",
    "    df_metadata = df_metadata[\n",
    "        ['filename', 'Make', 'ImageWidth', 'ImageHeight', 'Orientation', 'DateTimeOriginal', 'tags', 'color1', 'color2',\n",
    "         'color3', 'color4']]\n",
    "    # replace all 0 values with empty strings\n",
    "    df_metadata['Make'] = df_metadata['Make'].replace(0, '')\n",
    "\n",
    "    return df_metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pref = pd.DataFrame([preferences])\n",
    "df_preferences = get_clean_preferences(df_pref)\n",
    "df_preferences.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_metadata = get_clean_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_metadata.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Color Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_colors(df_metadata, df_preferences, n=0):\n",
    "    # Load the dataset into a Pandas DataFrame\n",
    "    data = df_metadata.copy()\n",
    "\n",
    "    # Extract the individual r, g, and b values from tupbles in the color columns\n",
    "    data[['r1', 'g1', 'b1']] = pd.DataFrame(data['color1'].tolist(), index=data.index)\n",
    "    data[['r2', 'g2', 'b2']] = pd.DataFrame(data['color2'].tolist(), index=data.index)\n",
    "    data[['r3', 'g3', 'b3']] = pd.DataFrame(data['color3'].tolist(), index=data.index)\n",
    "    data[['r4', 'g4', 'b4']] = pd.DataFrame(data['color4'].tolist(), index=data.index)\n",
    "\n",
    "    # Normalize the r, g, and b columns to be between 0 and 1\n",
    "    data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = data[['r1', 'g1', 'b1', 'r2', 'g2',\n",
    "                                                                                           'b2', 'r3', 'g3', 'b3', 'r4',\n",
    "                                                                                           'g4', 'b4']] / 255\n",
    "\n",
    "    # Normalize the input RGB color to be between 0 and 1\n",
    "    r, g, b = df_preferences['dominant_color'][0]\n",
    "    r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "    # Compute the Euclidean distance between the input color and all the colors in the dataset\n",
    "    data['similarity_dominant_color'] = euclidean_distances(\n",
    "        [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "        data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "    # Sort the dataset by Euclidean distance in ascending order and return the top 10 closest matches\n",
    "    if n == 0:\n",
    "        closest_matches = data.sort_values('similarity_dominant_color', ascending=True)[\n",
    "            ['filename', 'color1', 'color2', 'color3', 'color4', 'similarity_dominant_color']]\n",
    "    else:\n",
    "        closest_matches = data.sort_values('similarity_dominant_color', ascending=True).head(n)[\n",
    "            ['filename', 'color1', 'color2', 'color3', 'color4', 'similarity_dominant_color']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_colors(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tag Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_tags(df_metadata, df_preferences, n=0, nlp=None):\n",
    "    # Load the spaCy model if it hasn't been loaded\n",
    "    if not nlp:\n",
    "        nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Define the preferences list and the dataframe\n",
    "    preferences = df_preferences['tags'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.copy()\n",
    "    df = df.dropna(subset=[\"tags\"]).reset_index(drop=True)\n",
    "    # replace int with empty list\n",
    "    df['tags'] = df['tags'].apply(lambda x: x if x else [])\n",
    "\n",
    "    # Precompute the similarity between each tag word and each preference word\n",
    "    similarity_dict = {}\n",
    "    for tag_word in set([word for tags in df['tags'] for word in tags]):\n",
    "        for pref_word in set(preferences):\n",
    "            similarity_dict[(tag_word, pref_word)] = nlp(tag_word).similarity(nlp(pref_word))\n",
    "\n",
    "    # Compute the average similarity for each row in the dataframe\n",
    "    similarities = []\n",
    "    for tags in df['tags']:\n",
    "        sum_similarity = 0\n",
    "        for tag_word in tags:\n",
    "            for pref_word in preferences:\n",
    "                sum_similarity += similarity_dict[(tag_word, pref_word)]\n",
    "        avg_similarity = sum_similarity / (len(tags) * len(preferences)) if len(tags) > 0 else 0\n",
    "        similarities.append(avg_similarity)\n",
    "\n",
    "    # Add the similarity scores to a new column in the dataframe\n",
    "    df['similarity_tags'] = similarities\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_tags', ascending=False)[\n",
    "            ['filename', 'similarity_tags']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_tags', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_tags']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_tags(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_make(df_metadata, df_preferences, n=0):\n",
    "    # Load the spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Define the preferences list and the dataframe\n",
    "    make = df_preferences['Make'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.copy()\n",
    "    df = df.dropna(subset=[\"Make\"]).reset_index(drop=True)\n",
    "\n",
    "    # Convert make and Make to document objects\n",
    "    make_doc = nlp(make)\n",
    "    df['Make'] = df['Make'].apply(nlp)\n",
    "\n",
    "    # Compute the cosine similarity between the make preferences and all the makes in the dataset\n",
    "    similarities = [make_doc.similarity(doc) for doc in df['Make']]\n",
    "\n",
    "    # Add the similarity scores to a new column in the dataframe\n",
    "    df['similarity_make'] = similarities\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_make', ascending=False)[\n",
    "            ['filename', 'similarity_make']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_make', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_make']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_make(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Orientation Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_orientation(df_metadata, df_preferences, n=0):\n",
    "    # Define the preferences list and the dataframe\n",
    "    orientation = df_preferences['Orientation'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.dropna(subset=[\"Orientation\"]).reset_index(drop=True)\n",
    "    # if Orientation contain '' or '0' or '1' then replace with 0 or 1\n",
    "    df['Orientation'] = df['Orientation'].apply(lambda x: 0 if x == '' or x == '0' else 1)\n",
    "\n",
    "    # Convert the Orientation column to integer type\n",
    "    df['Orientation'] = df['Orientation'].astype(int)\n",
    "\n",
    "    # Orientation is 0 or 1, so we can just subtract the preference from the orientation\n",
    "    df['similarity_orientation'] = df['Orientation'].apply(lambda x: abs(x - orientation))\n",
    "\n",
    "    # sort by similarity\n",
    "    if n > 0:\n",
    "        closest_matches = df.sort_values('similarity_orientation', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_orientation']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_orientation', ascending=False)[\n",
    "            ['filename', 'similarity_orientation']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_orientation(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Size Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_size(df_metadata, df_preferences, n=0):\n",
    "    # Define the preferences list and the dataframe\n",
    "    width = int(df_preferences['ImageWidth'][0])\n",
    "    height = int(df_preferences['ImageHeight'][0])\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.dropna(subset=[\"ImageWidth\", \"ImageHeight\"]).reset_index(drop=True)\n",
    "\n",
    "    # Convert the ImageWidth and ImageHeight column to integer type\n",
    "    df[['ImageWidth', 'ImageHeight']] = df[['ImageWidth', 'ImageHeight']].astype(int)\n",
    "\n",
    "    # Compute the product of width and height outside the loop\n",
    "    product = width * height\n",
    "\n",
    "    # Use apply method to compute similarity score for each row\n",
    "    df['similarity_size'] = df.apply(lambda x: 1 - abs(product - (x['ImageWidth'] * x['ImageHeight'])) / product, axis=1)\n",
    "\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_size', ascending=False)[\n",
    "            ['filename', 'similarity_size']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_size', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_size']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_size(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend(df_metadata, df_preferences, n=0):\n",
    "    # Assign weights to properties based on user preferences\n",
    "    weights = {\n",
    "        'Make': float(5.0),\n",
    "        'ImageWidth': float(1.0),\n",
    "        'ImageHeight': float(1.0),\n",
    "        'Orientation': float(2.0),\n",
    "        'dominant_color': float(3.0),\n",
    "        'tags': float(5.0)\n",
    "    }\n",
    "\n",
    "    # Create a dictionary with the preferences and the corresponding recommendation methods\n",
    "    preference_methods = {\n",
    "        'Make': recommend_make,\n",
    "        'ImageWidth': recommend_size,\n",
    "        'ImageHeight': recommend_size,\n",
    "        'Orientation': recommend_orientation,\n",
    "        'dominant_color': recommend_colors,\n",
    "        'tags': recommend_tags\n",
    "    }\n",
    "\n",
    "    # Remove preferences with no values\n",
    "    preferences = {k: v for k, v in df_preferences.squeeze().to_dict().items() if v != ''}\n",
    "\n",
    "    # Calculate the sum of the weights\n",
    "    weights_sum = 0\n",
    "    for key in weights:\n",
    "        weights_sum += weights[key]\n",
    "    for key in weights:\n",
    "        weights[key] = weights[key] / weights_sum\n",
    "\n",
    "    # Calculate similarity score for each property\n",
    "    df_metadata['similarity_score'] = 0.0\n",
    "    for preference, value in preferences.items():\n",
    "        method = preference_methods[preference]\n",
    "        similarity = method(df_metadata, df_preferences, n)[f'similarity_{preference.lower()}'].astype(float)\n",
    "        df_metadata['similarity_score'] += similarity * (weights[preference] / weights_sum)\n",
    "\n",
    "    # Replace NaN values in the 'similarity_score' column with 0\n",
    "    df_metadata['similarity_score'].fillna(0, inplace=True)\n",
    "\n",
    "    # Sort by similarity score\n",
    "    if n == 0:\n",
    "        closest_matches = df_metadata.sort_values('similarity_score', ascending=False)[\n",
    "            ['filename', 'similarity_score']]\n",
    "    else:\n",
    "        closest_matches = df_metadata.sort_values('similarity_score', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_score']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
