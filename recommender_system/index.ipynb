{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "The following code imports the following libraries:\n",
    "\n",
    "- `mysql.connector.pooling`: A library used to connect to a MySQL database.\n",
    "- `tqdm`: A library used to display progress bars.\n",
    "- `sklearn.metrics.pairwise`: A library used to calculate pairwise distances.\n",
    "- `spacy`: A library used for natural language processing (NLP).\n",
    "- `pandas`: A library used for data analysis and manipulation.\n",
    "- `os`: A library used to interact with the operating system.\n",
    "- `collections`: A library used to work with namedtuples.\n",
    "- `dotenv`: A library used to load environment variables from a .env file.\n",
    "\n",
    "Additionally, the code calls the `load_dotenv()` function to load environment variables from a .env file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import spacy\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.dqn import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "import time\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.749402Z",
     "end_time": "2023-04-23T10:47:49.285765Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Named Tuple Definition and Directory Paths\n",
    "\n",
    "The `ImageProperties` named tuple contains information about an image, including its name, hex color, tags, make, orientation, width, and height.\n",
    "\n",
    "The script sets the base folder path for the project as `output_path`. The `images_path`, `metadata_path`, and `config_path` are then set as subdirectories within `output_path`. The `list_of_paths` variable holds all four paths."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ImageProperties = namedtuple('ImageProperties', ['name', 'hex_color', 'tags', 'make', 'orientation', 'width', 'height'])\n",
    "# Set the base folder path for the project\n",
    "output_path = \"../output\"\n",
    "images_path = os.path.join(output_path, \"images\")\n",
    "metadata_path = os.path.join(output_path, \"metadata\")\n",
    "config_path = os.path.join(output_path, \"config\")\n",
    "\n",
    "list_of_paths = [output_path, images_path, metadata_path, config_path]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.757747Z",
     "end_time": "2023-04-23T10:47:49.308796Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we define the preferences of the user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preferences = {\n",
    "    'Make': 'Canon',\n",
    "    'ImageWidth': '301',\n",
    "    'ImageHeight': '301',\n",
    "    'Orientation': 1,\n",
    "    'dominant_color': '#73AD3D',\n",
    "    'tags': ['vase', 'toilet']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.775472Z",
     "end_time": "2023-04-23T10:47:49.310098Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Metadata\n",
    "\n",
    "This function reads the metadata stored in a CSV file and returns the data as a pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_metadata():\n",
    "    \"\"\"\n",
    "    Get the metadata from the CSV file and return it as a pandas DataFrame.\n",
    "\n",
    "    :return: A pandas DataFrame with the metadata\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(os.path.join(metadata_path, \"metadata.csv\"))\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.789068Z",
     "end_time": "2023-04-23T10:47:49.311063Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function to get metadata as ImageProperties\n",
    "\n",
    "The function `get_metadata_as_imageproperties` retrieves the metadata from the CSV file and converts it into a list of namedtuples, ImageProperties.\n",
    "\n",
    "The `get_metadata` function is used to get the metadata as a pandas DataFrame.\n",
    "\n",
    "The required metadata fields are extracted from the DataFrame and stored as lists.\n",
    "\n",
    "For each row in the DataFrame, a namedtuple ImageProperties is created with the fields 'name', 'hex_color', 'tags', 'make', 'orientation', 'width', and 'height' and appended to the list `image_properties`.\n",
    "\n",
    "Finally, the list `image_properties` is returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ImageProperties = namedtuple('ImageProperties', ['name', 'hex_color', 'tags', 'make', 'orientation', 'width', 'height'])\n",
    "\n",
    "def get_metadata_as_imageproperties():\n",
    "    # Get the metadata from the CSV file\n",
    "    metadata_df = get_metadata()\n",
    "\n",
    "\n",
    "    # Create a list of ImageProperties\n",
    "    image_properties = []\n",
    "\n",
    "    names = metadata_df['filename'].tolist()\n",
    "    hex_colors = metadata_df['dominant_color'].tolist()\n",
    "    tags = metadata_df['tags'].tolist()\n",
    "    makes = metadata_df['Make'].tolist()\n",
    "    orientations = metadata_df['Orientation'].tolist()\n",
    "    widths = metadata_df['ImageWidth'].tolist()\n",
    "    heights = metadata_df['ImageHeight'].tolist()\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        image_properties.append(ImageProperties(names[i], hex_colors[i], ast.literal_eval(tags[i]), makes[i], orientations[i], widths[i], heights[i]))\n",
    "\n",
    "    return image_properties"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.804217Z",
     "end_time": "2023-04-23T10:47:49.311999Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hex to RGB Conversion Function\n",
    "\n",
    "The `hex_to_rgb` function is used to convert a hexadecimal color code to its equivalent RGB (Red, Green, Blue) values.\n",
    "\n",
    "### Parameters\n",
    "- color (str): A string representing the hexadecimal color code.\n",
    "\n",
    "### Returns\n",
    "- A tuple containing the red, green, and blue values of the color as integers.\n",
    "\n",
    "### Exception\n",
    "- If there is an error in the conversion process, the function returns a tuple with values (0, 0, 0).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hex_to_rgb(color):\n",
    "    try:\n",
    "        # remove the # from the color\n",
    "        color = color[1:]\n",
    "        # convert the color to rgb values\n",
    "        rgb = tuple(int(color[i:i + 2], 16) for i in (0, 2, 4))\n",
    "        return rgb\n",
    "    except:\n",
    "        return 0, 0, 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.810264Z",
     "end_time": "2023-04-23T10:47:49.312882Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning the Preferences Data\n",
    "\n",
    "The following code is used to clean the preferences data. It removes any rows with missing dominant color values, converts the dominant color column from a hexadecimal string to a tuple of RGB values, converts the tags column to a list of strings, replaces any NaN values with empty strings, and replaces any 0 values with empty strings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_clean_preferences(df_preferences):\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_preferences = df_preferences.dropna(subset=['dominant_color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    # convert the tags column to a list of strings\n",
    "    # Replace all NaN values with empty strings with the fillna() method\n",
    "    df_preferences = df_preferences.fillna(0)\n",
    "    # convert colors to rgb values\n",
    "    df_preferences['dominant_color'] = df_preferences['dominant_color'].apply(lambda x: hex_to_rgb(x))\n",
    "    # replace all 0 values with empty strings\n",
    "    df_preferences['dominant_color'] = df_preferences['dominant_color'].replace(0, '')\n",
    "\n",
    "    return df_preferences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.817653Z",
     "end_time": "2023-04-23T10:47:49.325739Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean Dataset\n",
    "\n",
    "The function `get_clean_dataset()` is used to clean the metadata dataset. It performs the following steps:\n",
    "\n",
    "1. Calls the `get_metadata()` function to retrieve the metadata.\n",
    "2. Converts the metadata to a pandas DataFrame `df_metadata`.\n",
    "3. Removes the rows in `df_metadata` that have missing values in the `dominant_color` column.\n",
    "4. If the `dominant_color` column exists, it splits it into four columns: `color1`, `color2`, `color3`, and `color4`. The `dominant_color` column is then dropped. The new columns are then converted to RGB values.\n",
    "5. Replaces missing values with zeros and converts the `tags` column to a list of strings.\n",
    "6. Keeps only the following columns in the DataFrame: `filename`, `Make`, `ImageWidth`, `ImageHeight`, `Orientation`, `DateTimeOriginal`, `tags`, `color1`, `color2`, `color3`, and `color4`.\n",
    "7. Replaces all zero values with empty strings.\n",
    "8. Returns the cleaned DataFrame `df_metadata`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_clean_dataset():\n",
    "    metadata = get_metadata()\n",
    "    df_metadata = pd.DataFrame(metadata)\n",
    "    # remove the rows with nan in dominant_color\n",
    "    df_metadata = df_metadata.dropna(subset=['dominant_color'])\n",
    "    # split dominant color into 4 columns and remove the dominant_color column\n",
    "    if 'dominant_color' in df_metadata.columns:\n",
    "        df_metadata['color1'] = df_metadata['dominant_color'].apply(lambda x: x[0] if len(x) >= 1 else 0)\n",
    "        df_metadata['color2'] = df_metadata['dominant_color'].apply(lambda x: x[1] if len(x) >= 2 else 0)\n",
    "        df_metadata['color3'] = df_metadata['dominant_color'].apply(lambda x: x[2] if len(x) == 3 else 0)\n",
    "        df_metadata['color4'] = df_metadata['dominant_color'].apply(lambda x: x[3] if len(x) == 4 else 0)\n",
    "        # convert colors to rgb values\n",
    "        df_metadata['color1'] = df_metadata['color1'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color2'] = df_metadata['color2'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color3'] = df_metadata['color3'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata['color4'] = df_metadata['color4'].apply(lambda x: hex_to_rgb(x) if x else (0, 0, 0))\n",
    "        df_metadata = df_metadata.drop('dominant_color', axis=1)\n",
    "    else:\n",
    "        df_metadata['color1'] = 0\n",
    "        df_metadata['color2'] = 0\n",
    "        df_metadata['color3'] = 0\n",
    "        df_metadata['color4'] = 0\n",
    "\n",
    "    # convert the tags column to a list of strings\n",
    "    df_metadata = df_metadata.fillna(0)\n",
    "    # remove all columns except filename, tags, color1, color2, color3, color4, Make, Width, Height\n",
    "    df_metadata = df_metadata[\n",
    "        ['filename', 'Make', 'ImageWidth', 'ImageHeight', 'Orientation', 'DateTimeOriginal', 'tags', 'color1', 'color2',\n",
    "         'color3', 'color4']]\n",
    "    # replace all 0 values with empty strings\n",
    "    df_metadata['Make'] = df_metadata['Make'].replace(0, '')\n",
    "\n",
    "    return df_metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.828472Z",
     "end_time": "2023-04-23T10:47:49.329369Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pref = pd.DataFrame([preferences])\n",
    "df_preferences = get_clean_preferences(df_pref)\n",
    "df_preferences.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.839296Z",
     "end_time": "2023-04-23T10:47:49.341360Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_metadata = get_clean_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.848682Z",
     "end_time": "2023-04-23T10:47:49.341492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_metadata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.857815Z",
     "end_time": "2023-04-23T10:47:49.343755Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Color Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function to Recommend Similar Colors\n",
    "\n",
    "This function `recommend_colors` recommends similar colors to a given color based on Euclidean distance. The input color is compared with all the colors in a given dataset and the most similar colors are returned as the output.\n",
    "\n",
    "The function takes two inputs:\n",
    "- `df_metadata`: A pandas dataframe that contains the information about the images and their colors.\n",
    "- `df_preferences`: A pandas dataframe that contains the preferred color.\n",
    "- `n` (optional): An integer that specifies the number of closest matches to return. If n is not specified, all closest matches are returned.\n",
    "\n",
    "The function first normalizes the colors in the dataset and the preferred color to be between 0 and 1. Then, the Euclidean distance is calculated between the preferred color and all the colors in the dataset. The dataset is sorted based on the Euclidean distance in ascending order and the top n closest matches are returned as the output.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_colors(df_metadata, df_preferences, n=0):\n",
    "    # Load the dataset into a Pandas DataFrame\n",
    "    data = df_metadata.copy()\n",
    "\n",
    "    # Extract the individual r, g, and b values from tupbles in the color columns\n",
    "    data[['r1', 'g1', 'b1']] = pd.DataFrame(data['color1'].tolist(), index=data.index)\n",
    "    data[['r2', 'g2', 'b2']] = pd.DataFrame(data['color2'].tolist(), index=data.index)\n",
    "    data[['r3', 'g3', 'b3']] = pd.DataFrame(data['color3'].tolist(), index=data.index)\n",
    "    data[['r4', 'g4', 'b4']] = pd.DataFrame(data['color4'].tolist(), index=data.index)\n",
    "\n",
    "    # Normalize the r, g, and b columns to be between 0 and 1\n",
    "    data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']] = data[['r1', 'g1', 'b1', 'r2', 'g2',\n",
    "                                                                                           'b2', 'r3', 'g3', 'b3', 'r4',\n",
    "                                                                                           'g4', 'b4']] / 255\n",
    "\n",
    "    # Normalize the input RGB color to be between 0 and 1\n",
    "    r, g, b = df_preferences['dominant_color'][0]\n",
    "    r_norm, g_norm, b_norm = r / 255, g / 255, b / 255\n",
    "\n",
    "    # Compute the Euclidean distance between the input color and all the colors in the dataset\n",
    "    data['similarity_dominant_color'] = euclidean_distances(\n",
    "        [[r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm, r_norm, g_norm, b_norm]],\n",
    "        data[['r1', 'g1', 'b1', 'r2', 'g2', 'b2', 'r3', 'g3', 'b3', 'r4', 'g4', 'b4']])[0]\n",
    "\n",
    "    # Sort the dataset by Euclidean distance in ascending order and return the top 10 closest matches\n",
    "    if n == 0:\n",
    "        closest_matches = data.sort_values('similarity_dominant_color', ascending=True)[\n",
    "            ['filename', 'color1', 'color2', 'color3', 'color4', 'similarity_dominant_color']]\n",
    "    else:\n",
    "        closest_matches = data.sort_values('similarity_dominant_color', ascending=True).head(n)[\n",
    "            ['filename', 'color1', 'color2', 'color3', 'color4', 'similarity_dominant_color']]\n",
    "\n",
    "    return closest_matches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.864576Z",
     "end_time": "2023-04-23T10:47:49.343835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_colors(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.866922Z",
     "end_time": "2023-04-23T10:47:49.349418Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tag Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Purpose\n",
    "The `recommend_tags` function is used to recommend images in a dataset based on their tags, compared to a set of preferred tags.\n",
    "\n",
    "# Input\n",
    "The function takes in three arguments:\n",
    "- `df_metadata`: a pandas DataFrame containing the metadata for the images in the dataset\n",
    "- `df_preferences`: a pandas DataFrame containing the preferred tags\n",
    "- `n`: (optional) the number of recommendations to be returned. The default value is 0, which means that the function will return all recommendations sorted by similarity score.\n",
    "\n",
    "# Output\n",
    "The function returns a pandas DataFrame containing the recommended images, sorted by their similarity score to the preferred tags. The DataFrame contains two columns:\n",
    "- `filename`: the name of the recommended image\n",
    "- `similarity_tags`: the similarity score between the image's tags and the preferred tags\n",
    "\n",
    "# Implementation details\n",
    "The function uses spaCy, a natural language processing library, to compute the similarity between each tag word and each preference word. The similarity score is then computed as the average similarity between the image's tags and the preferred tags. The images are sorted by their similarity score in descending order and the top `n` images are returned. If `n` is not specified, all recommendations will be returned.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_tags(df_metadata, df_preferences, n=0, nlp=None):\n",
    "    # Load the spaCy model if it hasn't been loaded\n",
    "    if not nlp:\n",
    "        nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Define the preferences list and the dataframe\n",
    "    preferences = df_preferences['tags'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.copy()\n",
    "    df = df.dropna(subset=[\"tags\"]).reset_index(drop=True)\n",
    "    # replace int with empty list\n",
    "    df['tags'] = df['tags'].apply(lambda x: x if x else [])\n",
    "\n",
    "    # Precompute the similarity between each tag word and each preference word\n",
    "    similarity_dict = {}\n",
    "    for tag_word in set([word for tags in df['tags'] for word in tags]):\n",
    "        for pref_word in set(preferences):\n",
    "            similarity_dict[(tag_word, pref_word)] = nlp(tag_word).similarity(nlp(pref_word))\n",
    "\n",
    "    # Compute the average similarity for each row in the dataframe\n",
    "    similarities = []\n",
    "    for tags in df['tags']:\n",
    "        sum_similarity = 0\n",
    "        for tag_word in tags:\n",
    "            for pref_word in preferences:\n",
    "                sum_similarity += similarity_dict[(tag_word, pref_word)]\n",
    "        avg_similarity = sum_similarity / (len(tags) * len(preferences)) if len(tags) > 0 else 0\n",
    "        similarities.append(avg_similarity)\n",
    "\n",
    "    # Add the similarity scores to a new column in the dataframe\n",
    "    df['similarity_tags'] = similarities\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_tags', ascending=False)[\n",
    "            ['filename', 'similarity_tags']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_tags', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_tags']]\n",
    "\n",
    "    return closest_matches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.885707Z",
     "end_time": "2023-04-23T10:47:49.374957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_tags(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:48.888057Z",
     "end_time": "2023-04-23T10:47:50.094750Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Similarity\n",
    "# recommend_make() Function\n",
    "\n",
    "The `recommend_make()` function is used to recommend images based on the make of a camera used to take the image. This function takes three parameters as input:\n",
    "1. `df_metadata`: a DataFrame containing metadata of images\n",
    "2. `df_preferences`: a DataFrame containing the make of the camera that the user wants to find similar images to\n",
    "3. `n`: an optional parameter that indicates the number of images to be recommended.\n",
    "\n",
    "The function starts by loading the spaCy NLP model \"en_core_web_md\". Then it defines the camera make from the preferences DataFrame, and loads the metadata DataFrame and removes the rows containing NaN values in the \"Make\" column.\n",
    "\n",
    "The function converts the camera make preference and the \"Make\" column of the metadata DataFrame into spaCy document objects. Then it calculates the cosine similarity between the make preference and all the makes in the metadata DataFrame.\n",
    "\n",
    "The calculated similarity scores are added to a new column \"similarity_make\" in the metadata DataFrame. The metadata DataFrame is then sorted based on the similarity scores and either the top `n` rows or all the rows (if n=0) are returned as the recommended images.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_make(df_metadata, df_preferences, n=0):\n",
    "    # Load the spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Define the preferences list and the dataframe\n",
    "    make = df_preferences['Make'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.copy()\n",
    "    df = df.dropna(subset=[\"Make\"]).reset_index(drop=True)\n",
    "\n",
    "    # Convert make and Make to document objects\n",
    "    make_doc = nlp(make)\n",
    "    df['Make'] = df['Make'].apply(nlp)\n",
    "\n",
    "    # Compute the cosine similarity between the make preferences and all the makes in the dataset\n",
    "    similarities = [make_doc.similarity(doc) for doc in df['Make']]\n",
    "\n",
    "    # Add the similarity scores to a new column in the dataframe\n",
    "    df['similarity_make'] = similarities\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_make', ascending=False)[\n",
    "            ['filename', 'similarity_make']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_make', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_make']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:50.099710Z",
     "end_time": "2023-04-23T10:47:50.103301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_make(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:50.104276Z",
     "end_time": "2023-04-23T10:47:51.848708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Orientation Similarity\n",
    "\n",
    "# Function to Recommend Orientation\n",
    "\n",
    "The `recommend_orientation` function takes in three arguments:\n",
    "1. `df_metadata`: A pandas dataframe containing metadata of images.\n",
    "2. `df_preferences`: A pandas dataframe containing the user's preferences for orientation.\n",
    "3. `n`: Number of recommendations to return. (default is 0, meaning all)\n",
    "\n",
    "## Step 1: Define the preferences\n",
    "The user's preferred orientation is extracted from the `df_preferences` dataframe.\n",
    "\n",
    "## Step 2: Load the dataset\n",
    "The `df_metadata` dataframe is loaded into a new dataframe, `df`, and any rows with missing values in the \"Orientation\" column are removed.\n",
    "\n",
    "## Step 3: Clean the Orientation column\n",
    "The \"Orientation\" column is converted to integer type, and any values of '' or '0' are replaced with 0, and any other values are replaced with 1.\n",
    "\n",
    "## Step 4: Calculate similarity\n",
    "The absolute difference between the \"Orientation\" column and the user's preferred orientation is calculated and stored in a new column, \"similarity_orientation\".\n",
    "\n",
    "## Step 5: Sort and return recommendations\n",
    "The dataframe is sorted by \"similarity_orientation\" in ascending order and the first `n` rows are returned. If `n` is 0 (default), all rows are returned.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_orientation(df_metadata, df_preferences, n=0):\n",
    "    # Define the preferences list and the dataframe\n",
    "    orientation = df_preferences['Orientation'][0]\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.dropna(subset=[\"Orientation\"]).reset_index(drop=True)\n",
    "    # if Orientation contain '' or '0' or '1' then replace with 0 or 1\n",
    "    df['Orientation'] = df['Orientation'].apply(lambda x: 0 if x == '' or x == '0' else 1)\n",
    "\n",
    "    # Convert the Orientation column to integer type\n",
    "    df['Orientation'] = df['Orientation'].astype(int)\n",
    "\n",
    "    # Orientation is 0 or 1, so we can just subtract the preference from the orientation\n",
    "    df['similarity_orientation'] = df['Orientation'].apply(lambda x: abs(x - orientation))\n",
    "\n",
    "    # sort by similarity\n",
    "    if n > 0:\n",
    "        closest_matches = df.sort_values('similarity_orientation', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_orientation']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_orientation', ascending=False)[\n",
    "            ['filename', 'similarity_orientation']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.848987Z",
     "end_time": "2023-04-23T10:47:51.851735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_orientation(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.855454Z",
     "end_time": "2023-04-23T10:47:51.859928Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Size Similarity\n",
    "\n",
    "The `recommend_size` function is used to recommend images based on their size. The function takes three arguments: `df_metadata`, `df_preferences`, and `n`, where `df_metadata` is the metadata of all images, `df_preferences` is the preferred size of the image, and `n` is the number of recommended images to return.\n",
    "\n",
    "The function starts by defining two variables `width` and `height` from the `df_preferences` dataframe and then loads the metadata of all images into a dataframe `df`. It removes any rows in the `df` dataframe that contain NaN values in the `ImageWidth` or `ImageHeight` columns.\n",
    "\n",
    "Next, the function converts the `ImageWidth` and `ImageHeight` columns in the `df` dataframe to integer type. Then, it computes the product of the `width` and `height` variables and stores it in a variable `product`.\n",
    "\n",
    "The function then uses the `apply` method to compute a similarity score for each row in the `df` dataframe. The similarity score is calculated by subtracting the product of the image width and height from the preferred `product` and dividing the result by the `product`.\n",
    "\n",
    "Finally, the function sorts the `df` dataframe based on the similarity score in descending order and returns the top `n` rows if `n` is not equal to zero, or returns all rows if `n` is equal to zero. The returned dataframe contains two columns: `filename` and `similarity_size`.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_size(df_metadata, df_preferences, n=0):\n",
    "    # Define the preferences list and the dataframe\n",
    "    width = int(df_preferences['ImageWidth'][0])\n",
    "    height = int(df_preferences['ImageHeight'][0])\n",
    "    # Load dataset with words and drop duplicate rows\n",
    "    df = df_metadata.dropna(subset=[\"ImageWidth\", \"ImageHeight\"]).reset_index(drop=True)\n",
    "\n",
    "    # Convert the ImageWidth and ImageHeight column to integer type\n",
    "    df[['ImageWidth', 'ImageHeight']] = df[['ImageWidth', 'ImageHeight']].astype(int)\n",
    "\n",
    "    # Compute the product of width and height outside the loop\n",
    "    product = width * height\n",
    "\n",
    "    # Use apply method to compute similarity score for each row\n",
    "    df['similarity_size'] = df.apply(lambda x: 1 - abs(product - (x['ImageWidth'] * x['ImageHeight'])) / product, axis=1)\n",
    "\n",
    "    if n == 0:\n",
    "        closest_matches = df.sort_values('similarity_size', ascending=False)[\n",
    "            ['filename', 'similarity_size']]\n",
    "    else:\n",
    "        closest_matches = df.sort_values('similarity_size', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_size']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.862447Z",
     "end_time": "2023-04-23T10:47:51.864318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend_size(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.869590Z",
     "end_time": "2023-04-23T10:47:52.017727Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recommendation Method\n",
    "\n",
    "The `recommend` function is a recommendation method that computes the similarity score between a set of images and a set of preferences. The function combines the results of several other recommendation methods, which are each designed to compare the images with one aspect of the preferences. The final similarity score is the weighted average of the scores from the individual methods.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- `df_metadata`: A Pandas DataFrame that contains metadata for each image.\n",
    "- `df_preferences`: A Pandas DataFrame that contains the preferences of the user.\n",
    "- `n`: The number of images to return in the result. If `n` is set to 0, all images will be returned.\n",
    "\n",
    "## Output\n",
    "\n",
    "- A Pandas DataFrame that contains the `filename` of each image, along with the `similarity_score` between the image and the user preferences. The images are sorted in descending order of similarity score.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "1. Assign weights to the different properties based on the user preferences.\n",
    "2. Create a dictionary with the preferences and the corresponding recommendation methods.\n",
    "3. Remove preferences with no values.\n",
    "4. Calculate the sum of the weights.\n",
    "5. Calculate the similarity score for each property using the corresponding recommendation method and weighting the scores.\n",
    "6. Replace NaN values in the `similarity_score` column with 0.\n",
    "7. Sort by similarity score and return the top `n` images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend(df_metadata, df_preferences, n=0):\n",
    "    # Assign weights to properties based on user preferences\n",
    "    weights = {\n",
    "        'Make': float(5.0),\n",
    "        'ImageWidth': float(1.0),\n",
    "        'ImageHeight': float(1.0),\n",
    "        'Orientation': float(2.0),\n",
    "        'dominant_color': float(3.0),\n",
    "        'tags': float(5.0)\n",
    "    }\n",
    "\n",
    "    # Create a dictionary with the preferences and the corresponding recommendation methods\n",
    "    preference_methods = {\n",
    "        'Make': recommend_make,\n",
    "        'ImageWidth': recommend_size,\n",
    "        'ImageHeight': recommend_size,\n",
    "        'Orientation': recommend_orientation,\n",
    "        'dominant_color': recommend_colors,\n",
    "        'tags': recommend_tags\n",
    "    }\n",
    "\n",
    "    # Remove preferences with no values\n",
    "    preferences = {k: v for k, v in df_preferences.squeeze().to_dict().items() if v != ''}\n",
    "\n",
    "    # Calculate the sum of the weights\n",
    "    weights_sum = 0\n",
    "    for key in weights:\n",
    "        weights_sum += weights[key]\n",
    "    for key in weights:\n",
    "        weights[key] = weights[key] / weights_sum\n",
    "\n",
    "    # Calculate similarity score for each property\n",
    "    df_metadata['similarity_score'] = 0.0\n",
    "    for preference, value in preferences.items():\n",
    "        method = preference_methods[preference]\n",
    "        if preference == 'ImageWidth' or preference == 'ImageHeight':\n",
    "            similarity = method(df_metadata, df_preferences, n)['similarity_size'].astype(float)\n",
    "        else:\n",
    "            similarity = method(df_metadata, df_preferences, n)[f'similarity_{preference.lower()}'].astype(float)\n",
    "        df_metadata['similarity_score'] += similarity * (weights[preference] / weights_sum)\n",
    "\n",
    "    # Replace NaN values in the 'similarity_score' column with 0\n",
    "    df_metadata['similarity_score'].fillna(0, inplace=True)\n",
    "\n",
    "    # Sort by similarity score\n",
    "    if n == 0:\n",
    "        closest_matches = df_metadata.sort_values('similarity_score', ascending=False)[\n",
    "            ['filename', 'similarity_score']]\n",
    "    else:\n",
    "        closest_matches = df_metadata.sort_values('similarity_score', ascending=False).head(n)[\n",
    "            ['filename', 'similarity_score']]\n",
    "\n",
    "    return closest_matches\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.872134Z",
     "end_time": "2023-04-23T10:47:52.018044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend(df_metadata, df_preferences)  # OK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:51.887566Z",
     "end_time": "2023-04-23T10:47:55.085249Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recommend by grouping all properties\n",
    "# Data Retrieval and User Preference Definition\n",
    "\n",
    "The code retrieves image metadata as image properties using the `get_metadata_as_imageproperties()` method. Then, it defines a dictionary `preferences` to specify the user's preferred values for the properties of an image such as the 'Make' of the camera used, the 'ImageWidth', 'ImageHeight', 'Orientation', the 'dominant_color', and the 'tags' associated with the image.\n",
    "\n",
    "The values specified in the `preferences` dictionary are as follows:\n",
    "- 'Make': 'Canon'\n",
    "- 'ImageWidth': ''\n",
    "- 'ImageHeight': ''\n",
    "- 'Orientation': 1\n",
    "- 'dominant_color': '#00000'\n",
    "- 'tags': ['cat']\n",
    "\n",
    "Note that for 'ImageWidth' and 'ImageHeight', no values are specified, indicated by an empty string.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = get_metadata_as_imageproperties()\n",
    "\n",
    "preferences = {\n",
    "    'Make': 'Canon',\n",
    "    'ImageWidth': '',\n",
    "    'ImageHeight': '',\n",
    "    'Orientation': 1,\n",
    "    'dominant_color': '#00000',\n",
    "    'tags': ['cat']\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.085441Z",
     "end_time": "2023-04-23T10:47:55.090538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function to Preprocess Data\n",
    "\n",
    "The `preprocess_data` function takes a data parameter which is a list of image properties. The function processes each image property in the data list and returns an array of processed data for each image. The function performs the following tasks for each image in the data list:\n",
    "\n",
    "1. It joins the tags of the image into a single string.\n",
    "2. It calculates the average RGB color of the image based on the list of hexadecimal color codes.\n",
    "3. It tries to convert the make of the image into an integer, and if it is not possible, it sets the make length to 0.\n",
    "4. It tries to convert the width and height of the image into integers, and if it is not possible, it sets them to 0.\n",
    "5. It tries to convert the orientation of the image into an integer, and if it is not possible, it sets the orientation to 0.\n",
    "6. It appends the average RGB color, tag length, make length, orientation, width, and height of the image to an array.\n",
    "7. It returns the array for each image in the data list.\n",
    "\n",
    "Note that if any error occurs while processing the data for an image, that image's data is skipped and the function moves on to the next image.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    for image in data:\n",
    "        image_tags = \" \".join(image.tags)\n",
    "        avg_rgb_color = np.mean([hex_to_rgb(color) for color in image.hex_color], axis=0)\n",
    "        try:\n",
    "            make_len = len(image.make)\n",
    "        except TypeError:\n",
    "            make_len = 0\n",
    "\n",
    "        try:\n",
    "            width = int(image.width)\n",
    "        except TypeError:\n",
    "            width = 0\n",
    "\n",
    "        try:\n",
    "            height = int(image.height)\n",
    "        except TypeError:\n",
    "            height = 0\n",
    "\n",
    "        try:\n",
    "            orientation = int(image.orientation)\n",
    "        except:\n",
    "            orientation = 0\n",
    "\n",
    "        avg_rgb_color_list = avg_rgb_color.tolist() if hasattr(avg_rgb_color, 'tolist') else [avg_rgb_color]\n",
    "\n",
    "        try:\n",
    "            yield np.array([\n",
    "                *avg_rgb_color_list,  # Ensure avg_rgb_color is an iterable before unpacking\n",
    "                len(image_tags),\n",
    "                make_len,\n",
    "                orientation,\n",
    "                width,\n",
    "                height\n",
    "            ])\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.092296Z",
     "end_time": "2023-04-23T10:47:55.093958Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code defines a function user_preferences_vector which takes in a dictionary of preferences as input and returns a numpy array containing the processed data. The input preferences include the following properties:\n",
    "\n",
    "- dominant_color: The preferred dominant color in hexadecimal format.\n",
    "- tags: A list of preferred tags.\n",
    "- Make: The preferred make.\n",
    "- Orientation: The preferred orientation.\n",
    "- ImageWidth: The preferred image width.\n",
    "- ImageHeight: The preferred image height.\n",
    "\n",
    "The function first converts the dominant_color from hexadecimal format to RGB format using the hex_to_rgb function. Then, it converts the list of preferred tags into a string by joining the elements of the list. The length of the Make and the tags string are also calculated.\n",
    "\n",
    "The Orientation, ImageWidth, and ImageHeight values are then processed to make sure they are in the correct format (integers).\n",
    "\n",
    "Finally, the processed data is returned as a numpy array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def user_preferences_vector(preferences):\n",
    "    dominant_color = hex_to_rgb(preferences['dominant_color'])\n",
    "    tags = \" \".join(preferences['tags'])\n",
    "    make = preferences['Make']\n",
    "\n",
    "    try:\n",
    "        make_len = len(make)\n",
    "    except TypeError:\n",
    "        make_len = 0\n",
    "\n",
    "    orientation = preferences['Orientation']\n",
    "\n",
    "    try:\n",
    "        width = int(preferences['ImageWidth'])\n",
    "    except (TypeError, ValueError):\n",
    "        width = 0\n",
    "\n",
    "    try:\n",
    "        height = int(preferences['ImageHeight'])\n",
    "    except (TypeError, ValueError):\n",
    "        height = 0\n",
    "\n",
    "    return np.array([\n",
    "        *dominant_color,\n",
    "        len(tags),\n",
    "        make_len,\n",
    "        orientation,\n",
    "        width,\n",
    "        height\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.098254Z",
     "end_time": "2023-04-23T10:47:55.100595Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function to recommend Images based on User Preferences\n",
    "\n",
    "The `recommend_images` function takes in three parameters: `preferences`, `data`, and `top_n`. The `preferences` parameter is a dictionary containing the user's preferences for the image properties, `data` is a list of image properties, and `top_n` is an optional parameter specifying the number of images to be returned.\n",
    "\n",
    "The function starts by preprocessing the `data` using the `preprocess_data` function, converting the image properties into a numerical representation. It then computes a user preferences vector using the `user_preferences_vector` function, which takes the `preferences` dictionary as input and returns a numerical representation of the user's preferences.\n",
    "\n",
    "The cosine similarity between the user vector and each of the preprocessed image properties is then calculated using the `cosine_similarity` function from the scikit-learn library. The `cosine_similarity` function returns a similarity matrix, with the first row containing the similarity scores for the user vector and the other rows containing the similarity scores for each preprocessed image property.\n",
    "\n",
    "The indices of the top `top_n` most similar images are then obtained using the `np.argsort` function, which sorts the similarity scores in ascending order and returns the indices of the elements in the sorted array. The final step is to return the actual image properties for the top `top_n` most similar images by indexing into the original `data` list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_images(preferences, data, top_n=10):\n",
    "    preprocessed_data = np.array(list(preprocess_data(data)))\n",
    "    user_vector = user_preferences_vector(preferences)\n",
    "    similarity_matrix = cosine_similarity(np.vstack([user_vector, preprocessed_data]))\n",
    "    most_similar_indices = np.argsort(-similarity_matrix[0])[1:top_n+1]\n",
    "    return [data[i - 1] for i in most_similar_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.101657Z",
     "end_time": "2023-04-23T10:47:55.144067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the recommender system\n",
    "recommended_images = recommend_images(preferences, data)\n",
    "for image in recommended_images:\n",
    "    print(image.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.105631Z",
     "end_time": "2023-04-23T10:47:55.144382Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recommend images with RL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanation of the `clean` Function\n",
    "\n",
    "The `clean` function is responsible for cleaning and preparing a given pandas DataFrame called `data`. The function follows these steps:\n",
    "\n",
    "1. **Extract the first hex color**: The `hex_color` column contains a list of hex colors. The function extracts the first color in the list by applying a lambda function on the 'hex_color' column. If the list is empty, it assigns `None` to the value.\n",
    "2. **Convert columns to the correct data type**: The function converts the 'width', 'height', and 'orientation' columns to numeric types using the `pd.to_numeric` function. If there are any errors during conversion, the function coerces the values to NaN.\n",
    "3. **Fill missing values**: It fills the missing values (NaN) in the 'width', 'height', and 'orientation' columns with 0 using the `fillna` function.\n",
    "4. **Remove rows with missing values**: Finally, the function removes rows containing any missing values using the `dropna` function.\n",
    "\n",
    "After these steps, the function returns the cleaned DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    \"\"\"\n",
    "    :param data: DataFrame\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 1. first, get only the first hex_color\n",
    "    # 2. Convert each column to the right type of data\n",
    "    # 2. Remove rows with missing values\n",
    "\n",
    "    data['hex_color'] = data['hex_color'].apply(lambda x: eval(x)[0] if len(x) > 0 else None)\n",
    "    data['width'] = pd.to_numeric(data['width'], errors='coerce')\n",
    "    data['height'] = pd.to_numeric(data['height'], errors='coerce')\n",
    "    data['orientation'] = pd.to_numeric(data['orientation'], errors='coerce')\n",
    "    data['width'].fillna(0, inplace=True)\n",
    "    data['height'].fillna(0, inplace=True)\n",
    "    data['orientation'].fillna(0, inplace=True)\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.110053Z",
     "end_time": "2023-04-23T10:47:55.144526Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `preprocess` Function\n",
    "\n",
    "The `preprocess` function is responsible for preprocessing a given pandas DataFrame called `data`. The function performs the following steps:\n",
    "\n",
    "1. **Normalize and scale numerical properties**: The 'width' and 'height' columns are scaled to the range [0, 1] by dividing each value by the maximum value in the respective column. The 'hex_color' column is converted to an RGB representation and normalized by dividing each component by 255, resulting in values in the range [0, 1].\n",
    "   - The '#' symbol is removed from the 'hex_color' column.\n",
    "   - The 'hex_color' values are converted to RGB tuples and stored in the 'rgb_color' column.\n",
    "   - The RGB components are separated into the 'r', 'g', and 'b' columns, and the 'hex_color' and 'rgb_color' columns are dropped.\n",
    "\n",
    "2. **One-hot encode categorical properties**: One-hot encoding is applied to the 'tags', 'make', and 'orientation' columns.\n",
    "   - The 'tags' column is first converted into an array using the `ast.literal_eval` function.\n",
    "   - One-hot encoding is applied to the 'tags' array by stacking the array elements into a single column, applying `pd.get_dummies`, and summing the resulting dummy columns at the original DataFrame index level.\n",
    "   - One-hot encoding is applied to the 'make' column using the `pd.get_dummies` function with the 'make' prefix.\n",
    "   - The 'orientation' column is one-hot encoded into 'landscape' and 'portrait' columns, where 'landscape' is 1 if the orientation is 0 and 'portrait' is 1 if the orientation is 1.\n",
    "   - The original 'tags', 'make', and 'orientation' columns are dropped.\n",
    "\n",
    "After these preprocessing steps, the function returns the preprocessed DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # 1. Normalize and scale numerical properties\n",
    "    # Width and Height: scale to [0, 1] by dividing each value by the maximum value\n",
    "    # Hex colors: Convert hex colors to RGB values in the range 0-255 and normalize it by dividing by 255 (range [0, 1])\n",
    "\n",
    "    data['width'] = data['width'] / data['width'].max()\n",
    "    data['height'] = data['height'] / data['height'].max()\n",
    "\n",
    "    # Convert hex color to RGB and normalize\n",
    "    # Remove # from hex color\n",
    "    data[\"hex_color\"] = data[\"hex_color\"].apply(lambda x: x[1:])\n",
    "    data[\"rgb_color\"] = data[\"hex_color\"].apply(lambda x: tuple(int(x[i:i + 2], 16) for i in (0, 2, 4)))\n",
    "    data[[\"r\", \"g\", \"b\"]] = pd.DataFrame(data[\"rgb_color\"].tolist(), index=data.index) / 255\n",
    "    data.drop([\"hex_color\", \"rgb_color\"], axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encode categorical properties\n",
    "    # 1. tags, make, orientation\n",
    "    # eval tags to have an array\n",
    "    convert_to_array = lambda tag_string: ast.literal_eval(tag_string)\n",
    "\n",
    "    data[\"tags\"] = data[\"tags\"].apply(convert_to_array)\n",
    "    data = pd.concat([data, pd.get_dummies(data[\"tags\"].apply(pd.Series).stack()).sum(level=0)], axis=1)\n",
    "    data = pd.concat([data, pd.get_dummies(data[\"make\"], prefix=\"make\")], axis=1)\n",
    "    data[\"landscape\"] = data[\"orientation\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "    data[\"portrait\"] = data[\"orientation\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "    data.drop([\"tags\", \"make\", \"orientation\"], axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.116199Z",
     "end_time": "2023-04-23T10:47:55.164071Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `train_and_test` Function\n",
    "\n",
    "The `train_and_test` function is responsible for training and evaluating a deep Q-network (DQN) agent for an image recommendation task. The function follows these steps:\n",
    "\n",
    "1. **Load and preprocess data**: Load the raw image properties from a CSV file and preprocess the data using the `clean` and `preprocess` functions. Fill any remaining missing values with 0.\n",
    "2. **Create feature vectors**: Drop the 'name' column and convert the DataFrame into a numpy array to create feature vectors.\n",
    "3. **Combine feature vectors with image names**: Create a new DataFrame containing the image names and their corresponding feature vectors.\n",
    "4. **Split the data**: Split the dataset into training (70%), validation (15%), and test (15%) sets using the `train_test_split` function.\n",
    "5. **Create environments**: Instantiate a `DummyVecEnv` for the training set and create validation and test environments using the `ImageRecommenderEnvironment` class.\n",
    "6. **Define and train the DQN agent**: Create a DQN agent with custom settings, such as the learning rate, buffer size, batch size, gamma, and tau values. Train the agent for a predefined number of timesteps.\n",
    "7. **Save and load the agent**: Save the trained agent to a file and load it for evaluation.\n",
    "8. **Evaluate the agent**: Evaluate the agent on the validation and test sets by running a fixed number of episodes and calculating the average reward, duration, and number of steps.\n",
    "9. **Print evaluation results**: Display the evaluation results, including reward, duration, and steps for both the validation and test sets.\n",
    "\n",
    "The function calculates the precision, recall, and F1-score for the agent's performance, but these metrics are not yet implemented in the code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    df = pd.read_csv('./raw_image_properties.csv', sep=\"|\")\n",
    "\n",
    "    # Convert the list of ImageProperties objects to a pandas DataFrame\n",
    "    #df = pd.DataFrame(raw_image_properties)\n",
    "\n",
    "    clean_image_properties = clean(df)\n",
    "    processed_image_properties = preprocess(clean_image_properties)\n",
    "\n",
    "    # Check for NaN values in the DataFrame\n",
    "    if processed_image_properties.isnull().values.any():\n",
    "        processed_image_properties.fillna(0, inplace=True)\n",
    "\n",
    "    # Create feature vectors (numpy array)\n",
    "    feature_vectors = processed_image_properties.drop([\"name\"], axis=1).values\n",
    "\n",
    "    # Combine the feature vectors with the image names in a new DataFrame\n",
    "    data_with_features = processed_image_properties[['name']].copy()\n",
    "    data_with_features['features'] = list(feature_vectors)\n",
    "\n",
    "    # Split the dataset into training (70%) and the remaining 30%\n",
    "    train_data, temp_data = train_test_split(data_with_features, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Split the remaining data into validation (15%) and test (15%) sets\n",
    "    validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "    env = DummyVecEnv([lambda: ImageRecommenderEnvironment(data_with_features)])\n",
    "\n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=CustomDQNNetwork,\n",
    "        features_extractor_kwargs={'input_dim': input_dim, 'output_dim': output_dim}\n",
    "    )\n",
    "\n",
    "    agent = DQN(MlpPolicy,\n",
    "                env,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "                learning_rate=1e-3,\n",
    "                buffer_size=100000,\n",
    "                batch_size=64,\n",
    "                gamma=0.99,\n",
    "                tau=0.01,\n",
    "                verbose=0)\n",
    "\n",
    "    total_timesteps = 500000  # Adjust this value based on the problem and computational resources\n",
    "    print(\"Starting training at time\", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    start_time = time.time()\n",
    "    agent.learn(total_timesteps=total_timesteps)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save the trained agent\n",
    "    agent.save(\"dqn_agent.pkl\")\n",
    "\n",
    "    # Load the trained agent\n",
    "    #agent = DQN.load(\"dqn_agent.pkl\")\n",
    "\n",
    "    # Create validation and test environments\n",
    "    validation_env = DummyVecEnv([lambda: ImageRecommenderEnvironment(validation_data)])\n",
    "    test_env = DummyVecEnv([lambda: ImageRecommenderEnvironment(test_data)])\n",
    "\n",
    "    # Evaluate the agent on the validation and test sets\n",
    "    num_validation_episodes = 100000\n",
    "    num_test_episodes = 100000\n",
    "\n",
    "    print(\"Starting evaluation at time\", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    start_time = time.time()\n",
    "    validation_reward, validation_duration, validation_steps = evaluate_agent(agent, validation_env, num_validation_episodes)\n",
    "    test_reward, test_duration, test_steps = evaluate_agent(agent, test_env, num_test_episodes)\n",
    "    end_time = time.time()\n",
    "    print(f\"Evaluation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"Validation reward: {validation_reward}, duration: {validation_duration:.2f}s, steps: {validation_steps}\")\n",
    "    print(f\"Test reward: {test_reward}, duration: {test_duration:.2f}s, steps: {test_steps}\")\n",
    "\n",
    "    # Precision = TP / (TP + FP)\n",
    "    # Recall = TP / (TP + FN)\n",
    "    # F1-score = 2 * (Precision * Recall) / (Precision + Recall)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.122947Z",
     "end_time": "2023-04-23T10:47:55.164226Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanation of the `preprocess_preferences` Function\n",
    "\n",
    "The `preprocess_preferences` function is responsible for preprocessing a given pandas DataFrame called `preferences`, which represents user preferences for image recommendations. The function performs the following steps:\n",
    "\n",
    "1. **Normalize and scale numerical properties**: Scale 'width' and 'height' columns to the range [0, 1] by dividing each value by the maximum width and height passed as arguments. Convert 'hex_color' to normalized RGB values in the range [0, 1].\n",
    "   - Remove the '#' symbol from the 'hex_color' column.\n",
    "   - Convert 'hex_color' values to RGB tuples and store them in the 'rgb_color' column.\n",
    "   - Separate RGB components into the 'r', 'g', and 'b' columns, then drop the 'hex_color' and 'rgb_color' columns.\n",
    "\n",
    "2. **One-hot encode categorical properties**: One-hot encode the 'tags', 'make', and 'orientation' columns.\n",
    "   - Convert the 'tags' column into an array using the `ast.literal_eval` function.\n",
    "   - One-hot encode the 'tags' array by stacking its elements into a single column, applying `pd.get_dummies`, and summing the resulting dummy columns at the original DataFrame index level.\n",
    "   - One-hot encode the 'make' column using the `pd.get_dummies` function with the 'make' prefix.\n",
    "   - One-hot encode the 'orientation' column into 'landscape' and 'portrait' columns, where 'landscape' is 1 if the orientation is 0 and 'portrait' is 1 if the orientation is 1.\n",
    "   - Drop the original 'tags', 'make', and 'orientation' columns.\n",
    "\n",
    "3. **Ensure consistent column order**: Compare the processed `preferences` DataFrame with a list of all possible column indexes (`all_indexes`) and adjust the DataFrame accordingly.\n",
    "   - Add missing columns from `all_indexes` to the DataFrame and set their values to 0.\n",
    "   - Remove any extra columns from the DataFrame that are not in `all_indexes`.\n",
    "   - If the number of columns in the processed DataFrame is not equal to the length of `all_indexes`, drop any columns not in `all_indexes` and add missing columns with values set to 0.\n",
    "\n",
    "After these preprocessing steps, the function returns the preprocessed user preferences DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_preferences(preferences, max_width, max_height, all_indexes):\n",
    "        # 1. Normalize and scale numerical properties\n",
    "        # Width and Height: scale to [0, 1] by dividing each value by the maximum value\n",
    "        # Hex colors: Convert hex colors to RGB values in the range 0-255 and normalize it by dividing by 255 (range [0, 1])\n",
    "\n",
    "        preferences['width'] = preferences['width'] / max_width\n",
    "        preferences['height'] = preferences['height'] / max_height\n",
    "\n",
    "        # Convert hex color to RGB and normalize\n",
    "        # Remove # from hex color\n",
    "        try:\n",
    "            preferences[\"hex_color\"] = preferences[\"hex_color\"].apply(lambda x: x[1:])\n",
    "            preferences[\"rgb_color\"] = preferences[\"hex_color\"].apply(lambda x: tuple(int(x[i:i + 2], 16) for i in (0, 2, 4)))\n",
    "            preferences[[\"r\", \"g\", \"b\"]] = pd.DataFrame(preferences[\"rgb_color\"].tolist(), index=preferences.index) / 255\n",
    "            preferences.drop([\"hex_color\", \"rgb_color\"], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # One-hot encode categorical properties\n",
    "        # 1. tags, make, orientation\n",
    "        # eval tags to have an array\n",
    "        convert_to_array = lambda tag_string: ast.literal_eval(tag_string)\n",
    "\n",
    "        try:\n",
    "            preferences[\"tags\"] = preferences[\"tags\"].apply(convert_to_array)\n",
    "            data = pd.concat([preferences, pd.get_dummies(preferences[\"tags\"].apply(pd.Series).stack()).sum(level=0)], axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data = pd.concat([data, pd.get_dummies(data[\"make\"], prefix=\"make\")], axis=1)\n",
    "        except:\n",
    "            data[\"make\"] = 0\n",
    "        data[\"landscape\"] = data[\"orientation\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "        data[\"portrait\"] = data[\"orientation\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "        data.drop([\"tags\", \"make\", \"orientation\"], axis=1, inplace=True)\n",
    "\n",
    "        present_indexes = data.columns.values.tolist()\n",
    "\n",
    "        # Add all indexes to the data as columns and set it to 0 if it is not present\n",
    "        for index in all_indexes:\n",
    "            if index not in present_indexes:\n",
    "                data[index] = 0\n",
    "\n",
    "        try:\n",
    "            data.drop(\"hex_color\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # if prepo_preferences do not have the same lenght as processed_image_properties remove columns that is not in processed_image_properties and add the one that are not in  prepro_preferences bt processed_image_properties\n",
    "\n",
    "        if len(data.columns) != len(all_indexes):\n",
    "            for col in data.columns:\n",
    "                if col not in all_indexes:\n",
    "                    data.drop(col, axis=1, inplace=True)\n",
    "            for col in data.columns:\n",
    "                if col not in data.columns:\n",
    "                    data[col] = 0\n",
    "\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.129218Z",
     "end_time": "2023-04-23T10:47:55.164281Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `clean_prefs` Function\n",
    "\n",
    "The `clean_prefs` function is responsible for cleaning and handling missing or erroneous values in a given pandas DataFrame called `preferences`, which represents user preferences for image recommendations. The function performs the following steps:\n",
    "\n",
    "1. **Clean 'hex_color' column**: Extract the first hex color from the 'hex_color' column. If the column is empty or an error occurs, set the value to 0.\n",
    "\n",
    "2. **Convert columns to numeric**: Convert the 'width', 'height', and 'orientation' columns to numeric values, using the `pd.to_numeric` function with the 'coerce' error handling option. If an error occurs, set the respective value to None.\n",
    "   - For the 'width' column, set any error-causing values to None.\n",
    "   - For the 'height' column, set any error-causing values to None.\n",
    "   - For the 'orientation' column, set any error-causing values to None.\n",
    "\n",
    "3. **Fill missing values**: Fill any missing values (None) in the 'width', 'height', and 'orientation' columns with 0, using the `fillna` function with the 'inplace' option set to True.\n",
    "\n",
    "After these cleaning steps, the function returns the cleaned user preferences DataFrame.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_prefs(preferences):\n",
    "\n",
    "    try:\n",
    "        preferences['hex_color'] = preferences['hex_color'].apply(lambda x: eval(x)[0] if len(x) > 0 else None)\n",
    "    except:\n",
    "        preferences['hex_color'] = 0\n",
    "\n",
    "    try:\n",
    "        preferences['width'] = pd.to_numeric(preferences['width'], errors='coerce')\n",
    "    except:\n",
    "        preferences['width'] = None\n",
    "\n",
    "    try:\n",
    "        preferences['height'] = pd.to_numeric(preferences['height'], errors='coerce')\n",
    "    except:\n",
    "        preferences['height'] = None\n",
    "\n",
    "    try:\n",
    "        preferences['orientation'] = pd.to_numeric(preferences['orientation'], errors='coerce')\n",
    "    except:\n",
    "        preferences['orientation'] = None\n",
    "\n",
    "    preferences['width'].fillna(0, inplace=True)\n",
    "    preferences['height'].fillna(0, inplace=True)\n",
    "    preferences['orientation'].fillna(0, inplace=True)\n",
    "\n",
    "    # check if there is make or others to set it to None\n",
    "    return preferences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.132904Z",
     "end_time": "2023-04-23T10:47:55.164339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_image_name(image_filenames, index):\n",
    "    return image_filenames[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.135950Z",
     "end_time": "2023-04-23T10:47:55.164393Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `recommend` Function\n",
    "\n",
    "The `recommend` function serves as an image recommendation engine. It processes user preferences and returns a recommended image based on those preferences. Here is a step-by-step explanation of the function:\n",
    "\n",
    "1. **Load image properties**: Read the raw image properties from a CSV file and store them in a pandas DataFrame called `df`.\n",
    "\n",
    "2. **Clean and preprocess image properties**: Clean the image properties using the `clean` function, and then preprocess the cleaned properties using the `preprocess` function. Store the maximum width and height values for later use.\n",
    "\n",
    "3. **Create user preferences**: Create a dictionary with user preferences, including 'make', 'tags', 'hex_color', 'width', and 'height'.\n",
    "\n",
    "4. **Convert user preferences to DataFrame**: Convert the user preferences dictionary to a pandas DataFrame called `df`.\n",
    "\n",
    "5. **Clean and preprocess user preferences**: Clean the user preferences using the `clean_prefs` function, and preprocess the cleaned preferences using the `preprocess_preferences` function. The preprocessed preferences are adjusted to match the format of the processed image properties.\n",
    "\n",
    "6. **Load the trained model**: Load the previously trained DQN model from the 'dqn_agent.pkl' file.\n",
    "\n",
    "7. **Predict the recommended image**: Drop the first column from the preprocessed preferences DataFrame. Then, use the DQN model to predict the recommended image index based on the user preferences, setting the `deterministic` parameter to `True`.\n",
    "\n",
    "8. **Return the recommended image**: Use the `get_image_name` function to retrieve the name of the recommended image from the list of image filenames, and return it as the output of the `recommend` function.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend():\n",
    "\n",
    "    df = pd.read_csv('./raw_image_properties.csv', sep=\"|\")\n",
    "\n",
    "    # Convert the list of ImageProperties objects to a pandas DataFrame\n",
    "    #df = pd.DataFrame(raw_image_properties)\n",
    "\n",
    "    clean_image_properties = clean(df)\n",
    "    max_width = clean_image_properties[\"width\"].max()\n",
    "    max_height = clean_image_properties[\"height\"].max()\n",
    "    processed_image_properties = preprocess(clean_image_properties)\n",
    "\n",
    "    images_filenames = processed_image_properties[\"name\"].values.tolist()\n",
    "\n",
    "    tags = \"['dog']\"\n",
    "\n",
    "    preferences = {\n",
    "        'make': \"Nikon\",\n",
    "        'tags': tags,\n",
    "        'hex_color': \"#88313\",\n",
    "        'width': 2000,\n",
    "        'height': 3000\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame([preferences])\n",
    "\n",
    "    clean_preferences = clean_prefs(df)\n",
    "\n",
    "    prepro_preferences = preprocess_preferences(clean_preferences, max_width, max_height, processed_image_properties.columns)\n",
    "\n",
    "    # do the prediction by loading the model\n",
    "    model = DQN.load(\"dqn_agent.pkl\")\n",
    "    # drop the first column\n",
    "    prepro_preferences.drop(prepro_preferences.columns[0], axis=1, inplace=True)\n",
    "    action, _ = model.predict(prepro_preferences, deterministic=True)\n",
    "\n",
    "    return get_image_name(images_filenames, int(action))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.140050Z",
     "end_time": "2023-04-23T10:47:55.164433Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `ImageRecommenderEnvironment` Class\n",
    "\n",
    "The `ImageRecommenderEnvironment` class is a custom Gym environment for the image recommendation task. It inherits from `gym.Env`, and it is designed to work with the DQN agent. The key components of the class are as follows:\n",
    "\n",
    "1. **Initialization**: The `__init__` method initializes the environment with the given data, setting the action space to the indices of the images and the state space to the feature vectors. The maximum number of steps per episode is also specified.\n",
    "\n",
    "2. **Reset**: The `reset` method resets the environment to an initial state by randomly selecting an image from the data.\n",
    "\n",
    "3. **Step**: The `step` method executes the given action, updates the environment's state, and calculates the reward. The next state and reward are determined using the `_get_next_state_and_reward` method. The method also checks if the episode is done using the `_is_done` method.\n",
    "\n",
    "4. **Render**: The `render` method is optional and can be implemented to visualize the current state of the environment.\n",
    "\n",
    "5. **_get_initial_state**: This helper method randomly selects an initial state from the data.\n",
    "\n",
    "6. **_get_next_state_and_reward**: This helper method takes the action as input, limits the action value to the maximum index of the DataFrame, retrieves the recommended image's features, calculates the reward using the `reward_function`, and returns the next state (which is the same as the current state in this implementation) and the reward.\n",
    "\n",
    "7. **_is_done**: This helper method checks if the episode is done based on the specified condition, which is reaching the maximum number of steps in this example.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageRecommenderEnvironment(gym.Env):\n",
    "    def __init__(self, data_with_features, max_steps=100):\n",
    "        super(ImageRecommenderEnvironment, self).__init__()\n",
    "\n",
    "        self.data = data_with_features\n",
    "        self.current_state = None\n",
    "        self.max_steps = max_steps\n",
    "        self.step_count = 0\n",
    "\n",
    "        # Define action space as the indices of the images\n",
    "        self.action_space = spaces.Discrete(len(self.data))\n",
    "\n",
    "        # Define state space as the feature vectors\n",
    "        feature_vector_length = len(self.data['features'].iloc[0])\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(feature_vector_length,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to an initial state\n",
    "        self.current_state = self._get_initial_state()\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute the given action and observe the next state and reward\n",
    "        next_state, reward = self._get_next_state_and_reward(action)\n",
    "\n",
    "        # Check if the episode is done\n",
    "        self.step_count += 1\n",
    "        done = self._is_done(next_state)\n",
    "\n",
    "        # Update the current state\n",
    "        self.current_state = next_state\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Render the current state of the environment (optional)\n",
    "        pass\n",
    "\n",
    "    def _get_initial_state(self):\n",
    "        # Randomly select an initial state from the data\n",
    "        initial_state = self.data.sample().iloc[0]['features']\n",
    "        return initial_state\n",
    "\n",
    "    def _get_next_state_and_reward(self, action):\n",
    "        # Limit the action value to the maximum index of the DataFrame\n",
    "        action = min(action, len(self.data) - 1)\n",
    "\n",
    "        # Get the recommended image's features based on the action\n",
    "        recommended_image_features = self.data.iloc[action]['features']\n",
    "\n",
    "        # Calculate the reward using the reward_function (you need to define user_preferences)\n",
    "        user_preferences = self.current_state.reshape(1, -1)\n",
    "        recommended_image_features = recommended_image_features.reshape(1, -1)\n",
    "        reward = reward_function(user_preferences, recommended_image_features)\n",
    "\n",
    "        # Get the next state (in this case, we will use the same state as the current state)\n",
    "        next_state = self.current_state\n",
    "\n",
    "        return next_state, reward\n",
    "\n",
    "\n",
    "    def _is_done(self, next_state):\n",
    "        # In this example, we will define a specific condition for the episode to be done.\n",
    "        # If the step_count reaches the max_steps, the episode is done.\n",
    "        return self.step_count >= self.max_steps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.145999Z",
     "end_time": "2023-04-23T10:47:55.164600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `CustomDQNNetwork` Class\n",
    "\n",
    "The `CustomDQNNetwork` class is a custom neural network module that inherits from PyTorch's `nn.Module`. It is designed to work with the DQN agent, and its main components are as follows:\n",
    "\n",
    "1. **Initialization**: The `__init__` method initializes the neural network with the given input and output dimensions. It defines a simple feedforward neural network architecture using the `nn.Sequential` module. The network comprises three fully connected (`nn.Linear`) layers with ReLU activation functions and dropout layers with a dropout rate of 0.5 for regularization.\n",
    "\n",
    "2. **Forward Pass**: The `forward` method is responsible for the forward pass of the input through the network. It takes the input tensor `x` and passes it through the defined network architecture, returning the output tensor.\n",
    "\n",
    "The `CustomDQNNetwork` class serves as the feature extractor for the DQN agent, and its architecture can be modified as needed to improve the performance of the agent on the image recommendation task.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDQNNetwork(nn.Module):\n",
    "    def __init__(self, *args, input_dim=None, output_dim=None, **kwargs):\n",
    "        super(CustomDQNNetwork, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "        self.features_dim = output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.149187Z",
     "end_time": "2023-04-23T10:47:55.281448Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  `reward_function`\n",
    "\n",
    "The `reward_function` is used to calculate the reward for a given recommendation based on the user preferences and the features of the recommended image. It is an essential component of the reinforcement learning environment. The function takes two input arguments: `user_preferences` and `recommended_image_features`, both of which are 1-dimensional feature vectors. The function performs the following steps:\n",
    "\n",
    "1. **Flatten Input Vectors**: The function checks whether the input vectors have the correct dimensions (1-dimensional). If not, it flattens the input vectors to ensure they are 1-dimensional.\n",
    "\n",
    "2. **Calculate Euclidean Distance**: The function computes the Euclidean distance between the user preferences and the recommended image features. This distance represents how dissimilar the recommendation is to the user's preferences.\n",
    "\n",
    "3. **Calculate Reward**: The reward is calculated as the inverse of the sum of 1 and the calculated distance. This formula normalizes the distance to a range between 0 and 1, where a value closer to 1 represents a better match between the recommendation and user preferences, and a value closer to 0 indicates a poor match.\n",
    "\n",
    "The `reward_function` plays a crucial role in guiding the agent's learning process, as it informs the agent about the quality of its recommendations based on the user's preferences.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reward_function(user_preferences, recommended_image_features):\n",
    "    # Ensure that input vectors are 1-dimensional\n",
    "    if not (np.ndim(user_preferences) == 1 and np.ndim(recommended_image_features) == 1):\n",
    "        user_preferences = np.asarray(user_preferences).flatten()\n",
    "        recommended_image_features = np.asarray(recommended_image_features).flatten()\n",
    "\n",
    "    distance = euclidean(user_preferences, recommended_image_features)\n",
    "    reward = 1 / (1 + distance)  # Normalize the distance to [0, 1] by using the inverse\n",
    "    return reward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.152286Z",
     "end_time": "2023-04-23T10:47:55.286414Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `evaluate_agent` Function\n",
    "\n",
    "The `evaluate_agent` function is used to evaluate the performance of a trained reinforcement learning agent in a given environment. The function takes three input arguments: `agent`, `env`, and `num_episodes`. The function performs the following steps:\n",
    "\n",
    "1. **Initialize Metrics**: It initializes empty lists for the total rewards, episode durations, and episode steps to keep track of the agent's performance during evaluation.\n",
    "\n",
    "2. **Run Evaluation Episodes**: For each evaluation episode (ranging from 1 to `num_episodes`), the function:\n",
    "    - Starts a timer to measure the episode duration.\n",
    "    - Resets the environment to an initial state and initializes the episode reward and step count.\n",
    "    - Executes the agent's policy in the environment until the episode is done. At each step, it:\n",
    "        - Predicts the action using the agent's policy (deterministic prediction).\n",
    "        - Takes the action and observes the next state, reward, and whether the episode is done.\n",
    "        - Adds the reward to the episode reward and updates the state.\n",
    "        - Increments the step count and prints the current step's reward.\n",
    "    - Stops the timer when the episode is done and calculates the episode duration.\n",
    "    - Appends the episode reward, duration, and step count to their respective lists.\n",
    "    - Prints the progress (current episode, reward, duration, and steps).\n",
    "\n",
    "3. **Calculate Averages**: After completing all evaluation episodes, the function calculates the average reward, duration, and steps across all episodes.\n",
    "\n",
    "4. **Return Results**: The function returns the average reward, duration, and steps, which can be used to evaluate the agent's performance in the given environment.\n",
    "\n",
    "The `evaluate_agent` function provides a standardized way to evaluate a trained agent's performance and can be used to compare the performance of different agents, training algorithms, or hyperparameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, env, num_episodes):\n",
    "    total_rewards = []\n",
    "    episode_durations = []\n",
    "    episode_steps = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        start_time = time.time()\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            action, _ = agent.predict(state, deterministic=True)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "            step_count += 1\n",
    "            print(f\"Episode {episode + 1}, Step {step_count}: Reward={reward}\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        episode_duration = end_time - start_time\n",
    "        total_rewards.append(episode_reward)\n",
    "        episode_durations.append(episode_duration)\n",
    "        episode_steps.append(step_count)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Episode {episode + 1}/{num_episodes}: Reward={episode_reward}, Duration={episode_duration:.2f}s, Steps={step_count}\")\n",
    "\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    avg_duration = np.mean(episode_durations)\n",
    "    avg_steps = np.mean(episode_steps)\n",
    "\n",
    "    return avg_reward, avg_duration, avg_steps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.156333Z",
     "end_time": "2023-04-23T10:47:55.300166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:47:55.159199Z",
     "end_time": "2023-04-23T10:53:07.777707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:53:07.652979Z",
     "end_time": "2023-04-23T10:53:07.781068Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Image Properties Preprocessing Code\n",
    "\n",
    "The given code snippet performs the following tasks:\n",
    "\n",
    "1. **Load Raw Image Properties**: It reads the raw image properties from the CSV file `./raw_image_properties.csv`, using the separator `|`, and stores the data in a pandas DataFrame `df`.\n",
    "\n",
    "2. **Clean Image Properties**: The `clean` function is called on the raw image properties DataFrame `df` to clean the data. The cleaned data is stored in the DataFrame `clean_image_properties`.\n",
    "\n",
    "3. **Find Maximum Width and Height**: The maximum width and height values from the cleaned image properties are calculated and stored in the variables `max_width` and `max_height`, respectively.\n",
    "\n",
    "4. **Preprocess Image Properties**: The `preprocess` function is called on the cleaned image properties to perform feature engineering and scaling. The preprocessed data is stored in the DataFrame `processed_image_properties`.\n",
    "\n",
    "5. **Save Processed Image Properties**: The preprocessed image properties are saved to a CSV file `./processed_image_properties.csv`, using the separator `|` and without including the DataFrame index.\n",
    "\n",
    "6. **Extract Image Filenames**: The image filenames are extracted from the processed image properties and stored in a list called `images_filenames`.\n",
    "\n",
    "7. **Create User Preferences**: A dictionary called `preferences` is created to store user preferences, including the camera make, tags, hex color, width, and height.\n",
    "\n",
    "8. **Convert Preferences to DataFrame**: The user preferences dictionary is converted into a pandas DataFrame `df`, containing a single row with the preferences.\n",
    "\n",
    "9. **Clean User Preferences**: The `clean_prefs` function is called on the user preferences DataFrame to clean the data. The cleaned data is stored in the DataFrame `clean_preferences`.\n",
    "\n",
    "10. **Preprocess User Preferences**: The `preprocess_preferences` function is called on the cleaned user preferences DataFrame, along with the maximum width and height values and the column names of the processed image properties DataFrame. The preprocessed user preferences are stored in the DataFrame `prepro_preferences`.\n",
    "\n",
    "This code snippet demonstrates how to preprocess both image properties and user preferences, which can be used later for model training, evaluation, or recommendation purposes.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./raw_image_properties.csv', sep=\"|\")\n",
    "# Convert the list of ImageProperties objects to a pandas DataFrame\n",
    "#df = pd.DataFrame(raw_image_properties)\n",
    "\n",
    "clean_image_properties = clean(df)\n",
    "max_width = clean_image_properties[\"width\"].max()\n",
    "max_height = clean_image_properties[\"height\"].max()\n",
    "processed_image_properties = preprocess(clean_image_properties)\n",
    "\n",
    "# Save processed image properties to a CSV file\n",
    "processed_image_properties.to_csv('./processed_image_properties.csv', sep=\"|\", index=False)\n",
    "\n",
    "images_filenames = processed_image_properties[\"name\"].values.tolist()\n",
    "\n",
    "tags = \"['dog']\"\n",
    "\n",
    "preferences = {\n",
    "    'make': \"Nikon\",\n",
    "    'tags': tags,\n",
    "    'hex_color': \"#883131\",\n",
    "    'width': 2000,\n",
    "    'height': 3000\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([preferences])\n",
    "\n",
    "clean_preferences = clean_prefs(df)\n",
    "\n",
    "prepro_preferences = preprocess_preferences(clean_preferences, max_width, max_height, processed_image_properties.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:53:50.251070Z",
     "end_time": "2023-04-23T10:53:50.336832Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanation of the Image Similarity Code\n",
    "\n",
    "The given code snippet performs the following tasks:\n",
    "\n",
    "1. **Create Feature Matrix**: The code creates a feature matrix by dropping the `name` column from the `processed_image_properties` DataFrame. This matrix contains only the feature values of the processed image properties.\n",
    "\n",
    "2. **Replace NaN Values**: All the NaN values in the feature matrix are replaced with 0 using the `fillna()` method.\n",
    "\n",
    "3. **Define Similarity Function**: A function named `get_top_n_similar_names_for_given_vector()` is defined, which takes three parameters: a given feature vector, the feature matrix, and an optional `top_n` parameter (with a default value of 3). This function computes the cosine similarity scores between the given vector and the feature matrix, sorts the scores in descending order, and returns the top `n` image names based on the similarity scores.\n",
    "\n",
    "4. **Reorganize Preprocessed User Preferences**: The `prepro_preferences` DataFrame is reorganized to match the column order of the feature matrix. This step is necessary to ensure that the given vector and the feature matrix have the same feature order when computing similarity scores.\n",
    "\n",
    "5. **Get Top Similar Images**: The given vector is obtained from the `prepro_preferences` DataFrame, and the `get_top_n_similar_names_for_given_vector()` function is called with the given vector and the feature matrix. The top 3 most similar image names are stored in the list `recommended_names`.\n",
    "\n",
    "6. **Print Recommended Image Names**: The recommended image names are printed as the output.\n",
    "\n",
    "This code snippet demonstrates how to find the top similar images for a given feature vector based on the cosine similarity metric. The top similar images can be used for recommendation purposes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_matrix = processed_image_properties.drop(columns=[\"name\"], axis=1)\n",
    "# replace all NaN values with 0\n",
    "feature_matrix = feature_matrix.fillna(0)\n",
    "# Function to get top_n most similar names for a given vector\n",
    "def get_top_n_similar_names_for_given_vector(vector, feature_matrix, top_n=3):\n",
    "    vector = vector.reshape(1, -1)\n",
    "    similarity_scores = cosine_similarity(vector, feature_matrix)\n",
    "    sorted_indexes = similarity_scores[0].argsort()[::-1]\n",
    "    top_n_indexes = sorted_indexes[:top_n]  # Get the top_n indices\n",
    "    return processed_image_properties['name'].iloc[top_n_indexes].tolist()\n",
    "\n",
    "\n",
    "# reorganize the columns of prepo_preferences to match the order of feature_matrix\n",
    "prepro_preferences = prepro_preferences[feature_matrix.columns]\n",
    "# Example usage: Get the top 3 most similar names for a given vector\n",
    "given_vector = prepro_preferences.values\n",
    "\n",
    "recommended_names = get_top_n_similar_names_for_given_vector(given_vector, feature_matrix)\n",
    "print(recommended_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T10:53:53.020725Z",
     "end_time": "2023-04-23T10:53:53.117164Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
